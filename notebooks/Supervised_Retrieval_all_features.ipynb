{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Supervised Retrieval for all models with all features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In this notebook we use the supervised classification model for a supervised crosslingual information retrieval task. We use the default settings with all features remaining after we got rid of correlated features and features that only have one value in the whole column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "#sys.path.append(os.path.dirname((os.path.abspath(''))))\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from src.models.predict_model import MAP_score, threshold_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## I. Import Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we import the feature dataframe for the retrieval task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_dataframe=pd.read_feather(\"../data/processed/feature_model_en_de.feather\")\n",
    "feature_retrieval=pd.read_feather(\"../data/processed/feature_retrieval_en_de.feather\")\n",
    "feature_dataframe = feature_dataframe.rename(columns={\"id_source\": \"source_id\", \"id_target\": \"target_id\"})\n",
    "feature_retrieval = feature_retrieval.rename(columns={\"id_source\": \"source_id\", \"id_target\": \"target_id\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Delete all columns with only one value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_mask = feature_dataframe.apply(threshold_counts, threshold=1)\n",
    "feature_dataframe = feature_dataframe.loc[:, column_mask]\n",
    "feature_retrieval = feature_retrieval.loc[:, column_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(feature_retrieval.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Supervised Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop the target label and the indexes for training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_train=feature_dataframe['Translation'].astype(float)\n",
    "data_train=feature_dataframe.drop(columns=['Translation','source_id','target_id'])\n",
    "target_test=feature_retrieval['Translation'].astype(float)\n",
    "data_test=feature_retrieval.drop(columns=['Translation','source_id','target_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Z-Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scale data into [0,1]\n",
    "scaler = preprocessing.StandardScaler()\n",
    "data_train.loc[:, data_train.columns] = scaler.fit_transform(data_train.loc[:, data_train.columns])\n",
    "data_test.loc[:, data_test.columns] = scaler.transform(data_test.loc[:, data_test.columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MAP score on test set: 0.1287\n"
     ]
    }
   ],
   "source": [
    "nb = GaussianNB().fit(data_train, target_train)\n",
    "prediction = nb.predict_proba(data_test)\n",
    "print(\"The MAP score on test set: {:.4f}\".format(MAP_score(feature_retrieval['source_id'],target_test,prediction)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.06518519\n",
      "Validation score: 0.987091\n",
      "Iteration 2, loss = 0.03789368\n",
      "Validation score: 0.987773\n",
      "Iteration 3, loss = 0.03533450\n",
      "Validation score: 0.988364\n",
      "Iteration 4, loss = 0.03473055\n",
      "Validation score: 0.988227\n",
      "Iteration 5, loss = 0.03368928\n",
      "Validation score: 0.988182\n",
      "Iteration 6, loss = 0.03309335\n",
      "Validation score: 0.988500\n",
      "Iteration 7, loss = 0.03249780\n",
      "Validation score: 0.988773\n",
      "Iteration 8, loss = 0.03149650\n",
      "Validation score: 0.988909\n",
      "Iteration 9, loss = 0.03099210\n",
      "Validation score: 0.989045\n",
      "Iteration 10, loss = 0.03063312\n",
      "Validation score: 0.989636\n",
      "Iteration 11, loss = 0.03044787\n",
      "Validation score: 0.988864\n",
      "Iteration 12, loss = 0.03039670\n",
      "Validation score: 0.989364\n",
      "Iteration 13, loss = 0.02978781\n",
      "Validation score: 0.989364\n",
      "Iteration 14, loss = 0.03024525\n",
      "Validation score: 0.989227\n",
      "Iteration 15, loss = 0.02917336\n",
      "Validation score: 0.989545\n",
      "Iteration 16, loss = 0.02930624\n",
      "Validation score: 0.989636\n",
      "Iteration 17, loss = 0.02875342\n",
      "Validation score: 0.989500\n",
      "Iteration 18, loss = 0.02861743\n",
      "Validation score: 0.988864\n",
      "Iteration 19, loss = 0.02925013\n",
      "Validation score: 0.989500\n",
      "Iteration 20, loss = 0.02861537\n",
      "Validation score: 0.989045\n",
      "Iteration 21, loss = 0.02795077\n",
      "Validation score: 0.989500\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "The MAP score on test set: 0.2385\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier( verbose=True, early_stopping=True).fit(data_train, target_train)\n",
    "prediction = mlp.predict_proba(data_test)\n",
    "print(\"The MAP score on test set: {:.4f}\".format(MAP_score(feature_retrieval['source_id'],target_test,prediction)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   23.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   23.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MAP score on test set: 0.7379\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(max_iter=100000, verbose=10).fit(data_train.to_numpy(), target_train.to_numpy())\n",
    "prediction = lr.predict_proba(data_test.to_numpy())\n",
    "print(\"The MAP score on test set: {:.4f}\".format(MAP_score(feature_retrieval['source_id'],target_test,prediction)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\nikla\\pycharmprojects\\crosslingual-information-retrieval\\venv\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:52:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "The MAP score on test set: 0.7169\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "model = XGBClassifier()\n",
    "model.fit(data_train.to_numpy(), target_train.to_numpy())\n",
    "\n",
    "prediction = model.predict_proba(data_test).tolist()\n",
    "print(\"The MAP score on test set: {:.4f}\".format(MAP_score(feature_retrieval['source_id'],target_test,prediction)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}