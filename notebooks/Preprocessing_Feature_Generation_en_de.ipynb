{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Preprocessing and Feature Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In this notebook we import the data, preprocess the data and create features for supervised and unsupervised cross-lingual-information retrieval models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## I. Import Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we import the English and German europarl datasets and combine them into a parallel sentence translation dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.dirname((os.path.abspath(''))))\n",
    "\n",
    "from src.data import create_data_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_data_subset(sentence_data_source_path='../data/external/europarl-v7.de-en.en',\n",
    "                   sentence_data_target_path='../data/external/europarl-v7.de-en.de',\n",
    "                   sample_size=25000,\n",
    "                   sentence_data_sampled_path=\"../data/interim/europarl_en_de.pkl\",)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## II. Preprocess data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we preprocess the parallel sentence data for the feature generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from nltk.corpus import stopwords\n",
    "from textblob import TextBlob as textblob_source\n",
    "from textblob_de import TextBlobDE as textblob_target\n",
    "import en_core_web_sm\n",
    "import de_core_news_sm\n",
    "# import it_core_news_sm\n",
    "# import pl_core_news_sm\n",
    "import time\n",
    "from src.data import PreprocessingEuroParl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "stopwords_source = stopwords.words('english')\n",
    "stopwords_target = stopwords.words('german') # German stopwords\n",
    "# stopwords_target = stopwords.words('italian') # Italian stopwords\n",
    "# stopwords_target = stopwords.words('polish') # Polish stopwords\n",
    "nlp_source = en_core_web_sm.load()\n",
    "nlp_target = de_core_news_sm.load() # German pipeline\n",
    "# nlp_target = it_core_news_sm.load() # Italian pipeline\n",
    "# nlp_target = pl_core_news_sm.load() # Polish pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_sentences = PreprocessingEuroParl(df_sampled_path=\"../data/interim/europarl_en_de.pkl\") # German\n",
    "# parallel_sentences = PreprocessingEuroParl(df_sampled_path=\"../data/interim/europarl_en_it.pkl\") # Italien\n",
    "# parallel_sentences = PreprocessingEuroParl(df_sampled_path=\"../data/interim/europarl_en_pol.pkl\") # Polnisch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_sentences.preprocess_sentences(nlp_source, nlp_target, stopwords_source, stopwords_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "parallel_sentences.extract_sentence_information(nlp_source, nlp_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_sentences.create_embedding_information(\"proc_5k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_sentences.create_embedding_information(\"proc_b_1k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_sentences.create_embedding_information(\"vecmap\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_sentences.preprocessed.to_json(\"../data/interim/preprocessed_data_en_de.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "preprocessed_data = pd.read_json(\"../data/interim/preprocessed_data_en_de.json\")\n",
    "parallel_sentences = PreprocessingEuroParl(df_sampled_path=\"../data/interim/europarl_en_de.pkl\")\n",
    "parallel_sentences.preprocessed = preprocessed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_sentences.preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_sentences.dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Create data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we create the datasets for the training of the supervised model and the data for the supervised and unsupervised retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from src.data import DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_model = 20000\n",
    "n_queries = 100\n",
    "n_retrieval = 5000\n",
    "k = 10\n",
    "sample_size_k = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "dataset = DataSet(parallel_sentences.preprocessed)\n",
    "#dataset = DataSet(preprocessed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.split_model_retrieval(n_model, n_retrieval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.create_model_index(n_model, k, sample_size_k,\n",
    "     \"sentence_embedding_tf_idf_proc_5k_source\", \"sentence_embedding_tf_idf_proc_5k_target\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.model_dataset_index.reset_index(drop=True).to_feather(\"../data/processed/dataset_model_index_en_de.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# pd.read_feather(\"../data/processed/dataset_model_index.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#dataset.create_retrieval_index(n_queries)\n",
    "\n",
    "# If your pandas version is old, use this instead\n",
    "query = pd.DataFrame({\"id_source\": dataset.retrieval_subset.iloc[:n_queries][\"id_source\"]})\n",
    "documents = pd.DataFrame({\"id_target\": dataset.retrieval_subset[\"id_target\"]})\n",
    "index = pd.MultiIndex.from_product([dataset.retrieval_subset.iloc[:n_queries][\"id_source\"], dataset.retrieval_subset[\"id_target\"]], names = [\"id_source\", \"id_target\"])\n",
    "dataset.retrieval_dataset_index = pd.DataFrame(index = index).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.retrieval_dataset_index.reset_index(drop=True).to_feather(\"../data/processed/dataset_retrieval_index_en_de.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# pd.read_feather(\"../data/processed/dataset_retrieval_index.feather\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%% md\n"
    }
   },
   "source": [
    "## IV. Create features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we create features for our model, that are sentence based and should be created before the text is preprocessed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#%autoreload 2\n",
    "from src.features import feature_generation_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# with open(r\"../data/processed/correlated_features.pkl\", \"rb\") as file:\n",
    "#    chosen_features = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generation of the training data for the supervised classifciation model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "features_model = feature_generation_class.FeatureGeneration(dataset.model_dataset_index, \n",
    "                                                             parallel_sentences.preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "features_model.create_feature_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_model.create_sentence_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_model.create_embedding_features(\"proc_5k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_model.create_embedding_features(\"proc_b_1k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_model.create_embedding_features(\"vecmap\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_model.feature_dataframe.reset_index(drop=True).to_feather(\"../data/processed/feature_model_en_de.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# pd.read_feather(\"../data/processed/feature_model.feather\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generation of the data for the crosslingual information retrieval task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_retrieval = feature_generation_class.FeatureGeneration(dataset.retrieval_dataset_index, \n",
    "                                                            parallel_sentences.preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_retrieval.create_feature_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_retrieval.create_sentence_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_retrieval.create_embedding_features(\"proc_5k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_retrieval.create_embedding_features(\"proc_b_1k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_retrieval.create_embedding_features(\"vecmap\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_retrieval.feature_dataframe.reset_index(drop=True).to_feather(\"../data/processed/feature_retrieval_en_de.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.read_feather(\"../data/processed/feature_retrieval_en_de_testset.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
