{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Supervised Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In this notebook we use the supervised classification model for a supervised crosslingual information retrieval task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, log_loss\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import RFECV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## I. Import Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we import the feature dataframe for the retrieval task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_dataframe=pd.read_json(\"../data/processed/feature_dataframe.json\")\n",
    "feature_retrieval=pd.read_json(\"../data/processed/feature_retrieval_reduced.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_id</th>\n",
       "      <th>target_id</th>\n",
       "      <th>number_punctuations_total_difference</th>\n",
       "      <th>number_punctuations_total_difference_relative</th>\n",
       "      <th>number_punctuations_total_difference_normalized</th>\n",
       "      <th>number_words_difference</th>\n",
       "      <th>number_words_difference_relative</th>\n",
       "      <th>number_!_difference</th>\n",
       "      <th>number_!_difference_relative</th>\n",
       "      <th>number_!_difference_normalized</th>\n",
       "      <th>...</th>\n",
       "      <th>pca_embeddding_average_diff_2</th>\n",
       "      <th>pca_embeddding_tf_idf_diff_2</th>\n",
       "      <th>pca_embeddding_average_diff_3</th>\n",
       "      <th>pca_embeddding_average_diff_4</th>\n",
       "      <th>pca_embeddding_average_diff_5</th>\n",
       "      <th>pca_embeddding_average_diff_6</th>\n",
       "      <th>pca_embeddding_average_diff_7</th>\n",
       "      <th>pca_embeddding_average_diff_8</th>\n",
       "      <th>pca_embeddding_average_diff_9</th>\n",
       "      <th>Translation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41255</th>\n",
       "      <td>2125</td>\n",
       "      <td>12982</td>\n",
       "      <td>4</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.060606</td>\n",
       "      <td>7</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002556</td>\n",
       "      <td>-0.003820</td>\n",
       "      <td>0.026419</td>\n",
       "      <td>-0.070108</td>\n",
       "      <td>-0.149395</td>\n",
       "      <td>-0.018912</td>\n",
       "      <td>-0.021365</td>\n",
       "      <td>0.080145</td>\n",
       "      <td>0.004029</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197200</th>\n",
       "      <td>17720</td>\n",
       "      <td>17676</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>0.114035</td>\n",
       "      <td>8</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.023285</td>\n",
       "      <td>0.006690</td>\n",
       "      <td>0.105190</td>\n",
       "      <td>-0.097305</td>\n",
       "      <td>-0.077884</td>\n",
       "      <td>-0.043635</td>\n",
       "      <td>-0.029408</td>\n",
       "      <td>0.073068</td>\n",
       "      <td>0.022291</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136979</th>\n",
       "      <td>11697</td>\n",
       "      <td>3888</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.076923</td>\n",
       "      <td>3</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.076853</td>\n",
       "      <td>-0.019355</td>\n",
       "      <td>-0.012643</td>\n",
       "      <td>-0.072363</td>\n",
       "      <td>-0.118291</td>\n",
       "      <td>-0.101588</td>\n",
       "      <td>0.037155</td>\n",
       "      <td>0.041971</td>\n",
       "      <td>-0.072246</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144434</th>\n",
       "      <td>12443</td>\n",
       "      <td>4544</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>1</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.068608</td>\n",
       "      <td>-0.019808</td>\n",
       "      <td>0.079789</td>\n",
       "      <td>-0.067451</td>\n",
       "      <td>-0.050441</td>\n",
       "      <td>-0.041185</td>\n",
       "      <td>-0.055180</td>\n",
       "      <td>0.056033</td>\n",
       "      <td>-0.049097</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198556</th>\n",
       "      <td>17855</td>\n",
       "      <td>12905</td>\n",
       "      <td>2</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.089286</td>\n",
       "      <td>-6</td>\n",
       "      <td>-0.214286</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.041669</td>\n",
       "      <td>-0.009074</td>\n",
       "      <td>0.080245</td>\n",
       "      <td>-0.024273</td>\n",
       "      <td>-0.121719</td>\n",
       "      <td>-0.066690</td>\n",
       "      <td>0.070969</td>\n",
       "      <td>0.026449</td>\n",
       "      <td>-0.062150</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>869</td>\n",
       "      <td>869</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.011111</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.111111</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.048272</td>\n",
       "      <td>-0.014800</td>\n",
       "      <td>-0.025744</td>\n",
       "      <td>-0.028717</td>\n",
       "      <td>-0.127420</td>\n",
       "      <td>-0.226481</td>\n",
       "      <td>0.072937</td>\n",
       "      <td>0.083777</td>\n",
       "      <td>-0.144790</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167865</th>\n",
       "      <td>14786</td>\n",
       "      <td>9390</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.206897</td>\n",
       "      <td>6</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.042361</td>\n",
       "      <td>-0.006038</td>\n",
       "      <td>0.073134</td>\n",
       "      <td>-0.029651</td>\n",
       "      <td>-0.077821</td>\n",
       "      <td>-0.008269</td>\n",
       "      <td>-0.008337</td>\n",
       "      <td>0.076887</td>\n",
       "      <td>-0.018930</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167701</th>\n",
       "      <td>14770</td>\n",
       "      <td>426</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.190476</td>\n",
       "      <td>1</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.047286</td>\n",
       "      <td>-0.010079</td>\n",
       "      <td>0.042496</td>\n",
       "      <td>-0.011377</td>\n",
       "      <td>-0.078073</td>\n",
       "      <td>-0.019256</td>\n",
       "      <td>-0.043349</td>\n",
       "      <td>0.032975</td>\n",
       "      <td>0.014765</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6242</th>\n",
       "      <td>6242</td>\n",
       "      <td>6242</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.032353</td>\n",
       "      <td>2</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.035501</td>\n",
       "      <td>-0.007600</td>\n",
       "      <td>0.077813</td>\n",
       "      <td>-0.086015</td>\n",
       "      <td>-0.043991</td>\n",
       "      <td>-0.001368</td>\n",
       "      <td>0.003086</td>\n",
       "      <td>0.074925</td>\n",
       "      <td>0.023217</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118768</th>\n",
       "      <td>9876</td>\n",
       "      <td>6905</td>\n",
       "      <td>-5</td>\n",
       "      <td>-0.833333</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>-9</td>\n",
       "      <td>-0.409091</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.072495</td>\n",
       "      <td>-0.019596</td>\n",
       "      <td>-0.013571</td>\n",
       "      <td>-0.092600</td>\n",
       "      <td>-0.136426</td>\n",
       "      <td>-0.075928</td>\n",
       "      <td>-0.084343</td>\n",
       "      <td>0.054816</td>\n",
       "      <td>-0.031043</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>220000 rows × 125 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        source_id  target_id  number_punctuations_total_difference  \\\n",
       "41255        2125      12982                                     4   \n",
       "197200      17720      17676                                    -1   \n",
       "136979      11697       3888                                     1   \n",
       "144434      12443       4544                                    -1   \n",
       "198556      17855      12905                                     2   \n",
       "...           ...        ...                                   ...   \n",
       "869           869        869                                     0   \n",
       "167865      14786       9390                                     6   \n",
       "167701      14770        426                                     4   \n",
       "6242         6242       6242                                     1   \n",
       "118768       9876       6905                                    -5   \n",
       "\n",
       "        number_punctuations_total_difference_relative  \\\n",
       "41255                                        1.000000   \n",
       "197200                                      -0.500000   \n",
       "136979                                       0.000000   \n",
       "144434                                      -0.500000   \n",
       "198556                                       0.500000   \n",
       "...                                               ...   \n",
       "869                                          0.000000   \n",
       "167865                                       0.000000   \n",
       "167701                                       0.000000   \n",
       "6242                                         0.500000   \n",
       "118768                                      -0.833333   \n",
       "\n",
       "        number_punctuations_total_difference_normalized  \\\n",
       "41255                                         -0.060606   \n",
       "197200                                         0.114035   \n",
       "136979                                        -0.076923   \n",
       "144434                                         0.071429   \n",
       "198556                                        -0.089286   \n",
       "...                                                 ...   \n",
       "869                                           -0.011111   \n",
       "167865                                        -0.206897   \n",
       "167701                                        -0.190476   \n",
       "6242                                          -0.032353   \n",
       "118768                                         0.142857   \n",
       "\n",
       "        number_words_difference  number_words_difference_relative  \\\n",
       "41255                         7                          0.388889   \n",
       "197200                        8                          0.800000   \n",
       "136979                        3                          0.333333   \n",
       "144434                        1                          0.083333   \n",
       "198556                       -6                         -0.214286   \n",
       "...                         ...                               ...   \n",
       "869                          -1                         -0.111111   \n",
       "167865                        6                          0.352941   \n",
       "167701                        1                          0.062500   \n",
       "6242                          2                          0.133333   \n",
       "118768                       -9                         -0.409091   \n",
       "\n",
       "        number_!_difference  number_!_difference_relative  \\\n",
       "41255                     0                             0   \n",
       "197200                    0                             0   \n",
       "136979                    0                             0   \n",
       "144434                    0                             0   \n",
       "198556                    0                             0   \n",
       "...                     ...                           ...   \n",
       "869                       0                             0   \n",
       "167865                    0                             0   \n",
       "167701                    0                             0   \n",
       "6242                      0                             0   \n",
       "118768                    0                             0   \n",
       "\n",
       "        number_!_difference_normalized  ...  pca_embeddding_average_diff_2  \\\n",
       "41255                              0.0  ...                      -0.002556   \n",
       "197200                             0.0  ...                      -0.023285   \n",
       "136979                             0.0  ...                      -0.076853   \n",
       "144434                             0.0  ...                      -0.068608   \n",
       "198556                             0.0  ...                      -0.041669   \n",
       "...                                ...  ...                            ...   \n",
       "869                                0.0  ...                      -0.048272   \n",
       "167865                             0.0  ...                      -0.042361   \n",
       "167701                             0.0  ...                      -0.047286   \n",
       "6242                               0.0  ...                      -0.035501   \n",
       "118768                             0.0  ...                      -0.072495   \n",
       "\n",
       "        pca_embeddding_tf_idf_diff_2  pca_embeddding_average_diff_3  \\\n",
       "41255                      -0.003820                       0.026419   \n",
       "197200                      0.006690                       0.105190   \n",
       "136979                     -0.019355                      -0.012643   \n",
       "144434                     -0.019808                       0.079789   \n",
       "198556                     -0.009074                       0.080245   \n",
       "...                              ...                            ...   \n",
       "869                        -0.014800                      -0.025744   \n",
       "167865                     -0.006038                       0.073134   \n",
       "167701                     -0.010079                       0.042496   \n",
       "6242                       -0.007600                       0.077813   \n",
       "118768                     -0.019596                      -0.013571   \n",
       "\n",
       "        pca_embeddding_average_diff_4  pca_embeddding_average_diff_5  \\\n",
       "41255                       -0.070108                      -0.149395   \n",
       "197200                      -0.097305                      -0.077884   \n",
       "136979                      -0.072363                      -0.118291   \n",
       "144434                      -0.067451                      -0.050441   \n",
       "198556                      -0.024273                      -0.121719   \n",
       "...                               ...                            ...   \n",
       "869                         -0.028717                      -0.127420   \n",
       "167865                      -0.029651                      -0.077821   \n",
       "167701                      -0.011377                      -0.078073   \n",
       "6242                        -0.086015                      -0.043991   \n",
       "118768                      -0.092600                      -0.136426   \n",
       "\n",
       "        pca_embeddding_average_diff_6  pca_embeddding_average_diff_7  \\\n",
       "41255                       -0.018912                      -0.021365   \n",
       "197200                      -0.043635                      -0.029408   \n",
       "136979                      -0.101588                       0.037155   \n",
       "144434                      -0.041185                      -0.055180   \n",
       "198556                      -0.066690                       0.070969   \n",
       "...                               ...                            ...   \n",
       "869                         -0.226481                       0.072937   \n",
       "167865                      -0.008269                      -0.008337   \n",
       "167701                      -0.019256                      -0.043349   \n",
       "6242                        -0.001368                       0.003086   \n",
       "118768                      -0.075928                      -0.084343   \n",
       "\n",
       "        pca_embeddding_average_diff_8  pca_embeddding_average_diff_9  \\\n",
       "41255                        0.080145                       0.004029   \n",
       "197200                       0.073068                       0.022291   \n",
       "136979                       0.041971                      -0.072246   \n",
       "144434                       0.056033                      -0.049097   \n",
       "198556                       0.026449                      -0.062150   \n",
       "...                               ...                            ...   \n",
       "869                          0.083777                      -0.144790   \n",
       "167865                       0.076887                      -0.018930   \n",
       "167701                       0.032975                       0.014765   \n",
       "6242                         0.074925                       0.023217   \n",
       "118768                       0.054816                      -0.031043   \n",
       "\n",
       "        Translation  \n",
       "41255             0  \n",
       "197200            0  \n",
       "136979            0  \n",
       "144434            0  \n",
       "198556            0  \n",
       "...             ...  \n",
       "869               1  \n",
       "167865            0  \n",
       "167701            0  \n",
       "6242              1  \n",
       "118768            0  \n",
       "\n",
       "[220000 rows x 125 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_dataframe=feature_dataframe.sample(frac=1)\n",
    "feature_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_id</th>\n",
       "      <th>target_id</th>\n",
       "      <th>number_punctuations_total_difference</th>\n",
       "      <th>number_punctuations_total_difference_relative</th>\n",
       "      <th>number_punctuations_total_difference_normalized</th>\n",
       "      <th>number_words_difference</th>\n",
       "      <th>number_words_difference_relative</th>\n",
       "      <th>number_!_difference</th>\n",
       "      <th>number_!_difference_relative</th>\n",
       "      <th>number_!_difference_normalized</th>\n",
       "      <th>...</th>\n",
       "      <th>pca_embeddding_average_diff_2</th>\n",
       "      <th>pca_embeddding_tf_idf_diff_2</th>\n",
       "      <th>pca_embeddding_average_diff_3</th>\n",
       "      <th>pca_embeddding_average_diff_4</th>\n",
       "      <th>pca_embeddding_average_diff_5</th>\n",
       "      <th>pca_embeddding_average_diff_6</th>\n",
       "      <th>pca_embeddding_average_diff_7</th>\n",
       "      <th>pca_embeddding_average_diff_8</th>\n",
       "      <th>pca_embeddding_average_diff_9</th>\n",
       "      <th>Translation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20000</td>\n",
       "      <td>20000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>-0.053913</td>\n",
       "      <td>-3</td>\n",
       "      <td>-0.136364</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20000</td>\n",
       "      <td>20001</td>\n",
       "      <td>1</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>-0.130000</td>\n",
       "      <td>-10</td>\n",
       "      <td>-0.454545</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20000</td>\n",
       "      <td>20002</td>\n",
       "      <td>-3</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>-19</td>\n",
       "      <td>-0.863636</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20000</td>\n",
       "      <td>20003</td>\n",
       "      <td>-3</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>-18</td>\n",
       "      <td>-0.818182</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20000</td>\n",
       "      <td>20004</td>\n",
       "      <td>-2</td>\n",
       "      <td>-0.666667</td>\n",
       "      <td>-0.005000</td>\n",
       "      <td>-15</td>\n",
       "      <td>-0.681818</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499995</th>\n",
       "      <td>20099</td>\n",
       "      <td>24995</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.137931</td>\n",
       "      <td>19</td>\n",
       "      <td>3.166667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499996</th>\n",
       "      <td>20099</td>\n",
       "      <td>24996</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.176471</td>\n",
       "      <td>8</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499997</th>\n",
       "      <td>20099</td>\n",
       "      <td>24997</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.125000</td>\n",
       "      <td>8</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499998</th>\n",
       "      <td>20099</td>\n",
       "      <td>24998</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.093750</td>\n",
       "      <td>23</td>\n",
       "      <td>3.833333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499999</th>\n",
       "      <td>20099</td>\n",
       "      <td>24999</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.250000</td>\n",
       "      <td>-3</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500000 rows × 125 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        source_id  target_id  number_punctuations_total_difference  \\\n",
       "0           20000      20000                                     1   \n",
       "1           20000      20001                                     1   \n",
       "2           20000      20002                                    -3   \n",
       "3           20000      20003                                    -3   \n",
       "4           20000      20004                                    -2   \n",
       "...           ...        ...                                   ...   \n",
       "499995      20099      24995                                     4   \n",
       "499996      20099      24996                                     3   \n",
       "499997      20099      24997                                     2   \n",
       "499998      20099      24998                                     3   \n",
       "499999      20099      24999                                     1   \n",
       "\n",
       "        number_punctuations_total_difference_relative  \\\n",
       "0                                            0.333333   \n",
       "1                                            0.333333   \n",
       "2                                           -1.000000   \n",
       "3                                           -1.000000   \n",
       "4                                           -0.666667   \n",
       "...                                               ...   \n",
       "499995                                       0.000000   \n",
       "499996                                       0.000000   \n",
       "499997                                       0.000000   \n",
       "499998                                       0.000000   \n",
       "499999                                       0.000000   \n",
       "\n",
       "        number_punctuations_total_difference_normalized  \\\n",
       "0                                             -0.053913   \n",
       "1                                             -0.130000   \n",
       "2                                              0.120000   \n",
       "3                                              0.120000   \n",
       "4                                             -0.005000   \n",
       "...                                                 ...   \n",
       "499995                                        -0.137931   \n",
       "499996                                        -0.176471   \n",
       "499997                                        -0.125000   \n",
       "499998                                        -0.093750   \n",
       "499999                                        -0.250000   \n",
       "\n",
       "        number_words_difference  number_words_difference_relative  \\\n",
       "0                            -3                         -0.136364   \n",
       "1                           -10                         -0.454545   \n",
       "2                           -19                         -0.863636   \n",
       "3                           -18                         -0.818182   \n",
       "4                           -15                         -0.681818   \n",
       "...                         ...                               ...   \n",
       "499995                       19                          3.166667   \n",
       "499996                        8                          1.333333   \n",
       "499997                        8                          1.333333   \n",
       "499998                       23                          3.833333   \n",
       "499999                       -3                         -0.500000   \n",
       "\n",
       "        number_!_difference  number_!_difference_relative  \\\n",
       "0                         0                             0   \n",
       "1                         0                             0   \n",
       "2                         0                             0   \n",
       "3                         0                             0   \n",
       "4                         0                             0   \n",
       "...                     ...                           ...   \n",
       "499995                    0                             0   \n",
       "499996                    0                             0   \n",
       "499997                    0                             0   \n",
       "499998                    0                             0   \n",
       "499999                    0                             0   \n",
       "\n",
       "        number_!_difference_normalized  ...  pca_embeddding_average_diff_2  \\\n",
       "0                                  0.0  ...                              0   \n",
       "1                                  0.0  ...                              0   \n",
       "2                                  0.0  ...                              0   \n",
       "3                                  0.0  ...                              0   \n",
       "4                                  0.0  ...                              0   \n",
       "...                                ...  ...                            ...   \n",
       "499995                             0.0  ...                              0   \n",
       "499996                             0.0  ...                              0   \n",
       "499997                             0.0  ...                              0   \n",
       "499998                             0.0  ...                              0   \n",
       "499999                             0.0  ...                              0   \n",
       "\n",
       "        pca_embeddding_tf_idf_diff_2  pca_embeddding_average_diff_3  \\\n",
       "0                                  0                              0   \n",
       "1                                  0                              0   \n",
       "2                                  0                              0   \n",
       "3                                  0                              0   \n",
       "4                                  0                              0   \n",
       "...                              ...                            ...   \n",
       "499995                             0                              0   \n",
       "499996                             0                              0   \n",
       "499997                             0                              0   \n",
       "499998                             0                              0   \n",
       "499999                             0                              0   \n",
       "\n",
       "        pca_embeddding_average_diff_4  pca_embeddding_average_diff_5  \\\n",
       "0                                   0                              0   \n",
       "1                                   0                              0   \n",
       "2                                   0                              0   \n",
       "3                                   0                              0   \n",
       "4                                   0                              0   \n",
       "...                               ...                            ...   \n",
       "499995                              0                              0   \n",
       "499996                              0                              0   \n",
       "499997                              0                              0   \n",
       "499998                              0                              0   \n",
       "499999                              0                              0   \n",
       "\n",
       "        pca_embeddding_average_diff_6  pca_embeddding_average_diff_7  \\\n",
       "0                                   0                              0   \n",
       "1                                   0                              0   \n",
       "2                                   0                              0   \n",
       "3                                   0                              0   \n",
       "4                                   0                              0   \n",
       "...                               ...                            ...   \n",
       "499995                              0                              0   \n",
       "499996                              0                              0   \n",
       "499997                              0                              0   \n",
       "499998                              0                              0   \n",
       "499999                              0                              0   \n",
       "\n",
       "        pca_embeddding_average_diff_8  pca_embeddding_average_diff_9  \\\n",
       "0                                   0                              0   \n",
       "1                                   0                              0   \n",
       "2                                   0                              0   \n",
       "3                                   0                              0   \n",
       "4                                   0                              0   \n",
       "...                               ...                            ...   \n",
       "499995                              0                              0   \n",
       "499996                              0                              0   \n",
       "499997                              0                              0   \n",
       "499998                              0                              0   \n",
       "499999                              0                              0   \n",
       "\n",
       "        Translation  \n",
       "0                 1  \n",
       "1                 0  \n",
       "2                 0  \n",
       "3                 0  \n",
       "4                 0  \n",
       "...             ...  \n",
       "499995            0  \n",
       "499996            0  \n",
       "499997            0  \n",
       "499998            0  \n",
       "499999            0  \n",
       "\n",
       "[500000 rows x 125 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Supervised Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First iteration after dropping correlated features from analyes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'characters_avg_difference_relative',\n",
       " 'cosine_similarity_tf_idf',\n",
       " 'euclidean_distance_tf_idf',\n",
       " 'jaccard_translation_target',\n",
       " 'number_#_difference_normalized',\n",
       " 'number_#_difference_relative',\n",
       " 'number_$_difference_normalized',\n",
       " 'number_$_difference_relative',\n",
       " 'number_%_difference_normalized',\n",
       " 'number_&_difference_normalized',\n",
       " \"number_'_difference_normalized\",\n",
       " \"number_'_difference_relative\",\n",
       " 'number_)_difference',\n",
       " 'number_)_difference_normalized',\n",
       " 'number_)_difference_relative',\n",
       " 'number_+_difference_normalized',\n",
       " 'number_+_difference_relative',\n",
       " 'number_,_difference',\n",
       " 'number_,_difference_relative',\n",
       " 'number_-_difference_normalized',\n",
       " 'number_._difference_relative',\n",
       " 'number_/_difference_normalized',\n",
       " 'number_NOUN_difference',\n",
       " 'number_[_difference_normalized',\n",
       " 'number_[_difference_relative',\n",
       " 'number_]_difference',\n",
       " 'number_]_difference_normalized',\n",
       " 'number_]_difference_relative',\n",
       " 'number_characters_difference',\n",
       " 'number_characters_difference_relative',\n",
       " 'number_stopwords_difference',\n",
       " 'number_unique_words_difference',\n",
       " 'number_unique_words_difference_normalized',\n",
       " 'number_unique_words_difference_relative',\n",
       " 'number_words_difference_normalized',\n",
       " 'pca_embeddding_tf_idf_diff_1',\n",
       " 'pca_embeddding_tf_idf_diff_3',\n",
       " 'pca_embeddding_tf_idf_diff_4',\n",
       " 'pca_embeddding_tf_idf_diff_5',\n",
       " 'pca_embeddding_tf_idf_diff_6',\n",
       " 'pca_embeddding_tf_idf_diff_7',\n",
       " 'pca_embeddding_tf_idf_diff_8',\n",
       " 'pca_embeddding_tf_idf_diff_9'}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle \n",
    "file = open(\"../data/processed/correlated_features.pkl\",'rb')\n",
    "correlated_features = pickle.load(file)\n",
    "file.close()\n",
    "correlated_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'[\\'jaccard_translation_target\\' \\'number_._difference_relative\\'\\n \\'characters_avg_difference_relative\\' \\'number_%_difference_normalized\\'\\n \\'number_[_difference_relative\\' \\'pca_embeddding_tf_idf_diff_3\\'\\n \\'number_,_difference\\' \\'pca_embeddding_tf_idf_diff_4\\'\\n \"number_\\'_difference_relative\" \\'number_words_difference_normalized\\'\\n \\'number_)_difference_normalized\\' \\'number_]_difference_relative\\'\\n \\'number_/_difference_normalized\\' \\'pca_embeddding_tf_idf_diff_8\\'\\n \"number_\\'_difference_normalized\" \\'number_+_difference_relative\\'\\n \\'number_[_difference_normalized\\' \\'number_stopwords_difference\\'\\n \\'pca_embeddding_tf_idf_diff_7\\' \\'pca_embeddding_tf_idf_diff_9\\'\\n \\'number_,_difference_relative\\' \\'number_characters_difference_relative\\'\\n \\'number_#_difference_normalized\\' \\'number_-_difference_normalized\\'\\n \\'number_characters_difference\\'\\n \\'number_unique_words_difference_normalized\\'\\n \\'number_unique_words_difference_relative\\' \\'cosine_similarity_tf_idf\\'\\n \\'number_)_difference\\' \\'number_#_difference_relative\\'\\n \\'number_unique_words_difference\\' \\'pca_embeddding_tf_idf_diff_5\\'\\n \\'pca_embeddding_tf_idf_diff_6\\' \\'number_&_difference_normalized\\'\\n \\'number_$_difference_relative\\' \\'number_+_difference_normalized\\'\\n \\'number_]_difference\\' \\'number_$_difference_normalized\\'\\n \\'euclidean_distance_tf_idf\\' \\'number_)_difference_relative\\'\\n \\'pca_embeddding_tf_idf_diff_1\\' \\'number_]_difference_normalized\\'\\n \\'number_NOUN_difference\\'] not found in axis'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-ea8e0424ceb4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfeature_dataframe\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeature_dataframe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcorrelated_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mfeature_dataframe\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\nikla\\pycharmprojects\\crosslingual-information-retrieval\\venv\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4306\u001b[0m                 \u001b[0mweight\u001b[0m  \u001b[1;36m1.0\u001b[0m     \u001b[1;36m0.8\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4307\u001b[0m         \"\"\"\n\u001b[1;32m-> 4308\u001b[1;33m         return super().drop(\n\u001b[0m\u001b[0;32m   4309\u001b[0m             \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4310\u001b[0m             \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\nikla\\pycharmprojects\\crosslingual-information-retrieval\\venv\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4151\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4152\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4153\u001b[1;33m                 \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4154\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4155\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\nikla\\pycharmprojects\\crosslingual-information-retrieval\\venv\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[1;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[0;32m   4186\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4187\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4188\u001b[1;33m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4189\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\nikla\\pycharmprojects\\crosslingual-information-retrieval\\venv\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   5589\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5590\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5591\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{labels[mask]} not found in axis\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5592\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5593\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: '[\\'jaccard_translation_target\\' \\'number_._difference_relative\\'\\n \\'characters_avg_difference_relative\\' \\'number_%_difference_normalized\\'\\n \\'number_[_difference_relative\\' \\'pca_embeddding_tf_idf_diff_3\\'\\n \\'number_,_difference\\' \\'pca_embeddding_tf_idf_diff_4\\'\\n \"number_\\'_difference_relative\" \\'number_words_difference_normalized\\'\\n \\'number_)_difference_normalized\\' \\'number_]_difference_relative\\'\\n \\'number_/_difference_normalized\\' \\'pca_embeddding_tf_idf_diff_8\\'\\n \"number_\\'_difference_normalized\" \\'number_+_difference_relative\\'\\n \\'number_[_difference_normalized\\' \\'number_stopwords_difference\\'\\n \\'pca_embeddding_tf_idf_diff_7\\' \\'pca_embeddding_tf_idf_diff_9\\'\\n \\'number_,_difference_relative\\' \\'number_characters_difference_relative\\'\\n \\'number_#_difference_normalized\\' \\'number_-_difference_normalized\\'\\n \\'number_characters_difference\\'\\n \\'number_unique_words_difference_normalized\\'\\n \\'number_unique_words_difference_relative\\' \\'cosine_similarity_tf_idf\\'\\n \\'number_)_difference\\' \\'number_#_difference_relative\\'\\n \\'number_unique_words_difference\\' \\'pca_embeddding_tf_idf_diff_5\\'\\n \\'pca_embeddding_tf_idf_diff_6\\' \\'number_&_difference_normalized\\'\\n \\'number_$_difference_relative\\' \\'number_+_difference_normalized\\'\\n \\'number_]_difference\\' \\'number_$_difference_normalized\\'\\n \\'euclidean_distance_tf_idf\\' \\'number_)_difference_relative\\'\\n \\'pca_embeddding_tf_idf_diff_1\\' \\'number_]_difference_normalized\\'\\n \\'number_NOUN_difference\\'] not found in axis'"
     ]
    }
   ],
   "source": [
    "feature_dataframe=feature_dataframe.drop(columns=correlated_features)\n",
    "feature_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['word_mover_distance'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-46-8bb4bfbe96b1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfeature_dataframe\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeature_dataframe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'word_mover_distance'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\nikla\\pycharmprojects\\crosslingual-information-retrieval\\venv\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4306\u001b[0m                 \u001b[0mweight\u001b[0m  \u001b[1;36m1.0\u001b[0m     \u001b[1;36m0.8\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4307\u001b[0m         \"\"\"\n\u001b[1;32m-> 4308\u001b[1;33m         return super().drop(\n\u001b[0m\u001b[0;32m   4309\u001b[0m             \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4310\u001b[0m             \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\nikla\\pycharmprojects\\crosslingual-information-retrieval\\venv\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4151\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4152\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4153\u001b[1;33m                 \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4154\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4155\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\nikla\\pycharmprojects\\crosslingual-information-retrieval\\venv\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[1;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[0;32m   4186\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4187\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4188\u001b[1;33m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4189\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\nikla\\pycharmprojects\\crosslingual-information-retrieval\\venv\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   5589\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5590\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5591\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{labels[mask]} not found in axis\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5592\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5593\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['word_mover_distance'] not found in axis\""
     ]
    }
   ],
   "source": [
    "feature_dataframe=feature_dataframe.drop(columns=['word_mover_distance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([], dtype='object')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_dataframe.columns.difference(feature_retrieval.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### drop the target label and the indexes for training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_train=feature_dataframe['Translation'].astype(float)\n",
    "data_train=feature_dataframe.drop(columns=['Translation','source_id','target_id'])\n",
    "target_test=feature_retrieval['Translation'].astype(float)\n",
    "data_test=feature_retrieval.drop(columns=['Translation','source_id','target_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #scale data into [0,1]\n",
    "# scaler = preprocessing.MinMaxScaler()\n",
    "# data_train[data_train.columns] = scaler.fit_transform(data_train[data_train.columns])\n",
    "# data_test[data_test.columns] = scaler.fit_transform(data_test[data_test.columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\nikla\\pycharmprojects\\crosslingual-information-retrieval\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy on test set: 0.9998\n",
      "The F1-Score on test set: 0.0000\n",
      "The Precision-Score on test set: 0.0000\n",
      "The Recall-Score on test set: 0.0000\n",
      "The Los_loss on test set: 0.0069\n"
     ]
    }
   ],
   "source": [
    "nb = GaussianNB().fit(data_train, target_train)\n",
    "prediction = nb.predict(data_test)\n",
    "acc = accuracy_score(target_test,prediction) \n",
    "f1= f1_score(target_test,prediction) \n",
    "pr= precision_score(target_test,prediction) \n",
    "re= recall_score(target_test,prediction)\n",
    "ll=log_loss(target_test,prediction)\n",
    "print(\"The Accuracy on test set: {:.4f}\".format(acc))\n",
    "print(\"The F1-Score on test set: {:.4f}\".format(f1))\n",
    "print(\"The Precision-Score on test set: {:.4f}\".format(pr))\n",
    "print(\"The Recall-Score on test set: {:.4f}\".format(re))\n",
    "print(\"The Los_loss on test set: {:.4f}\".format(ll))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         1.0\n",
       "1         0.0\n",
       "2         0.0\n",
       "3         0.0\n",
       "4         0.0\n",
       "         ... \n",
       "499995    0.0\n",
       "499996    0.0\n",
       "499997    0.0\n",
       "499998    0.0\n",
       "499999    0.0\n",
       "Name: Translation, Length: 500000, dtype: float64"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy on test set: 0.9812\n",
      "The F1-Score on test set: 0.0163\n",
      "The Precision-Score on test set: 0.0083\n",
      "The Recall-Score on test set: 0.7800\n",
      "The Los_loss on test set: 0.6487\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier().fit(data_train, target_train)\n",
    "prediction = mlp.predict(data_test)\n",
    "acc = accuracy_score(target_test,prediction) \n",
    "f1= f1_score(target_test,prediction) \n",
    "pr= precision_score(target_test,prediction) \n",
    "re= recall_score(target_test,prediction) \n",
    "ll=log_loss(target_test,prediction)\n",
    "print(\"The Accuracy on test set: {:.4f}\".format(acc))\n",
    "print(\"The F1-Score on test set: {:.4f}\".format(f1))\n",
    "print(\"The Precision-Score on test set: {:.4f}\".format(pr))\n",
    "print(\"The Recall-Score on test set: {:.4f}\".format(re))\n",
    "print(\"The Los_loss on test set: {:.4f}\".format(ll))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9446.0"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy on test set: 0.6879\n",
      "The F1-Score on test set: 0.0005\n",
      "The Precision-Score on test set: 0.0002\n",
      "The Recall-Score on test set: 0.3900\n",
      "The Los_loss on test set: 10.7807\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(max_iter=10000).fit(data_train, target_train)\n",
    "prediction = lr.predict(data_test)\n",
    "acc = accuracy_score(target_test,prediction) \n",
    "f1= f1_score(target_test,prediction) \n",
    "pr= precision_score(target_test,prediction) \n",
    "re= recall_score(target_test,prediction) \n",
    "ll=log_loss(target_test,prediction)\n",
    "print(\"The Accuracy on test set: {:.4f}\".format(acc))\n",
    "print(\"The F1-Score on test set: {:.4f}\".format(f1))\n",
    "print(\"The Precision-Score on test set: {:.4f}\".format(pr))\n",
    "print(\"The Recall-Score on test set: {:.4f}\".format(re))\n",
    "print(\"The Los_loss on test set: {:.4f}\".format(ll))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[343898, 156002],\n",
       "       [    61,     39]], dtype=int64)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(target_test,prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0., ..., 0., 0., 1.])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(max_iter=10000).fit(data_train, target_train)\n",
    "prediction = lr.predict_proba(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
