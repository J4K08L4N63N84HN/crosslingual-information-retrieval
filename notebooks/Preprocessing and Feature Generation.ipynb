{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Preprocessing and Feature Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In this notebook we import the data, preprocess the data and create features for supervised and unsupervised cross-lingual-information retrieval models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## I. Import Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we import the English and German europarl datasets and combine them into a parallel sentence translation dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.preprocessing_class import PreprocessingEuroParl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_sentences = PreprocessingEuroParl(sentence_data_source='../data/external/europarl-v7.de-en.en',\n",
    "                 sentence_data_target='../data/external/europarl-v7.de-en.de',number_datapoints=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "parallel_sentences.dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #duc dataset\n",
    "# parallel_sentences.dataframe['Translation']=1\n",
    "# wrong= PreprocessingEuroParl(sentence_data_source='../data/external/europarl-v7.de-en.en',\n",
    "#                  sentence_data_target='../data/external/europarl-v7.de-en.de',number_datapoints=10000)\n",
    "# import pandas as pd\n",
    "# wrong_data=pd.concat([wrong.dataframe.drop(columns='text_target').reset_index(drop=True),wrong.dataframe['text_target'].sample(frac=1).reset_index(drop=True)],axis=1)\n",
    "# wrong_data['Translation']=0\n",
    "# data=pd.concat([parallel_sentences.dataframe.reset_index(drop=True),wrong_data.reset_index(drop=True)])\n",
    "# import pickle \n",
    "# filehandler = open('../data/processed/dataset_duc.pkl', 'wb') \n",
    "# pickle.dump(data, filehandler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## II. Preprocess data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we preprocess the parallel sentence data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "from nltk.corpus import stopwords\n",
    "from textblob import TextBlob as textblob_source\n",
    "from textblob_de import TextBlobDE as textblob_target\n",
    "import en_core_web_sm\n",
    "import de_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "stopwords_source = stopwords.words('english')\n",
    "stopwords_target = stopwords.words('german')\n",
    "nlp_source = en_core_web_sm.load()\n",
    "nlp_target = de_core_news_sm.load()\n",
    "embedding_matrix_source = \"../data/interim/proc_b_src_emb.p\"\n",
    "embedding_dictionary_source =  \"../data/interim/proc_b_src_word.p\"\n",
    "embedding_matrix_target = \"../data/interim/proc_b_trg_emb.p\"\n",
    "embedding_dictionary_target =  \"../data/interim/proc_b_trg_word.p\"\n",
    "number_translations = 1\n",
    "number_pc = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "parallel_sentences.preprocess_sentences(stopwords_source, nlp_source, textblob_source,\n",
    "                                               embedding_matrix_source, embedding_dictionary_source,\n",
    "                                                stopwords_target,nlp_target, textblob_target,\n",
    "                                               embedding_matrix_target, embedding_dictionary_target,\n",
    "                                                number_translations, number_pc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def save_object(obj, filename):\n",
    "#     with open(filename, 'wb') as output:  # Overwrites any existing file.\n",
    "#        pickle.dump(obj, output, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# sample usage\n",
    "# save_object(parallel_sentences, '../data/processed/processed_data_2505.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle \n",
    "# filehandler = open('../data/processed/processed_data_2505_2.pkl', 'wb') \n",
    "# pickle.dump(parallel_sentences, filehandler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle \n",
    "# file = open(\"../data/processed/processed_data_2505_2.pkl\",'rb')\n",
    "# df = pickle.load(file)\n",
    "# file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Create data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from src.data.dataset_class import DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "dataset = DataSet(parallel_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_training = 50\n",
    "n_test_queries = 5\n",
    "n_test_documents = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "dataset.get_sample(n_training, n_test_queries, n_test_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%% md\n"
    }
   },
   "source": [
    "## II. Create sentence based features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we create features for our model, that are sentence based and should be created before the text is preprocessed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from src.features.feature_generation_class import FeatureGeneration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "features = FeatureGeneration(dataset.dataset, number_pc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "features.feature_generation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.feature_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle \n",
    "# filehandler = open('../data/processed/processed_data.pkl', 'wb') \n",
    "# pickle.dump(features.feature_dataframe, filehandler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle \n",
    "# file = open(\"../data/processed/processed_data.pkl\",'rb')\n",
    "# df = pickle.load(file)\n",
    "# file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV. Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#look at correlation matrix\n",
    "np.cov(df, bias=True)\n",
    "corrMatrix=df.corr()\n",
    "f=plt.figure(figsize=(14,9))\n",
    "sn.heatmap(corrMatrix, annot=False)\n",
    "f.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Korrelation\n",
    "correlated_features = set()\n",
    "correlation_matrix = df.corr()\n",
    "\n",
    "for i in range(len(correlation_matrix.columns)):\n",
    "    for j in range(i):\n",
    "        if abs(correlation_matrix.iloc[i, j]) > 0.8:\n",
    "            print(f\"The following features are correlated: {correlation_matrix.columns[i]} and {correlation_matrix.columns[j]}. Correlation = {round(abs(correlation_matrix.iloc[i, j]),2)}\")\n",
    "            colname = correlation_matrix.columns[i]\n",
    "            correlated_features.add(colname)\n",
    "\n",
    "print(f\"Drop the following features: {correlated_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop correlated features, but only when looking at a big dataset\n",
    "df=df.drop(columns=correlated_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V. Train Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "target=df['Translation']\n",
    "df=df.drop(columns=['Translation'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(df.isna().any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scale data otherwise logistic regression does not converge\n",
    "from sklearn import preprocessing\n",
    "\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "df[df.columns] = scaler.fit_transform(df[df.columns])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data_train, data_test, target_train, target_test = train_test_split(\n",
    "    df,target,test_size=0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "lr = LogisticRegression(class_weight = 'balanced', max_iter=10000).fit(data_train, target_train)\n",
    "prediction = lr.predict(data_test)\n",
    "acc = accuracy_score(target_test,prediction) \n",
    "f1= f1_score(target_test,prediction) \n",
    "pr= precision_score(target_test,prediction) \n",
    "re= recall_score(target_test,prediction) \n",
    "print(\"The Accuracy on test set: {:.4f}\".format(acc))\n",
    "print(\"The F1-Score on test set: {:.4f}\".format(f1))\n",
    "print(\"The Precision-Score on test set: {:.4f}\".format(pr))\n",
    "print(\"The Recall-Score on test set: {:.4f}\".format(re))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature importance\n",
    "# get importance\n",
    "importance = lr.coef_[0]\n",
    "# summarize feature importance\n",
    "for i, v in enumerate(importance):\n",
    "    print(f'Feature: {i} {data_train.columns[i]}, Score: {v}')\n",
    "\n",
    "# plot feature importance\n",
    "plt.bar([x for x in range(len(importance))], importance)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "nb = GaussianNB().fit(data_train, target_train)\n",
    "prediction = nb.predict(data_test)\n",
    "acc = accuracy_score(target_test,prediction) \n",
    "f1= f1_score(target_test,prediction) \n",
    "pr= precision_score(target_test,prediction) \n",
    "re= recall_score(target_test,prediction) \n",
    "print(\"The Accuracy on test set: {:.4f}\".format(acc))\n",
    "print(\"The F1-Score on test set: {:.4f}\".format(f1))\n",
    "print(\"The Precision-Score on test set: {:.4f}\".format(pr))\n",
    "print(\"The Recall-Score on test set: {:.4f}\".format(re))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "svc = SVC().fit(data_train, target_train)\n",
    "prediction = svc.predict(data_test)\n",
    "acc = accuracy_score(target_test,prediction) \n",
    "f1= f1_score(target_test,prediction) \n",
    "pr= precision_score(target_test,prediction) \n",
    "re= recall_score(target_test,prediction) \n",
    "print(\"The Accuracy on test set: {:.4f}\".format(acc))\n",
    "print(\"The F1-Score on test set: {:.4f}\".format(f1))\n",
    "print(\"The Precision-Score on test set: {:.4f}\".format(pr))\n",
    "print(\"The Recall-Score on test set: {:.4f}\".format(re))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "mlp = MLPClassifier().fit(data_train, target_train)\n",
    "prediction = mlp.predict(data_test)\n",
    "acc = accuracy_score(target_test,prediction) \n",
    "f1= f1_score(target_test,prediction) \n",
    "pr= precision_score(target_test,prediction) \n",
    "re= recall_score(target_test,prediction) \n",
    "print(\"The Accuracy on test set: {:.4f}\".format(acc))\n",
    "print(\"The F1-Score on test set: {:.4f}\".format(f1))\n",
    "print(\"The Precision-Score on test set: {:.4f}\".format(pr))\n",
    "print(\"The Recall-Score on test set: {:.4f}\".format(re))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
