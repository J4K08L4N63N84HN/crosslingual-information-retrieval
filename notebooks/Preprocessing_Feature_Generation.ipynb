{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Preprocessing and Feature Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In this notebook we import the data, preprocess the data and create features for supervised and unsupervised cross-lingual-information retrieval models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## I. Import Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we import the English and German europarl datasets and combine them into a parallel sentence translation dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data import create_data_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'load_doc' in 1.34 seconds.\n",
      "Finished function: 'to_sentences' in 0.71 seconds.\n",
      "Finished function: 'load_doc' in 1.89 seconds.\n",
      "Finished function: 'to_sentences' in 0.97 seconds.\n",
      "Sampled dataframe saved in: ../data/interim/europarl_en_it.pkl\n",
      "Finished function: 'create_data_subset' in 6.26 seconds.\n"
     ]
    }
   ],
   "source": [
    "create_data_subset(sentence_data_source_path='../data/external/europarl-v7.it-en.en',\n",
    "                   sentence_data_target_path='../data/external/europarl-v7.it-en.it',\n",
    "                   sample_size=500,\n",
    "                   sentence_data_sampled_path=\"../data/interim/europarl_en_it.pkl\",)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## II. Preprocess data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we preprocess the parallel sentence data for the feature generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from nltk.corpus import stopwords\n",
    "from textblob import TextBlob as textblob_source\n",
    "from textblob_de import TextBlobDE as textblob_target\n",
    "#import en_core_web_sm\n",
    "# import de_core_news_sm\n",
    "#import it_core_news_sm\n",
    "# import pl_core_news_sm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data import PreprocessingEuroParl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "stopwords_source = stopwords.words('english')\n",
    "stopwords_target = stopwords.words('german') # German stopwords\n",
    "#stopwords_target = stopwords.words('italian') # Italian stopwords\n",
    "# stopwords_target = stopwords.words('polish') # Polish stopwords\n",
    "#nlp_source = en_core_web_sm.load()\n",
    "# nlp_target = de_core_news_sm.load() # German pipeline\n",
    "#nlp_target = it_core_news_sm.load() # Italian pipeline\n",
    "# nlp_target = pl_core_news_sm.load() # Polish pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'import_data' in 0.0 seconds.\n"
     ]
    }
   ],
   "source": [
    "parallel_sentences = PreprocessingEuroParl(df_sampled_path=\"../data/interim/europarl_en_it.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:03<00:00, 161.32it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 7004.07it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 424009.70it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 321107.33it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 236966.33it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 26487.22it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 141365.15it/s]\n",
      "  0%|          | 0/500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'lemmatize' in 3.12 seconds.\n",
      "Finished function: 'tokenize_sentence' in 0.07 seconds.\n",
      "Finished function: 'strip_whitespace' in 0.0 seconds.\n",
      "Finished function: 'lowercase' in 0.0 seconds.\n",
      "Finished function: 'remove_punctuation' in 0.0 seconds.\n",
      "Finished function: 'remove_stopwords' in 0.02 seconds.\n",
      "Finished function: 'remove_numbers' in 0.0 seconds.\n",
      "Finished function: 'create_cleaned_token_embedding' in 3.22 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:02<00:00, 190.17it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 6979.53it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 388217.70it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 303539.15it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 212133.52it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 17735.65it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 112914.01it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 7549.12it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 364468.54it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 272039.43it/s]\n",
      "  0%|          | 0/500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'lemmatize' in 2.63 seconds.\n",
      "Finished function: 'tokenize_sentence' in 0.07 seconds.\n",
      "Finished function: 'strip_whitespace' in 0.0 seconds.\n",
      "Finished function: 'lowercase' in 0.0 seconds.\n",
      "Finished function: 'remove_punctuation' in 0.0 seconds.\n",
      "Finished function: 'remove_stopwords' in 0.03 seconds.\n",
      "Finished function: 'remove_numbers' in 0.01 seconds.\n",
      "Finished function: 'create_cleaned_token_embedding' in 2.74 seconds.\n",
      "Finished function: 'tokenize_sentence' in 0.07 seconds.\n",
      "Finished function: 'strip_whitespace' in 0.0 seconds.\n",
      "Finished function: 'lowercase' in 0.0 seconds.\n",
      "Finished function: 'create_cleaned_text' in 0.07 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:00<00:00, 6953.12it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 338086.73it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 273672.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'tokenize_sentence' in 0.07 seconds.\n",
      "Finished function: 'strip_whitespace' in 0.0 seconds.\n",
      "Finished function: 'lowercase' in 0.0 seconds.\n",
      "Finished function: 'create_cleaned_text' in 0.08 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "parallel_sentences.preprocess_sentences(stopwords_source, stopwords_target, nlp_source, nlp_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:00<00:00, 84819.09it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 84990.96it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 217953.86it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 212047.72it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 36103.02it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 42229.36it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 80774.64it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 90141.93it/s]\n",
      "/Users/jakob/PycharmProjects/crosslingual-information-retrieval/src/data/preprocess_data.py:243: RuntimeWarning: divide by zero encountered in log\n",
      "  return (character_vector / word_vector).replace(np.nan, 0).replace(np.inf, 0).replace(np.log(0), 0)\n",
      "100%|██████████| 500/500 [00:00<00:00, 352107.45it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 321550.44it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 409120.56it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 396812.11it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 397187.88it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 333357.49it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 380539.29it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 400985.09it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 417343.68it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 328913.43it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 387285.69it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 405560.24it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 361266.49it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 414293.16it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 415936.53it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 396512.01it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 378820.81it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 426250.41it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 397790.59it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 394349.76it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 414211.34it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 398622.32it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 406503.59it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 396137.51it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 379369.03it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 409520.02it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 354368.37it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 410160.77it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 407847.53it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 414293.16it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 403842.10it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 409600.00it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 387858.70it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 418426.18it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 381994.90it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 399990.84it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 417676.16it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 397790.59it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 370456.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'number_punctuations_total' in 0.01 seconds.\n",
      "Finished function: 'number_punctuations_total' in 0.01 seconds.\n",
      "Finished function: 'number_words' in 0.0 seconds.\n",
      "Finished function: 'number_words' in 0.0 seconds.\n",
      "Finished function: 'number_unique_words' in 0.01 seconds.\n",
      "Finished function: 'number_unique_words' in 0.01 seconds.\n",
      "Finished function: 'number_characters' in 0.01 seconds.\n",
      "Finished function: 'number_characters' in 0.01 seconds.\n",
      "Finished function: 'average_characters' in 0.0 seconds.\n",
      "Finished function: 'average_characters' in 0.0 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.0 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.0 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.0 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.0 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.0 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.0 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.0 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.0 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.0 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.0 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.0 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.0 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.0 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.0 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.0 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.0 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.0 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.0 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.0 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.0 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.0 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.0 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.0 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.0 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.0 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.0 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.0 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.0 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.0 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.0 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.0 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.0 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.0 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.0 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.0 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.0 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.0 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.0 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 500/500 [00:00<00:00, 397790.59it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 346522.14it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 377933.32it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 408881.26it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 418342.71it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 314274.24it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 406109.99it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 399001.52it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 374826.09it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 428077.57it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 385505.88it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 403919.88it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 284745.69it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 389154.20it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 401599.39it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 336459.49it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 414866.86it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 396512.01it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 371967.36it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 405795.67it/s]\n",
      "  0%|          | 0/500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'number_punctuation_marks' in 0.0 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.0 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.0 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.0 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.0 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.0 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.0 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.0 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.0 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.0 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.0 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.0 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.0 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.0 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.0 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.0 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.0 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.0 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.0 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.0 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.0 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:00<00:00, 390676.60it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 386714.36it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 380470.25it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 371243.05it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 405795.67it/s]\n",
      "  3%|▎         | 16/500 [00:00<00:03, 159.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'number_punctuation_marks' in 0.0 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.0 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.0 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.0 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.0 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:02<00:00, 186.21it/s]\n",
      "  5%|▍         | 23/500 [00:00<00:02, 229.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'number_pos' in 2.69 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:02<00:00, 203.99it/s]\n",
      "  4%|▍         | 22/500 [00:00<00:02, 218.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'number_pos' in 2.45 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:02<00:00, 192.37it/s]\n",
      "  5%|▍         | 24/500 [00:00<00:02, 231.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'number_pos' in 2.6 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:02<00:00, 206.27it/s]\n",
      "  5%|▍         | 23/500 [00:00<00:02, 218.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'number_pos' in 2.42 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:02<00:00, 193.50it/s]\n",
      "  5%|▍         | 24/500 [00:00<00:02, 234.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'number_pos' in 2.58 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:02<00:00, 206.60it/s]\n",
      "  4%|▍         | 22/500 [00:00<00:02, 216.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'number_pos' in 2.42 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:02<00:00, 190.32it/s]\n",
      "  4%|▍         | 22/500 [00:00<00:02, 219.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'number_times' in 2.63 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:02<00:00, 198.22it/s]\n",
      "  5%|▍         | 23/500 [00:00<00:02, 215.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'number_times' in 2.52 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:02<00:00, 188.92it/s]\n",
      "  5%|▍         | 24/500 [00:00<00:02, 232.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'number_times' in 2.65 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:02<00:00, 202.50it/s]\n",
      "  5%|▍         | 23/500 [00:00<00:02, 217.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'number_times' in 2.47 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:02<00:00, 174.15it/s]\n",
      "  4%|▍         | 22/500 [00:00<00:02, 212.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'number_times' in 2.87 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 446/500 [00:02<00:00, 178.81it/s]"
     ]
    }
   ],
   "source": [
    "parallel_sentences.extract_sentence_information(nlp_source, nlp_target, textblob_source, textblob_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_sentences.create_embedding_information(\"proc_5k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_sentences.create_embedding_information(\"proc_b_1k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_sentences.create_embedding_information(\"vecmap\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_sentences.preprocessed.to_json(\"../data/interim/preprocessed_data_en_it.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# preprocessed_data = pd.read_json(\"../data/interim/preprocessed_data.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Create data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we create the datasets for the training of the supervised model and the data for the supervised and unsupervised retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "from src.data import DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_model = 0\n",
    "n_queries = 100\n",
    "n_retrieval = 500\n",
    "k = 0\n",
    "sample_size_k = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "dataset = DataSet(parallel_sentences.preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.split_model_retrieval(n_model, n_retrieval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset.create_model_index(n_model, k, sample_size_k,\n",
    "#     \"sentence_embedding_tf_idf_proc_5k_source\", \"sentence_embedding_tf_idf_proc_5k_target\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset.model_dataset_index.reset_index(drop=True).to_feather(\"../data/processed/dataset_model_index_en_it.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# pd.read_feather(\"../data/processed/dataset_model_index.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.create_retrieval_index(n_queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.retrieval_dataset_index.reset_index(drop=True).to_feather(\"../data/processed/dataset_retrieval_index_en_it.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# pd.read_feather(\"../data/processed/dataset_retrieval_index.feather\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%% md\n"
    }
   },
   "source": [
    "## IV. Create features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we create features for our model, that are sentence based and should be created before the text is preprocessed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "from src.features import feature_generation_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# with open(r\"../data/processed/correlated_features.pkl\", \"rb\") as file:\n",
    "#    chosen_features = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generation of the training data for the supervised classifciation model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# features_model = feature_generation_class.FeatureGeneration(dataset.model_dataset_index, \n",
    "#                                                             parallel_sentences.preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# features_model.create_feature_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features_model.create_sentence_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features_model.create_embedding_features(\"proc_5k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_model.create_embedding_features(\"proc_b_1k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features_model.create_embedding_features(\"vecmap\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features_model.feature_dataframe.reset_index(drop=True).to_feather(\"../data/processed/feature_model_en_it.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# pd.read_feather(\"../data/processed/feature_model.feather\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generation of the data for the crosslingual information retrieval task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_retrieval = feature_generation_class.FeatureGeneration(dataset.retrieval_dataset_index, \n",
    "                                                            parallel_sentences.preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_retrieval.create_feature_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_retrieval.create_sentence_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_retrieval.create_embedding_features(\"proc_5k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_retrieval.create_embedding_features(\"proc_b_1k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_retrieval.create_embedding_features(\"vecmap\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_retrieval.feature_dataframe.reset_index(drop=True).to_feather(\"../data/processed/feature_retrieval_en_it.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# pd.read_feather(\"../data/processed/feature_retrieval.feather\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}