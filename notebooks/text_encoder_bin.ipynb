{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "text_encoder_bin.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PX_USRna_KBr",
        "outputId": "19d0adc1-695e-4ac6-f6c9-4de4d9e973b4"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yne-REqY_E1Q",
        "outputId": "bbcf5753-6e44-4076-ccc0-4b76c19c633d"
      },
      "source": [
        "! pip3 install torch==1.5.0 transformers==3.4.0\n",
        "! pip install faiss-gpu cudatoolkit=10.0 -c pytorch"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torch==1.5.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/76/58/668ffb25215b3f8231a550a227be7f905f514859c70a65ca59d28f9b7f60/torch-1.5.0-cp37-cp37m-manylinux1_x86_64.whl (752.0MB)\n",
            "\u001b[K     |████████████████████████████████| 752.0MB 23kB/s \n",
            "\u001b[?25hCollecting transformers==3.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2c/4e/4f1ede0fd7a36278844a277f8d53c21f88f37f3754abf76a5d6224f76d4a/transformers-3.4.0-py3-none-any.whl (1.3MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3MB 39.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.5.0) (1.19.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch==1.5.0) (0.16.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3.4.0) (2019.12.20)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3.4.0) (20.9)\n",
            "Collecting tokenizers==0.9.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/35/e7/edf655ae34925aeaefb7b7fcc3dd0887d2a1203ee6b0df4d1170d1a19d4f/tokenizers-0.9.2-cp37-cp37m-manylinux1_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 38.7MB/s \n",
            "\u001b[?25hCollecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 32.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3.4.0) (3.0.12)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==3.4.0) (4.41.1)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 42.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from transformers==3.4.0) (3.12.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==3.4.0) (2.23.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3.4.0) (2.4.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.4.0) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.4.0) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.4.0) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf->transformers==3.4.0) (56.1.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.4.0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.4.0) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.4.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.4.0) (2.10)\n",
            "\u001b[31mERROR: torchvision 0.9.1+cu101 has requirement torch==1.8.1, but you'll have torch 1.5.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: torchtext 0.9.1 has requirement torch==1.8.1, but you'll have torch 1.5.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: torch, tokenizers, sentencepiece, sacremoses, transformers\n",
            "  Found existing installation: torch 1.8.1+cu101\n",
            "    Uninstalling torch-1.8.1+cu101:\n",
            "      Successfully uninstalled torch-1.8.1+cu101\n",
            "Successfully installed sacremoses-0.0.45 sentencepiece-0.1.95 tokenizers-0.9.2 torch-1.5.0 transformers-3.4.0\n",
            "\u001b[31mERROR: Could not open requirements file: [Errno 2] No such file or directory: 'pytorch'\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bu2ukk2u_M7q"
      },
      "source": [
        "## Load Data, tokenize and split into train/val/test\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fakdjGUW_3gF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "e5457882-e5ef-4c16-ad58-9e8eecc7a1d3"
      },
      "source": [
        "import pickle\n",
        "\n",
        "path = \"/content/drive/MyDrive/CLIR/europarl_data/dataset_duc.pkl\"\n",
        "model_used = \"xlm-roberta-base\"\n",
        "\n",
        "# Load Data\n",
        "with open(path, 'rb') as f:\n",
        "    data = pickle.load(f)\n",
        "data.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text_source</th>\n",
              "      <th>text_target</th>\n",
              "      <th>Translation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Mention was made of citizenship, but I felt th...</td>\n",
              "      <td>Zwar wird der Bürgersinn erwähnt, doch wurde m...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Yesterday, Mr Barroso rightly said that we nee...</td>\n",
              "      <td>Kommissionspräsident Barroso hat gestern zu Re...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Some of them even gestured to me to resort to ...</td>\n",
              "      <td>Jemand forderte mich sogar mit einer Geste auf...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Despite the excellent work of Mr Hernández Mol...</td>\n",
              "      <td>Trotz der ausgezeichneten Arbeit des Ausschuss...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>(GA) Mr President, I also welcome the Taoiseac...</td>\n",
              "      <td>(GA) Herr Präsident! Auch ich möchte den Premi...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                         text_source  ... Translation\n",
              "0  Mention was made of citizenship, but I felt th...  ...           1\n",
              "1  Yesterday, Mr Barroso rightly said that we nee...  ...           1\n",
              "2  Some of them even gestured to me to resort to ...  ...           1\n",
              "3  Despite the excellent work of Mr Hernández Mol...  ...           1\n",
              "4  (GA) Mr President, I also welcome the Taoiseac...  ...           1\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P411sIE9p4B3"
      },
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "\n",
        "class Torch_dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, data):\n",
        "        tokenizer = AutoTokenizer.from_pretrained(\"xlm-roberta-base\")\n",
        "        sentence_pairs = data.apply(lambda row: [row[\"text_source\"], row[\"text_target\"]], axis=1).tolist()\n",
        "        self.encodings = tokenizer(sentence_pairs, padding=\"max_length\", truncation=\"longest_first\", return_tensors=\"pt\")\n",
        "        self.labels = data[\"Translation\"].tolist()\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "      "
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1VhXf4IM674e"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import torch.utils.data as data_utils\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "train, test = train_test_split(data, test_size=.2)\n",
        "\n",
        "\n",
        "\n",
        "# Convert to pytorch data\n",
        "'''train_target = torch.tensor(train[\"Translation\"].values.astype(np.float32))\n",
        "train_data = torch.tensor(train[\"tokenized_sequence_pair\"].values.tolist())\n",
        "train_tensor = data_utils.TensorDataset(train_data, train_target) \n",
        "\n",
        "# Convert to pytorch data\n",
        "test_target = torch.tensor(test[\"Translation\"].values.astype(np.float32))\n",
        "test_data = torch.tensor(test[\"tokenized_sequence_pair\"].values.tolist())\n",
        "test_tensor = data_utils.TensorDataset(test_data, test_target) '''\n",
        "\n",
        "train_dataset = Torch_dataset(train)\n",
        "test_dataset = Torch_dataset(test)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jTDhBovIGALY",
        "outputId": "dd2645f5-54ef-4da1-e844-daa787731027"
      },
      "source": [
        "test_dataset.__len__()"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0TKtbxDDo-P7"
      },
      "source": [
        "## Train Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UYpOmKjIps4d",
        "outputId": "ab6f2903-ae05-4a49-80bd-e100274939b2"
      },
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained('xlm-roberta-base', num_labels=2)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "- This IS expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "kTMbk6kA7KY9",
        "outputId": "74fddfe0-5054-4927-98c8-257652541e53"
      },
      "source": [
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',          # output directory\n",
        "    num_train_epochs=1,              # total number of training epochs\n",
        "    per_device_train_batch_size=8,  # batch size per device during training\n",
        "    per_device_eval_batch_size=8,   # batch size for evaluation\n",
        "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
        "    weight_decay=0.01,               # strength of weight decay\n",
        "    logging_dir='./logs',            # directory for storing logs\n",
        "    logging_steps=10,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,                         # the instantiated 🤗 Transformers model to be trained\n",
        "    args=training_args,                  # training arguments, defined above\n",
        "    train_dataset=train_dataset,         # training dataset\n",
        "    eval_dataset=test_dataset             # evaluation dataset\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "        </style>\n",
              "      \n",
              "      <progress value='2000' max='2000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2000/2000 31:13, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.704225</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.688133</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.703396</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.707666</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.698685</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>0.697302</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>0.690036</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>0.661416</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>0.625328</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.637036</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>110</td>\n",
              "      <td>0.448638</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>0.347180</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>130</td>\n",
              "      <td>0.244759</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>140</td>\n",
              "      <td>0.149825</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>0.164276</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>160</td>\n",
              "      <td>0.130249</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>170</td>\n",
              "      <td>0.158709</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>180</td>\n",
              "      <td>0.162543</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>190</td>\n",
              "      <td>0.083669</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.117590</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>210</td>\n",
              "      <td>0.260040</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>220</td>\n",
              "      <td>0.245876</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>230</td>\n",
              "      <td>0.119575</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>240</td>\n",
              "      <td>0.033366</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>0.215297</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>260</td>\n",
              "      <td>0.293575</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>270</td>\n",
              "      <td>0.615769</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>280</td>\n",
              "      <td>0.295247</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>290</td>\n",
              "      <td>0.155254</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.241943</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>310</td>\n",
              "      <td>0.281148</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>320</td>\n",
              "      <td>0.323710</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>330</td>\n",
              "      <td>0.265133</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>340</td>\n",
              "      <td>0.158098</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>0.000690</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>360</td>\n",
              "      <td>0.096488</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>370</td>\n",
              "      <td>0.210750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>380</td>\n",
              "      <td>0.271242</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>390</td>\n",
              "      <td>0.004700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.001469</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>410</td>\n",
              "      <td>0.089966</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>420</td>\n",
              "      <td>0.446329</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>430</td>\n",
              "      <td>0.155731</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>440</td>\n",
              "      <td>0.152979</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>0.191046</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>460</td>\n",
              "      <td>0.262816</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>470</td>\n",
              "      <td>0.397211</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>480</td>\n",
              "      <td>0.566975</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>490</td>\n",
              "      <td>0.160085</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.267325</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>510</td>\n",
              "      <td>0.421030</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>520</td>\n",
              "      <td>0.347931</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>530</td>\n",
              "      <td>0.406490</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>540</td>\n",
              "      <td>0.332262</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>550</td>\n",
              "      <td>0.475772</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>560</td>\n",
              "      <td>0.653183</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>570</td>\n",
              "      <td>0.464835</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>580</td>\n",
              "      <td>0.147844</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>590</td>\n",
              "      <td>0.268971</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.381960</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>610</td>\n",
              "      <td>0.268182</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>620</td>\n",
              "      <td>0.310605</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>630</td>\n",
              "      <td>0.575549</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>640</td>\n",
              "      <td>0.288139</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>650</td>\n",
              "      <td>0.298340</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>660</td>\n",
              "      <td>0.519302</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>670</td>\n",
              "      <td>0.294203</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>680</td>\n",
              "      <td>0.129570</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>690</td>\n",
              "      <td>0.277930</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.180391</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>710</td>\n",
              "      <td>0.227882</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>720</td>\n",
              "      <td>0.190379</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>730</td>\n",
              "      <td>0.174577</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>740</td>\n",
              "      <td>0.286494</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>750</td>\n",
              "      <td>0.212021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>760</td>\n",
              "      <td>0.273764</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>770</td>\n",
              "      <td>0.203737</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>780</td>\n",
              "      <td>0.550964</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>790</td>\n",
              "      <td>0.372362</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.077916</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>810</td>\n",
              "      <td>0.005498</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>820</td>\n",
              "      <td>0.166930</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>830</td>\n",
              "      <td>0.276389</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>840</td>\n",
              "      <td>0.176968</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>850</td>\n",
              "      <td>0.288043</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>860</td>\n",
              "      <td>0.004819</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>870</td>\n",
              "      <td>0.269363</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>880</td>\n",
              "      <td>0.194244</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>890</td>\n",
              "      <td>0.146951</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.142654</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>910</td>\n",
              "      <td>0.339066</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>920</td>\n",
              "      <td>0.184503</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>930</td>\n",
              "      <td>0.063962</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>940</td>\n",
              "      <td>0.340497</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>950</td>\n",
              "      <td>0.076575</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>960</td>\n",
              "      <td>0.253442</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>970</td>\n",
              "      <td>0.224344</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>980</td>\n",
              "      <td>0.099789</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>990</td>\n",
              "      <td>0.435361</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.302905</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1010</td>\n",
              "      <td>0.116815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1020</td>\n",
              "      <td>0.394183</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1030</td>\n",
              "      <td>0.262912</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1040</td>\n",
              "      <td>0.289243</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1050</td>\n",
              "      <td>0.244376</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1060</td>\n",
              "      <td>0.161758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1070</td>\n",
              "      <td>0.082321</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1080</td>\n",
              "      <td>0.298416</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1090</td>\n",
              "      <td>0.080579</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.095367</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1110</td>\n",
              "      <td>0.151935</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1120</td>\n",
              "      <td>0.072067</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1130</td>\n",
              "      <td>0.004807</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1140</td>\n",
              "      <td>0.149066</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1150</td>\n",
              "      <td>0.075229</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1160</td>\n",
              "      <td>0.217554</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1170</td>\n",
              "      <td>0.089911</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1180</td>\n",
              "      <td>0.286960</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1190</td>\n",
              "      <td>0.071817</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.288565</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1210</td>\n",
              "      <td>0.136664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1220</td>\n",
              "      <td>0.060745</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1230</td>\n",
              "      <td>0.071393</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1240</td>\n",
              "      <td>0.376361</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1250</td>\n",
              "      <td>0.090491</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1260</td>\n",
              "      <td>0.255548</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1270</td>\n",
              "      <td>0.118188</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1280</td>\n",
              "      <td>0.141483</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1290</td>\n",
              "      <td>0.066757</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.227029</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1310</td>\n",
              "      <td>0.100671</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1320</td>\n",
              "      <td>0.184201</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1330</td>\n",
              "      <td>0.152496</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1340</td>\n",
              "      <td>0.097708</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1350</td>\n",
              "      <td>0.029489</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1360</td>\n",
              "      <td>0.094595</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1370</td>\n",
              "      <td>0.047177</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1380</td>\n",
              "      <td>0.085706</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1390</td>\n",
              "      <td>0.228720</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.262607</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1410</td>\n",
              "      <td>0.131238</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1420</td>\n",
              "      <td>0.199136</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1430</td>\n",
              "      <td>0.018530</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1440</td>\n",
              "      <td>0.049524</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1450</td>\n",
              "      <td>0.091614</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1460</td>\n",
              "      <td>0.029938</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1470</td>\n",
              "      <td>0.086087</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1480</td>\n",
              "      <td>0.099936</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1490</td>\n",
              "      <td>0.156094</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.001840</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1510</td>\n",
              "      <td>0.001807</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1520</td>\n",
              "      <td>0.088101</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1530</td>\n",
              "      <td>0.016867</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1540</td>\n",
              "      <td>0.105453</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1550</td>\n",
              "      <td>0.001703</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1560</td>\n",
              "      <td>0.137207</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1570</td>\n",
              "      <td>0.064532</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1580</td>\n",
              "      <td>0.079425</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1590</td>\n",
              "      <td>0.001895</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.133832</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1610</td>\n",
              "      <td>0.059698</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1620</td>\n",
              "      <td>0.008356</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1630</td>\n",
              "      <td>0.016003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1640</td>\n",
              "      <td>0.145834</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1650</td>\n",
              "      <td>0.084274</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1660</td>\n",
              "      <td>0.048560</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1670</td>\n",
              "      <td>0.196921</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1680</td>\n",
              "      <td>0.075784</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1690</td>\n",
              "      <td>0.180103</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>0.083966</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1710</td>\n",
              "      <td>0.069260</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1720</td>\n",
              "      <td>0.128485</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1730</td>\n",
              "      <td>0.019821</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1740</td>\n",
              "      <td>0.074832</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1750</td>\n",
              "      <td>0.001352</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1760</td>\n",
              "      <td>0.083273</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1770</td>\n",
              "      <td>0.017780</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1780</td>\n",
              "      <td>0.077441</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1790</td>\n",
              "      <td>0.001294</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.164594</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1810</td>\n",
              "      <td>0.001297</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1820</td>\n",
              "      <td>0.154947</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1830</td>\n",
              "      <td>0.011374</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1840</td>\n",
              "      <td>0.121893</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1850</td>\n",
              "      <td>0.099487</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1860</td>\n",
              "      <td>0.165179</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1870</td>\n",
              "      <td>0.001459</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1880</td>\n",
              "      <td>0.035941</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1890</td>\n",
              "      <td>0.001245</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1900</td>\n",
              "      <td>0.001068</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1910</td>\n",
              "      <td>0.078998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1920</td>\n",
              "      <td>0.076712</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1930</td>\n",
              "      <td>0.000995</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1940</td>\n",
              "      <td>0.080255</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1950</td>\n",
              "      <td>0.153415</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1960</td>\n",
              "      <td>0.001025</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1970</td>\n",
              "      <td>0.077426</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1980</td>\n",
              "      <td>0.001898</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1990</td>\n",
              "      <td>0.001236</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.080920</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  del sys.path[0]\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  del sys.path[0]\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=2000, training_loss=0.19823226928710938)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Ju3G0mgInw7"
      },
      "source": [
        "## Evaluate Model/Predict"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "nGA-YHY8mmFQ",
        "outputId": "33713c1c-4a3d-4fa5-e144-4726ea6b4e04"
      },
      "source": [
        "import numpy as np\n",
        "from datasets import load_metric\n",
        "\n",
        "metric = load_metric(\"accuracy\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    return metric.compute(predictions=predictions, references=labels)\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,                         # the instantiated 🤗 Transformers model to be trained\n",
        "    args=training_args,                  # training arguments, defined above\n",
        "    eval_dataset=test_dataset,             # evaluation dataset\n",
        "    compute_metrics=compute_metrics,\n",
        "    test_dataset=test_dataset\n",
        ")\n",
        "\n",
        "# Evaluate on Test Set\n",
        "trainer.evaluate()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "        </style>\n",
              "      \n",
              "      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [500/500 01:57]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eval_accuracy': 0.98925, 'eval_loss': 0.059095073491334915}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "id": "6ueeiAlXzR6i",
        "outputId": "efc12e3f-4504-4d2d-d122-356752525ed5"
      },
      "source": [
        "trainer = Trainer(\n",
        "    model=model,                         # the instantiated 🤗 Transformers model to be trained\n",
        "    args=training_args,                  # training arguments, defined above\n",
        "    train_dataset=train_dataset,         # training dataset\n",
        "    eval_dataset=test_dataset,             # evaluation dataset\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "# Do Prediction on Test Set\n",
        "predictions = trainer.predict(test_dataset)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "        </style>\n",
              "      \n",
              "      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [500/500 01:57]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4w6MHiG60J9"
      },
      "source": [
        "import pandas\n",
        "pandas.set_option('display.max_colwidth', None)\n",
        "\n",
        "def logit2prob(logit):\n",
        "  odds = np.exp(logit)\n",
        "  prob = odds/(1+odds)\n",
        "  return prob\n",
        "\n",
        "def prob2label(prod):\n",
        "  return (prod > 0.5)\n",
        "\n",
        "pred_logit = [pred[1] for pred in predictions.predictions]\n",
        "pred_prob = logit2prob(pred_logit)\n",
        "pred_label = prob2label(pred_prob)\n",
        "\n",
        "test['prediction_prob'] = pred_prob\n",
        "test['prediction'] = pred_label"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "MlPkg8sm74TP",
        "outputId": "75ff91df-16b1-477c-e285-4fec80fb1c63"
      },
      "source": [
        "# Show some predictions\n",
        "test.head(n=10)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text_source</th>\n",
              "      <th>text_target</th>\n",
              "      <th>Translation</th>\n",
              "      <th>prediction</th>\n",
              "      <th>prediction_prob</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6333</th>\n",
              "      <td>But on balance it is impossible to agree with ...</td>\n",
              "      <td>Da muß die Kommission beobachten, und notfalls...</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>0.035325</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4976</th>\n",
              "      <td>Mr President, on issues concerning the third p...</td>\n",
              "      <td>Ich begrüße es, dass die Bekämpfung des Mensch...</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>0.026230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4276</th>\n",
              "      <td>We are organising campaigns throughout the Eur...</td>\n",
              "      <td>Derzeit organisieren wir Kampagnen in ganz Eur...</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>0.983490</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3423</th>\n",
              "      <td>That cannot be allowed to happen!</td>\n",
              "      <td>Das darf nicht sein!</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>0.983445</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1795</th>\n",
              "      <td>Regarding the issue of Christianity versus Isl...</td>\n",
              "      <td>In Valencia wurden in großem Umfang Immobilien...</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>0.026791</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6468</th>\n",
              "      <td>The two most important examples of this are th...</td>\n",
              "      <td>Die zwei wichtigsten Beispiele dafür sind die ...</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>0.983754</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7107</th>\n",
              "      <td>My question to Council was tabled as No 3. Whe...</td>\n",
              "      <td>Meine Anfrage an den Rat hatte die Nr. 3. Als ...</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>0.983761</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3425</th>\n",
              "      <td>In conclusion, I would like to express my hope...</td>\n",
              "      <td>Ich will damit sagen, dass das, was ich heute ...</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>0.029201</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9601</th>\n",
              "      <td>Nowadays, everyone must have the necessary rea...</td>\n",
              "      <td>Unsere Bürger möchten weder mit krebserregende...</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>0.027699</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8874</th>\n",
              "      <td>For this frankness I am grateful, for it gives...</td>\n",
              "      <td>Ich bin dankbar für diese Offenheit, weil sie ...</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>0.983705</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            text_source  ... prediction_prob\n",
              "6333  But on balance it is impossible to agree with ...  ...        0.035325\n",
              "4976  Mr President, on issues concerning the third p...  ...        0.026230\n",
              "4276  We are organising campaigns throughout the Eur...  ...        0.983490\n",
              "3423                  That cannot be allowed to happen!  ...        0.983445\n",
              "1795  Regarding the issue of Christianity versus Isl...  ...        0.026791\n",
              "6468  The two most important examples of this are th...  ...        0.983754\n",
              "7107  My question to Council was tabled as No 3. Whe...  ...        0.983761\n",
              "3425  In conclusion, I would like to express my hope...  ...        0.029201\n",
              "9601  Nowadays, everyone must have the necessary rea...  ...        0.027699\n",
              "8874  For this frankness I am grateful, for it gives...  ...        0.983705\n",
              "\n",
              "[10 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "IlDXUnvZ7753",
        "outputId": "515443cc-5c58-4c26-ece9-fe0081007647"
      },
      "source": [
        "# Show wrong predictions\n",
        "test.loc[test['Translation'] != test['prediction']]"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text_source</th>\n",
              "      <th>text_target</th>\n",
              "      <th>Translation</th>\n",
              "      <th>prediction</th>\n",
              "      <th>prediction_prob</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6533</th>\n",
              "      <td>It also confirms the fact that the issue of the price of drugs is at the heart of the debates on access to treatment and the importance of research and development and, above all, it stresses the need to focus efforts on diseases that particularly affect the South, as well as forgotten illnesses.</td>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "      <td>0.028090</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4246</th>\n",
              "      <td>We should be encouraged by the fact that the issue is back where it belongs, that is at scientific and at veterinary level.</td>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "      <td>0.028881</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7997</th>\n",
              "      <td>Are we prepared to tolerate that for the sake of a slice of salami in our sandwich?</td>\n",
              "      <td>Während wir hier unsere Aussprache führen, stirbt ein Pferd infolge einer solchen unwürdigen Behandlung von Tieren.</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "      <td>0.027997</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3553</th>\n",
              "      <td></td>\n",
              "      <td>Viertens: Die demographische Entwicklung macht uns zu schaffen.</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "      <td>0.033435</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1603</th>\n",
              "      <td>The next item is the vote.</td>\n",
              "      <td>Als nächster Punkt folgt die Abstimmungsstunde.</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "      <td>0.168404</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>868</th>\n",
              "      <td>I give the floor to the rapporteur, Mr Herman.</td>\n",
              "      <td>Vorschlag für einen Beschluß des Rates über die Vertretung und die Festlegung von Standpunkten der Gemeinschaft auf internationaler Ebene im Zusammenhang mit der Wirtschafts- und Währungsunion (KOM(98)0637 - C4-0638/98-00/0785(COS)). Zunächst hat Herr Herman in seiner Eigenschaft als Berichterstatter das Wort.</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "      <td>0.027290</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5674</th>\n",
              "      <td></td>\n",
              "      <td>(IT) Frau Präsidentin, Herr Wathelet, Herr Kommissar, meine Damen und Herren!</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "      <td>0.188270</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3480</th>\n",
              "      <td>We do not wish to sanction but rather to assist. Not to assist for the sake of assisting, but to assist so that the commitments may be met.</td>\n",
              "      <td>Wir wollen keine Strafen verhängen, sondern Hilfe leisten, keine Hilfe um der Hilfe willen, sondern zur Unterstützung der Entwicklungsländer bei ihren Bemühungen um Einhaltung ihrer Verpflichtungen.</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "      <td>0.155421</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>332</th>\n",
              "      <td>The matter has been deferred.</td>\n",
              "      <td>Das Thema ist vertagt.</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "      <td>0.420807</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6126</th>\n",
              "      <td>Another criterion should be that the young people who take part do not find themselves subjected to repressive measures on their return home.</td>\n",
              "      <td>Außerdem dürfen die Teilnehmer bei ihrer Rückkehr keinen Repressalien ausgesetzt werden.</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "      <td>0.039022</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3245</th>\n",
              "      <td></td>\n",
              "      <td>Auch hier gilt: soweit so gut.</td>\n",
              "      <td>0</td>\n",
              "      <td>True</td>\n",
              "      <td>0.978042</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4917</th>\n",
              "      <td>They do not want any more promises that we then fail to keep, or to see any efforts that we then fail to follow through.</td>\n",
              "      <td>Sie wollen keine weiteren Zusagen, die wir dann doch nicht einhalten, sie wollen keine Bemühungen, die wir dann doch nicht umsetzen.</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "      <td>0.081473</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6799</th>\n",
              "      <td>What are the goals being pursued by the various organisations?</td>\n",
              "      <td>Was wollen die Bürger?</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "      <td>0.196286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6721</th>\n",
              "      <td>The global economy is in recession, but that is nothing new.</td>\n",
              "      <td>Europas Wirtschaft kränkelt schon seit mindestens zehn Jahren.</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "      <td>0.031169</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8929</th>\n",
              "      <td>Mr President, I thank the President-in-Office for his answer.</td>\n",
              "      <td>Herr Präsident!</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "      <td>0.147697</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7324</th>\n",
              "      <td>I admit, Mrs Beer, that there are a great many issues that remain to be resolved, very serious problems that have not yet been solved.</td>\n",
              "      <td>Für viele Mitglieder des Parlaments, unter anderem ich selbst, ist das nicht hinnehmbar.</td>\n",
              "      <td>0</td>\n",
              "      <td>True</td>\n",
              "      <td>0.543568</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6803</th>\n",
              "      <td>They also need to be considered in the light of ‘better regulation’, something that they cannot be said to achieve.</td>\n",
              "      <td>Deshalb hat die österreichische ÖVP-Delegation diese Kompromisse großteils abgelehnt. Sie sind auch vor dem Hintergrund einer zu sehen.</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "      <td>0.029670</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3564</th>\n",
              "      <td>Madam President, Candidate for the Commission Presidency, ladies and gentlemen, what is at stake with tomorrow’s vote?</td>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "      <td>0.057546</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7814</th>\n",
              "      <td></td>\n",
              "      <td>Man kann aus allem eine Wissenschaft machen und durchaus interessante Erkenntnisse haben.</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "      <td>0.030147</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4102</th>\n",
              "      <td>We will see that it is put right.</td>\n",
              "      <td>Wir werden dafür sorgen, daß das berichtigt wird.</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "      <td>0.122364</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6342</th>\n",
              "      <td>There are many different kinds of fanaticism.</td>\n",
              "      <td>Besonders in der heutigen Welt sind wir mit diesen Spielarten vertraut.</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "      <td>0.030353</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>853</th>\n",
              "      <td>During Mrs Merkel's German Presidency there was unanimous support for a number of targets.</td>\n",
              "      <td>Im Rahmen der deutschen Präsidentschaft unter Frau Merkel haben wir einstimmig bestimmte Ziele festgelegt.</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "      <td>0.268974</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3769</th>\n",
              "      <td>Dictators and their regimes and families should not be allowed to leave their country or to acquire any assets abroad.</td>\n",
              "      <td>Eine solche Großzügigkeit im Haushalt auf der Gemeinschaftsebene wäre den Bürgern und Steuerzahlern Europas schlicht nicht zu vermitteln.</td>\n",
              "      <td>0</td>\n",
              "      <td>True</td>\n",
              "      <td>0.979810</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4374</th>\n",
              "      <td>– Mr President, I was shocked by what Mr Frattini had to say about Chechnya.</td>\n",
              "      <td>– Herr Parlamentspräsident, Herr amtierender Ratspräsident, Herr Kommissar, werte Kollegen!</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "      <td>0.163072</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1542</th>\n",
              "      <td>The opinion of the Committee on Legal Affairs should be taken into consideration.</td>\n",
              "      <td>Beachtung verdient die Stellungnahme des Rechtsausschusses.</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "      <td>0.104635</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6041</th>\n",
              "      <td>First of all recycling.</td>\n",
              "      <td>Erstens stoffliche Verwertung.</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "      <td>0.458040</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8864</th>\n",
              "      <td>The problem lies in the content of the framework directive.</td>\n",
              "      <td>Die Schwierigkeit ist, was in der Rahmenrichtlinie steht.</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "      <td>0.037619</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5062</th>\n",
              "      <td>The directive is a mere starting point.</td>\n",
              "      <td>Die Richtlinie stellt einen Ausgangspunkt dar.</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "      <td>0.161743</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6347</th>\n",
              "      <td></td>\n",
              "      <td>Steuern schließlich, die der Gesundheit und nicht dem Lebensverdruß Vorschub leisten.</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "      <td>0.029101</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9673</th>\n",
              "      <td>The enlargement negotiations have now passed the point of no return and there must be no new demands made.</td>\n",
              "      <td>Bei den Erweiterungsverhandlungen gibt es jetzt kein Zurück mehr, und es dürfen keine neuen Forderungen gestellt werden.</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "      <td>0.070167</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5032</th>\n",
              "      <td>If adopted, these various amendments will undoubtedly turn our Europe - which is already an open door when it comes to immigration - into a Europe where the floodgates are opened to what will become a spate of immigrants.</td>\n",
              "      <td>Und es sind die zahlreichen Änderungsvorschläge, wenn sie denn genehmigt werden, die, da gibt es keinen Zweifel, aus unserem Europa, das in Sachen Einwanderung jetzt schon ein Sieb ist, einen \"Wasserhahn\" machen, durch den sich die Einwanderung, diesmal im Schwall, über uns ergießt.</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "      <td>0.030615</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8460</th>\n",
              "      <td>It is deliberately this complicated so that no-one can get their head around what it contains.</td>\n",
              "      <td>Dies ist eine substanzielle Angelegenheit, und es geht nicht nur um eine rechtliche Interpretation.</td>\n",
              "      <td>0</td>\n",
              "      <td>True</td>\n",
              "      <td>0.969031</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>547</th>\n",
              "      <td>The proposal by the European Commission, enhanced by the amendments of the Committee on the Environment, Public Health and Consumer Policy, has succeeded in taking both of these principles into account.</td>\n",
              "      <td>Mit dem durch die Änderungsanträge des Umweltausschusses ergänzten Vorschlag der Europäischen Kommission ist das Kunststück gelungen, diese beiden Forderungen miteinander zu vereinbaren.</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "      <td>0.036302</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2209</th>\n",
              "      <td></td>\n",
              "      <td>Was die Maßnahme betreffen die Kabeljau-Bestände anbelangt, so wurde bestimmt, daß die Verteilung künftig zwischen Kanada in dessen Gewässer sich 95 % der Bestände befinden, und der NAFO-Zone erfolgen soll, und daß beide - Kanada einerseits und die NAFO-Zone anderseits - die jeweiligen zulässigen Höchstfangmengen in enger Zusammenarbeit und auf der Grundlage wissenschaftlicher Gutachten festlegen sollen.</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "      <td>0.026278</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>739</th>\n",
              "      <td>Several amendments also help clarify the text, and, furthermore, we accept Amendments Nos 4, 7, 8, 14, 27, 28 and 29.</td>\n",
              "      <td>Mehrere Änderungsanträge dienen auch dazu, den Wortlaut zu verbessern.</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "      <td>0.048960</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1664</th>\n",
              "      <td>According to the European Union's Voltairian principles of enlightenment, we should fight to the bitter end precisely for ideals which we do not share.</td>\n",
              "      <td>Die der Aufklärung und Voltaire verpflichteten Grundsätze der Europäischen Union besagen, dass wir unser Leben dafür geben, um zu gewährleisten, dass gerade die Meinungen geäußert werden dürfen, die wir nicht teilen.</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "      <td>0.038687</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5460</th>\n",
              "      <td></td>\n",
              "      <td>Obwohl ich die genannten Vorschläge begrüße, war es mir nicht möglich, den Bericht Haug zu unterstützen.</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "      <td>0.027405</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5191</th>\n",
              "      <td>This debate could not be more timely.</td>\n",
              "      <td>Daher kommt unsere Aussprache zu einem sehr günstigen Augenblick.</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "      <td>0.032074</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2576</th>\n",
              "      <td>The bottom line is in the red but no one accepts any responsibility for it.</td>\n",
              "      <td>Die Bilanz ist negativ, Herr Präsident, doch aus diesem Anlass war keinerlei Selbstkritik zu vernehmen.</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "      <td>0.033037</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4127</th>\n",
              "      <td>As we should be pleased with the outcome, I have endorsed the agreement reached.</td>\n",
              "      <td>Ich hoffe daher, ihre Stimmen auch jetzt zu hören.</td>\n",
              "      <td>0</td>\n",
              "      <td>True</td>\n",
              "      <td>0.977390</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2505</th>\n",
              "      <td>It makes no sense that when staff retire from working for a European Union institution, they can choose to live in any country, but the value of their pension depends on what country they chose to live in.</td>\n",
              "      <td>Herr Harbour ging insbesondere auf einen Antrag zu den Berichtigungskoeffizienten ein.</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "      <td>0.027663</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9688</th>\n",
              "      <td>Now, I do not think that this is the appropriate place to debate this.</td>\n",
              "      <td>Diese Dinge sind nicht hinnehmbar, Herr Präsident.</td>\n",
              "      <td>0</td>\n",
              "      <td>True</td>\n",
              "      <td>0.965850</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1292</th>\n",
              "      <td>I have faith in the type of agreement that we concluded in Cotonou, on 23 January 2000, which introduces the requirement for enhanced political dialogue, without which there can be no economic cooperation.</td>\n",
              "      <td>Nicht dass die Ergebnisse besonders brillant wären, das ist keineswegs der Fall, aber ich glaube an diesen Mechanismus.</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "      <td>0.026543</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                                                                                                                                                                                                    text_source  ... prediction_prob\n",
              "6533  It also confirms the fact that the issue of the price of drugs is at the heart of the debates on access to treatment and the importance of research and development and, above all, it stresses the need to focus efforts on diseases that particularly affect the South, as well as forgotten illnesses.  ...        0.028090\n",
              "4246                                                                                                                                                                                We should be encouraged by the fact that the issue is back where it belongs, that is at scientific and at veterinary level.  ...        0.028881\n",
              "7997                                                                                                                                                                                                                        Are we prepared to tolerate that for the sake of a slice of salami in our sandwich?  ...        0.027997\n",
              "3553                                                                                                                                                                                                                                                                                                             ...        0.033435\n",
              "1603                                                                                                                                                                                                                                                                                 The next item is the vote.  ...        0.168404\n",
              "868                                                                                                                                                                                                                                                              I give the floor to the rapporteur, Mr Herman.  ...        0.027290\n",
              "5674                                                                                                                                                                                                                                                                                                             ...        0.188270\n",
              "3480                                                                                                                                                                We do not wish to sanction but rather to assist. Not to assist for the sake of assisting, but to assist so that the commitments may be met.  ...        0.155421\n",
              "332                                                                                                                                                                                                                                                                               The matter has been deferred.  ...        0.420807\n",
              "6126                                                                                                                                                              Another criterion should be that the young people who take part do not find themselves subjected to repressive measures on their return home.  ...        0.039022\n",
              "3245                                                                                                                                                                                                                                                                                                             ...        0.978042\n",
              "4917                                                                                                                                                                                   They do not want any more promises that we then fail to keep, or to see any efforts that we then fail to follow through.  ...        0.081473\n",
              "6799                                                                                                                                                                                                                                             What are the goals being pursued by the various organisations?  ...        0.196286\n",
              "6721                                                                                                                                                                                                                                               The global economy is in recession, but that is nothing new.  ...        0.031169\n",
              "8929                                                                                                                                                                                                                                              Mr President, I thank the President-in-Office for his answer.  ...        0.147697\n",
              "7324                                                                                                                                                                     I admit, Mrs Beer, that there are a great many issues that remain to be resolved, very serious problems that have not yet been solved.  ...        0.543568\n",
              "6803                                                                                                                                                                                        They also need to be considered in the light of ‘better regulation’, something that they cannot be said to achieve.  ...        0.029670\n",
              "3564                                                                                                                                                                                     Madam President, Candidate for the Commission Presidency, ladies and gentlemen, what is at stake with tomorrow’s vote?  ...        0.057546\n",
              "7814                                                                                                                                                                                                                                                                                                             ...        0.030147\n",
              "4102                                                                                                                                                                                                                                                                          We will see that it is put right.  ...        0.122364\n",
              "6342                                                                                                                                                                                                                                                              There are many different kinds of fanaticism.  ...        0.030353\n",
              "853                                                                                                                                                                                                                  During Mrs Merkel's German Presidency there was unanimous support for a number of targets.  ...        0.268974\n",
              "3769                                                                                                                                                                                     Dictators and their regimes and families should not be allowed to leave their country or to acquire any assets abroad.  ...        0.979810\n",
              "4374                                                                                                                                                                                                                               – Mr President, I was shocked by what Mr Frattini had to say about Chechnya.  ...        0.163072\n",
              "1542                                                                                                                                                                                                                          The opinion of the Committee on Legal Affairs should be taken into consideration.  ...        0.104635\n",
              "6041                                                                                                                                                                                                                                                                                    First of all recycling.  ...        0.458040\n",
              "8864                                                                                                                                                                                                                                                The problem lies in the content of the framework directive.  ...        0.037619\n",
              "5062                                                                                                                                                                                                                                                                    The directive is a mere starting point.  ...        0.161743\n",
              "6347                                                                                                                                                                                                                                                                                                             ...        0.029101\n",
              "9673                                                                                                                                                                                                 The enlargement negotiations have now passed the point of no return and there must be no new demands made.  ...        0.070167\n",
              "5032                                                                              If adopted, these various amendments will undoubtedly turn our Europe - which is already an open door when it comes to immigration - into a Europe where the floodgates are opened to what will become a spate of immigrants.  ...        0.030615\n",
              "8460                                                                                                                                                                                                             It is deliberately this complicated so that no-one can get their head around what it contains.  ...        0.969031\n",
              "547                                                                                                  The proposal by the European Commission, enhanced by the amendments of the Committee on the Environment, Public Health and Consumer Policy, has succeeded in taking both of these principles into account.  ...        0.036302\n",
              "2209                                                                                                                                                                                                                                                                                                             ...        0.026278\n",
              "739                                                                                                                                                                                       Several amendments also help clarify the text, and, furthermore, we accept Amendments Nos 4, 7, 8, 14, 27, 28 and 29.  ...        0.048960\n",
              "1664                                                                                                                                                    According to the European Union's Voltairian principles of enlightenment, we should fight to the bitter end precisely for ideals which we do not share.  ...        0.038687\n",
              "5460                                                                                                                                                                                                                                                                                                             ...        0.027405\n",
              "5191                                                                                                                                                                                                                                                                      This debate could not be more timely.  ...        0.032074\n",
              "2576                                                                                                                                                                                                                                The bottom line is in the red but no one accepts any responsibility for it.  ...        0.033037\n",
              "4127                                                                                                                                                                                                                           As we should be pleased with the outcome, I have endorsed the agreement reached.  ...        0.977390\n",
              "2505                                                                                              It makes no sense that when staff retire from working for a European Union institution, they can choose to live in any country, but the value of their pension depends on what country they chose to live in.  ...        0.027663\n",
              "9688                                                                                                                                                                                                                                     Now, I do not think that this is the appropriate place to debate this.  ...        0.965850\n",
              "1292                                                                                              I have faith in the type of agreement that we concluded in Cotonou, on 23 January 2000, which introduces the requirement for enhanced political dialogue, without which there can be no economic cooperation.  ...        0.026543\n",
              "\n",
              "[43 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "frIcl3kT_G5v"
      },
      "source": [
        ""
      ],
      "execution_count": 71,
      "outputs": []
    }
  ]
}