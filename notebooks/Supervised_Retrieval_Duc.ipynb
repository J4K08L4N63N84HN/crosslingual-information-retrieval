{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Supervised Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In this notebook we use the supervised classification model for a supervised crosslingual information retrieval task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.dirname((os.path.abspath(''))))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, log_loss\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import RFECV\n",
    "from src.models.predict_model import MAP_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## I. Import Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we import the feature dataframe for the retrieval task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_dataframe=pd.read_json(\"../data/processed/feature_dataframe.json\")\n",
    "feature_retrieval=pd.read_json(\"../data/processed/feature_retrieval_reduced.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_id</th>\n",
       "      <th>target_id</th>\n",
       "      <th>number_punctuations_total_difference</th>\n",
       "      <th>number_punctuations_total_difference_relative</th>\n",
       "      <th>number_punctuations_total_difference_normalized</th>\n",
       "      <th>number_words_difference</th>\n",
       "      <th>number_words_difference_relative</th>\n",
       "      <th>number_words_difference_normalized</th>\n",
       "      <th>number_unique_words_difference</th>\n",
       "      <th>number_unique_words_difference_relative</th>\n",
       "      <th>...</th>\n",
       "      <th>pca_embeddding_tf_idf_diff_5</th>\n",
       "      <th>pca_embeddding_average_diff_6</th>\n",
       "      <th>pca_embeddding_tf_idf_diff_6</th>\n",
       "      <th>pca_embeddding_average_diff_7</th>\n",
       "      <th>pca_embeddding_tf_idf_diff_7</th>\n",
       "      <th>pca_embeddding_average_diff_8</th>\n",
       "      <th>pca_embeddding_tf_idf_diff_8</th>\n",
       "      <th>pca_embeddding_average_diff_9</th>\n",
       "      <th>pca_embeddding_tf_idf_diff_9</th>\n",
       "      <th>Translation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>109</td>\n",
       "      <td>109</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>-0.009524</td>\n",
       "      <td>-5</td>\n",
       "      <td>-0.294118</td>\n",
       "      <td>0.009524</td>\n",
       "      <td>-4</td>\n",
       "      <td>-0.250000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004874</td>\n",
       "      <td>-0.047148</td>\n",
       "      <td>-0.008058</td>\n",
       "      <td>-0.084391</td>\n",
       "      <td>-0.023995</td>\n",
       "      <td>0.010583</td>\n",
       "      <td>0.001481</td>\n",
       "      <td>-0.044518</td>\n",
       "      <td>-0.010591</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22684</th>\n",
       "      <td>268</td>\n",
       "      <td>13222</td>\n",
       "      <td>3</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000299</td>\n",
       "      <td>0.013027</td>\n",
       "      <td>-0.001395</td>\n",
       "      <td>0.031509</td>\n",
       "      <td>0.015462</td>\n",
       "      <td>0.030560</td>\n",
       "      <td>0.014559</td>\n",
       "      <td>-0.068374</td>\n",
       "      <td>-0.027733</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212257</th>\n",
       "      <td>19225</td>\n",
       "      <td>17786</td>\n",
       "      <td>1</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>13</td>\n",
       "      <td>1.083333</td>\n",
       "      <td>-0.035714</td>\n",
       "      <td>14</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.048708</td>\n",
       "      <td>-0.071461</td>\n",
       "      <td>-0.028607</td>\n",
       "      <td>0.043429</td>\n",
       "      <td>0.007141</td>\n",
       "      <td>0.119771</td>\n",
       "      <td>0.028388</td>\n",
       "      <td>-0.099804</td>\n",
       "      <td>-0.028861</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128119</th>\n",
       "      <td>10811</td>\n",
       "      <td>8960</td>\n",
       "      <td>4</td>\n",
       "      <td>4.00</td>\n",
       "      <td>-0.097222</td>\n",
       "      <td>11</td>\n",
       "      <td>1.375000</td>\n",
       "      <td>0.097222</td>\n",
       "      <td>11</td>\n",
       "      <td>1.375000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.026901</td>\n",
       "      <td>-0.047534</td>\n",
       "      <td>-0.018759</td>\n",
       "      <td>0.086064</td>\n",
       "      <td>0.023210</td>\n",
       "      <td>0.048726</td>\n",
       "      <td>0.012149</td>\n",
       "      <td>-0.054367</td>\n",
       "      <td>-0.012938</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181804</th>\n",
       "      <td>16180</td>\n",
       "      <td>17021</td>\n",
       "      <td>3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.150000</td>\n",
       "      <td>10</td>\n",
       "      <td>1.428571</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>10</td>\n",
       "      <td>1.428571</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.047277</td>\n",
       "      <td>0.034917</td>\n",
       "      <td>0.010096</td>\n",
       "      <td>-0.031786</td>\n",
       "      <td>-0.018326</td>\n",
       "      <td>0.035693</td>\n",
       "      <td>0.008005</td>\n",
       "      <td>-0.027249</td>\n",
       "      <td>-0.007824</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202319</th>\n",
       "      <td>18231</td>\n",
       "      <td>7359</td>\n",
       "      <td>2</td>\n",
       "      <td>2.00</td>\n",
       "      <td>-0.130952</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.130952</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.055980</td>\n",
       "      <td>0.061674</td>\n",
       "      <td>0.016336</td>\n",
       "      <td>-0.008921</td>\n",
       "      <td>-0.007011</td>\n",
       "      <td>0.085686</td>\n",
       "      <td>0.024694</td>\n",
       "      <td>-0.091589</td>\n",
       "      <td>-0.027445</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7113</th>\n",
       "      <td>7113</td>\n",
       "      <td>7113</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004311</td>\n",
       "      <td>-0.183242</td>\n",
       "      <td>-0.110884</td>\n",
       "      <td>-0.089385</td>\n",
       "      <td>-0.054618</td>\n",
       "      <td>0.149621</td>\n",
       "      <td>0.075848</td>\n",
       "      <td>-0.097817</td>\n",
       "      <td>-0.055209</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141879</th>\n",
       "      <td>12187</td>\n",
       "      <td>11226</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>0.015152</td>\n",
       "      <td>-4</td>\n",
       "      <td>-0.444444</td>\n",
       "      <td>-0.015152</td>\n",
       "      <td>-3</td>\n",
       "      <td>-0.375000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005525</td>\n",
       "      <td>-0.063130</td>\n",
       "      <td>-0.002613</td>\n",
       "      <td>-0.031770</td>\n",
       "      <td>-0.011397</td>\n",
       "      <td>0.092851</td>\n",
       "      <td>0.040517</td>\n",
       "      <td>-0.175271</td>\n",
       "      <td>-0.062434</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185057</th>\n",
       "      <td>16505</td>\n",
       "      <td>5751</td>\n",
       "      <td>4</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.142857</td>\n",
       "      <td>13</td>\n",
       "      <td>1.181818</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>13</td>\n",
       "      <td>1.181818</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.030264</td>\n",
       "      <td>-0.091880</td>\n",
       "      <td>-0.027707</td>\n",
       "      <td>0.059644</td>\n",
       "      <td>0.011309</td>\n",
       "      <td>0.032890</td>\n",
       "      <td>0.005979</td>\n",
       "      <td>-0.039682</td>\n",
       "      <td>-0.009445</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178487</th>\n",
       "      <td>15848</td>\n",
       "      <td>11637</td>\n",
       "      <td>3</td>\n",
       "      <td>1.50</td>\n",
       "      <td>-0.167920</td>\n",
       "      <td>-5</td>\n",
       "      <td>-0.263158</td>\n",
       "      <td>0.167920</td>\n",
       "      <td>-5</td>\n",
       "      <td>-0.263158</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.013344</td>\n",
       "      <td>-0.026538</td>\n",
       "      <td>-0.004632</td>\n",
       "      <td>-0.038526</td>\n",
       "      <td>-0.006279</td>\n",
       "      <td>-0.008371</td>\n",
       "      <td>-0.006343</td>\n",
       "      <td>-0.053240</td>\n",
       "      <td>-0.011142</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>220000 rows × 169 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        source_id  target_id  number_punctuations_total_difference  \\\n",
       "109           109        109                                    -1   \n",
       "22684         268      13222                                     3   \n",
       "212257      19225      17786                                     1   \n",
       "128119      10811       8960                                     4   \n",
       "181804      16180      17021                                     3   \n",
       "...           ...        ...                                   ...   \n",
       "202319      18231       7359                                     2   \n",
       "7113         7113       7113                                     0   \n",
       "141879      12187      11226                                    -1   \n",
       "185057      16505       5751                                     4   \n",
       "178487      15848      11637                                     3   \n",
       "\n",
       "        number_punctuations_total_difference_relative  \\\n",
       "109                                             -0.25   \n",
       "22684                                            3.00   \n",
       "212257                                           0.50   \n",
       "128119                                           4.00   \n",
       "181804                                           0.00   \n",
       "...                                               ...   \n",
       "202319                                           2.00   \n",
       "7113                                             0.00   \n",
       "141879                                          -0.50   \n",
       "185057                                           0.00   \n",
       "178487                                           1.50   \n",
       "\n",
       "        number_punctuations_total_difference_normalized  \\\n",
       "109                                           -0.009524   \n",
       "22684                                          0.000000   \n",
       "212257                                         0.035714   \n",
       "128119                                        -0.097222   \n",
       "181804                                        -0.150000   \n",
       "...                                                 ...   \n",
       "202319                                        -0.130952   \n",
       "7113                                           0.000000   \n",
       "141879                                         0.015152   \n",
       "185057                                        -0.142857   \n",
       "178487                                        -0.167920   \n",
       "\n",
       "        number_words_difference  number_words_difference_relative  \\\n",
       "109                          -5                         -0.294118   \n",
       "22684                        18                          3.000000   \n",
       "212257                       13                          1.083333   \n",
       "128119                       11                          1.375000   \n",
       "181804                       10                          1.428571   \n",
       "...                         ...                               ...   \n",
       "202319                        0                          0.000000   \n",
       "7113                          0                          0.000000   \n",
       "141879                       -4                         -0.444444   \n",
       "185057                       13                          1.181818   \n",
       "178487                       -5                         -0.263158   \n",
       "\n",
       "        number_words_difference_normalized  number_unique_words_difference  \\\n",
       "109                               0.009524                              -4   \n",
       "22684                             0.000000                              18   \n",
       "212257                           -0.035714                              14   \n",
       "128119                            0.097222                              11   \n",
       "181804                            0.150000                              10   \n",
       "...                                    ...                             ...   \n",
       "202319                            0.130952                               0   \n",
       "7113                              0.000000                               0   \n",
       "141879                           -0.015152                              -3   \n",
       "185057                            0.142857                              13   \n",
       "178487                            0.167920                              -5   \n",
       "\n",
       "        number_unique_words_difference_relative  ...  \\\n",
       "109                                   -0.250000  ...   \n",
       "22684                                  3.000000  ...   \n",
       "212257                                 1.400000  ...   \n",
       "128119                                 1.375000  ...   \n",
       "181804                                 1.428571  ...   \n",
       "...                                         ...  ...   \n",
       "202319                                 0.000000  ...   \n",
       "7113                                   0.000000  ...   \n",
       "141879                                -0.375000  ...   \n",
       "185057                                 1.181818  ...   \n",
       "178487                                -0.263158  ...   \n",
       "\n",
       "        pca_embeddding_tf_idf_diff_5  pca_embeddding_average_diff_6  \\\n",
       "109                        -0.004874                      -0.047148   \n",
       "22684                      -0.000299                       0.013027   \n",
       "212257                     -0.048708                      -0.071461   \n",
       "128119                     -0.026901                      -0.047534   \n",
       "181804                     -0.047277                       0.034917   \n",
       "...                              ...                            ...   \n",
       "202319                     -0.055980                       0.061674   \n",
       "7113                       -0.004311                      -0.183242   \n",
       "141879                     -0.005525                      -0.063130   \n",
       "185057                     -0.030264                      -0.091880   \n",
       "178487                     -0.013344                      -0.026538   \n",
       "\n",
       "        pca_embeddding_tf_idf_diff_6  pca_embeddding_average_diff_7  \\\n",
       "109                        -0.008058                      -0.084391   \n",
       "22684                      -0.001395                       0.031509   \n",
       "212257                     -0.028607                       0.043429   \n",
       "128119                     -0.018759                       0.086064   \n",
       "181804                      0.010096                      -0.031786   \n",
       "...                              ...                            ...   \n",
       "202319                      0.016336                      -0.008921   \n",
       "7113                       -0.110884                      -0.089385   \n",
       "141879                     -0.002613                      -0.031770   \n",
       "185057                     -0.027707                       0.059644   \n",
       "178487                     -0.004632                      -0.038526   \n",
       "\n",
       "        pca_embeddding_tf_idf_diff_7  pca_embeddding_average_diff_8  \\\n",
       "109                        -0.023995                       0.010583   \n",
       "22684                       0.015462                       0.030560   \n",
       "212257                      0.007141                       0.119771   \n",
       "128119                      0.023210                       0.048726   \n",
       "181804                     -0.018326                       0.035693   \n",
       "...                              ...                            ...   \n",
       "202319                     -0.007011                       0.085686   \n",
       "7113                       -0.054618                       0.149621   \n",
       "141879                     -0.011397                       0.092851   \n",
       "185057                      0.011309                       0.032890   \n",
       "178487                     -0.006279                      -0.008371   \n",
       "\n",
       "        pca_embeddding_tf_idf_diff_8  pca_embeddding_average_diff_9  \\\n",
       "109                         0.001481                      -0.044518   \n",
       "22684                       0.014559                      -0.068374   \n",
       "212257                      0.028388                      -0.099804   \n",
       "128119                      0.012149                      -0.054367   \n",
       "181804                      0.008005                      -0.027249   \n",
       "...                              ...                            ...   \n",
       "202319                      0.024694                      -0.091589   \n",
       "7113                        0.075848                      -0.097817   \n",
       "141879                      0.040517                      -0.175271   \n",
       "185057                      0.005979                      -0.039682   \n",
       "178487                     -0.006343                      -0.053240   \n",
       "\n",
       "        pca_embeddding_tf_idf_diff_9  Translation  \n",
       "109                        -0.010591            1  \n",
       "22684                      -0.027733            0  \n",
       "212257                     -0.028861            0  \n",
       "128119                     -0.012938            0  \n",
       "181804                     -0.007824            0  \n",
       "...                              ...          ...  \n",
       "202319                     -0.027445            0  \n",
       "7113                       -0.055209            1  \n",
       "141879                     -0.062434            0  \n",
       "185057                     -0.009445            0  \n",
       "178487                     -0.011142            0  \n",
       "\n",
       "[220000 rows x 169 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_dataframe=feature_dataframe.sample(frac=1)\n",
    "feature_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Supervised Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First iteration after dropping correlated features from analyes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'characters_avg_difference_relative',\n",
       " 'cosine_similarity_tf_idf',\n",
       " 'euclidean_distance_tf_idf',\n",
       " 'jaccard_translation_target',\n",
       " 'number_#_difference_normalized',\n",
       " 'number_#_difference_relative',\n",
       " 'number_$_difference_normalized',\n",
       " 'number_$_difference_relative',\n",
       " 'number_%_difference_normalized',\n",
       " 'number_&_difference_normalized',\n",
       " \"number_'_difference_normalized\",\n",
       " \"number_'_difference_relative\",\n",
       " 'number_)_difference',\n",
       " 'number_)_difference_normalized',\n",
       " 'number_)_difference_relative',\n",
       " 'number_+_difference_normalized',\n",
       " 'number_+_difference_relative',\n",
       " 'number_,_difference',\n",
       " 'number_,_difference_relative',\n",
       " 'number_-_difference_normalized',\n",
       " 'number_._difference_relative',\n",
       " 'number_/_difference_normalized',\n",
       " 'number_NOUN_difference',\n",
       " 'number_[_difference_normalized',\n",
       " 'number_[_difference_relative',\n",
       " 'number_]_difference',\n",
       " 'number_]_difference_normalized',\n",
       " 'number_]_difference_relative',\n",
       " 'number_characters_difference',\n",
       " 'number_characters_difference_relative',\n",
       " 'number_stopwords_difference',\n",
       " 'number_unique_words_difference',\n",
       " 'number_unique_words_difference_normalized',\n",
       " 'number_unique_words_difference_relative',\n",
       " 'number_words_difference_normalized',\n",
       " 'pca_embeddding_tf_idf_diff_1',\n",
       " 'pca_embeddding_tf_idf_diff_3',\n",
       " 'pca_embeddding_tf_idf_diff_4',\n",
       " 'pca_embeddding_tf_idf_diff_5',\n",
       " 'pca_embeddding_tf_idf_diff_6',\n",
       " 'pca_embeddding_tf_idf_diff_7',\n",
       " 'pca_embeddding_tf_idf_diff_8',\n",
       " 'pca_embeddding_tf_idf_diff_9'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle \n",
    "file = open(\"../data/processed/correlated_features.pkl\",'rb')\n",
    "correlated_features = pickle.load(file)\n",
    "file.close()\n",
    "correlated_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_id</th>\n",
       "      <th>target_id</th>\n",
       "      <th>number_punctuations_total_difference</th>\n",
       "      <th>number_punctuations_total_difference_relative</th>\n",
       "      <th>number_punctuations_total_difference_normalized</th>\n",
       "      <th>number_words_difference</th>\n",
       "      <th>number_words_difference_relative</th>\n",
       "      <th>number_!_difference</th>\n",
       "      <th>number_!_difference_relative</th>\n",
       "      <th>number_!_difference_normalized</th>\n",
       "      <th>...</th>\n",
       "      <th>pca_embeddding_average_diff_2</th>\n",
       "      <th>pca_embeddding_tf_idf_diff_2</th>\n",
       "      <th>pca_embeddding_average_diff_3</th>\n",
       "      <th>pca_embeddding_average_diff_4</th>\n",
       "      <th>pca_embeddding_average_diff_5</th>\n",
       "      <th>pca_embeddding_average_diff_6</th>\n",
       "      <th>pca_embeddding_average_diff_7</th>\n",
       "      <th>pca_embeddding_average_diff_8</th>\n",
       "      <th>pca_embeddding_average_diff_9</th>\n",
       "      <th>Translation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>109</td>\n",
       "      <td>109</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>-0.009524</td>\n",
       "      <td>-5</td>\n",
       "      <td>-0.294118</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.066667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>-0.001361</td>\n",
       "      <td>-0.003251</td>\n",
       "      <td>-0.058206</td>\n",
       "      <td>-0.042816</td>\n",
       "      <td>-0.047148</td>\n",
       "      <td>-0.084391</td>\n",
       "      <td>0.010583</td>\n",
       "      <td>-0.044518</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22684</th>\n",
       "      <td>268</td>\n",
       "      <td>13222</td>\n",
       "      <td>3</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.059663</td>\n",
       "      <td>-0.005186</td>\n",
       "      <td>-0.023072</td>\n",
       "      <td>-0.005830</td>\n",
       "      <td>0.000950</td>\n",
       "      <td>0.013027</td>\n",
       "      <td>0.031509</td>\n",
       "      <td>0.030560</td>\n",
       "      <td>-0.068374</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212257</th>\n",
       "      <td>19225</td>\n",
       "      <td>17786</td>\n",
       "      <td>1</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>13</td>\n",
       "      <td>1.083333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009355</td>\n",
       "      <td>0.006870</td>\n",
       "      <td>0.021219</td>\n",
       "      <td>-0.053048</td>\n",
       "      <td>-0.169190</td>\n",
       "      <td>-0.071461</td>\n",
       "      <td>0.043429</td>\n",
       "      <td>0.119771</td>\n",
       "      <td>-0.099804</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128119</th>\n",
       "      <td>10811</td>\n",
       "      <td>8960</td>\n",
       "      <td>4</td>\n",
       "      <td>4.00</td>\n",
       "      <td>-0.097222</td>\n",
       "      <td>11</td>\n",
       "      <td>1.375000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.028330</td>\n",
       "      <td>-0.010495</td>\n",
       "      <td>-0.026490</td>\n",
       "      <td>-0.086742</td>\n",
       "      <td>-0.097948</td>\n",
       "      <td>-0.047534</td>\n",
       "      <td>0.086064</td>\n",
       "      <td>0.048726</td>\n",
       "      <td>-0.054367</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181804</th>\n",
       "      <td>16180</td>\n",
       "      <td>17021</td>\n",
       "      <td>3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.150000</td>\n",
       "      <td>10</td>\n",
       "      <td>1.428571</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.087906</td>\n",
       "      <td>-0.012733</td>\n",
       "      <td>0.107612</td>\n",
       "      <td>0.004078</td>\n",
       "      <td>-0.100966</td>\n",
       "      <td>0.034917</td>\n",
       "      <td>-0.031786</td>\n",
       "      <td>0.035693</td>\n",
       "      <td>-0.027249</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202319</th>\n",
       "      <td>18231</td>\n",
       "      <td>7359</td>\n",
       "      <td>2</td>\n",
       "      <td>2.00</td>\n",
       "      <td>-0.130952</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.040491</td>\n",
       "      <td>0.011073</td>\n",
       "      <td>0.013887</td>\n",
       "      <td>-0.014963</td>\n",
       "      <td>-0.177531</td>\n",
       "      <td>0.061674</td>\n",
       "      <td>-0.008921</td>\n",
       "      <td>0.085686</td>\n",
       "      <td>-0.091589</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7113</th>\n",
       "      <td>7113</td>\n",
       "      <td>7113</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.034515</td>\n",
       "      <td>-0.004604</td>\n",
       "      <td>0.347093</td>\n",
       "      <td>0.121631</td>\n",
       "      <td>0.045028</td>\n",
       "      <td>-0.183242</td>\n",
       "      <td>-0.089385</td>\n",
       "      <td>0.149621</td>\n",
       "      <td>-0.097817</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141879</th>\n",
       "      <td>12187</td>\n",
       "      <td>11226</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>0.015152</td>\n",
       "      <td>-4</td>\n",
       "      <td>-0.444444</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019947</td>\n",
       "      <td>0.000543</td>\n",
       "      <td>0.058875</td>\n",
       "      <td>0.026531</td>\n",
       "      <td>-0.057264</td>\n",
       "      <td>-0.063130</td>\n",
       "      <td>-0.031770</td>\n",
       "      <td>0.092851</td>\n",
       "      <td>-0.175271</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185057</th>\n",
       "      <td>16505</td>\n",
       "      <td>5751</td>\n",
       "      <td>4</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.142857</td>\n",
       "      <td>13</td>\n",
       "      <td>1.181818</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.102474</td>\n",
       "      <td>-0.024596</td>\n",
       "      <td>0.005421</td>\n",
       "      <td>-0.048078</td>\n",
       "      <td>-0.109183</td>\n",
       "      <td>-0.091880</td>\n",
       "      <td>0.059644</td>\n",
       "      <td>0.032890</td>\n",
       "      <td>-0.039682</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178487</th>\n",
       "      <td>15848</td>\n",
       "      <td>11637</td>\n",
       "      <td>3</td>\n",
       "      <td>1.50</td>\n",
       "      <td>-0.167920</td>\n",
       "      <td>-5</td>\n",
       "      <td>-0.263158</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.052632</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.023513</td>\n",
       "      <td>-0.004947</td>\n",
       "      <td>0.069368</td>\n",
       "      <td>-0.036508</td>\n",
       "      <td>-0.070284</td>\n",
       "      <td>-0.026538</td>\n",
       "      <td>-0.038526</td>\n",
       "      <td>-0.008371</td>\n",
       "      <td>-0.053240</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>220000 rows × 126 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        source_id  target_id  number_punctuations_total_difference  \\\n",
       "109           109        109                                    -1   \n",
       "22684         268      13222                                     3   \n",
       "212257      19225      17786                                     1   \n",
       "128119      10811       8960                                     4   \n",
       "181804      16180      17021                                     3   \n",
       "...           ...        ...                                   ...   \n",
       "202319      18231       7359                                     2   \n",
       "7113         7113       7113                                     0   \n",
       "141879      12187      11226                                    -1   \n",
       "185057      16505       5751                                     4   \n",
       "178487      15848      11637                                     3   \n",
       "\n",
       "        number_punctuations_total_difference_relative  \\\n",
       "109                                             -0.25   \n",
       "22684                                            3.00   \n",
       "212257                                           0.50   \n",
       "128119                                           4.00   \n",
       "181804                                           0.00   \n",
       "...                                               ...   \n",
       "202319                                           2.00   \n",
       "7113                                             0.00   \n",
       "141879                                          -0.50   \n",
       "185057                                           0.00   \n",
       "178487                                           1.50   \n",
       "\n",
       "        number_punctuations_total_difference_normalized  \\\n",
       "109                                           -0.009524   \n",
       "22684                                          0.000000   \n",
       "212257                                         0.035714   \n",
       "128119                                        -0.097222   \n",
       "181804                                        -0.150000   \n",
       "...                                                 ...   \n",
       "202319                                        -0.130952   \n",
       "7113                                           0.000000   \n",
       "141879                                         0.015152   \n",
       "185057                                        -0.142857   \n",
       "178487                                        -0.167920   \n",
       "\n",
       "        number_words_difference  number_words_difference_relative  \\\n",
       "109                          -5                         -0.294118   \n",
       "22684                        18                          3.000000   \n",
       "212257                       13                          1.083333   \n",
       "128119                       11                          1.375000   \n",
       "181804                       10                          1.428571   \n",
       "...                         ...                               ...   \n",
       "202319                        0                          0.000000   \n",
       "7113                          0                          0.000000   \n",
       "141879                       -4                         -0.444444   \n",
       "185057                       13                          1.181818   \n",
       "178487                       -5                         -0.263158   \n",
       "\n",
       "        number_!_difference  number_!_difference_relative  \\\n",
       "109                       1                             0   \n",
       "22684                     0                             0   \n",
       "212257                    0                             0   \n",
       "128119                    0                             0   \n",
       "181804                    0                             0   \n",
       "...                     ...                           ...   \n",
       "202319                    0                             0   \n",
       "7113                      0                             0   \n",
       "141879                    0                             0   \n",
       "185057                    0                             0   \n",
       "178487                    1                             0   \n",
       "\n",
       "        number_!_difference_normalized  ...  pca_embeddding_average_diff_2  \\\n",
       "109                          -0.066667  ...                       0.000003   \n",
       "22684                         0.000000  ...                      -0.059663   \n",
       "212257                        0.000000  ...                       0.009355   \n",
       "128119                        0.000000  ...                      -0.028330   \n",
       "181804                        0.000000  ...                      -0.087906   \n",
       "...                                ...  ...                            ...   \n",
       "202319                        0.000000  ...                       0.040491   \n",
       "7113                          0.000000  ...                      -0.034515   \n",
       "141879                        0.000000  ...                       0.019947   \n",
       "185057                        0.000000  ...                      -0.102474   \n",
       "178487                       -0.052632  ...                      -0.023513   \n",
       "\n",
       "        pca_embeddding_tf_idf_diff_2  pca_embeddding_average_diff_3  \\\n",
       "109                        -0.001361                      -0.003251   \n",
       "22684                      -0.005186                      -0.023072   \n",
       "212257                      0.006870                       0.021219   \n",
       "128119                     -0.010495                      -0.026490   \n",
       "181804                     -0.012733                       0.107612   \n",
       "...                              ...                            ...   \n",
       "202319                      0.011073                       0.013887   \n",
       "7113                       -0.004604                       0.347093   \n",
       "141879                      0.000543                       0.058875   \n",
       "185057                     -0.024596                       0.005421   \n",
       "178487                     -0.004947                       0.069368   \n",
       "\n",
       "        pca_embeddding_average_diff_4  pca_embeddding_average_diff_5  \\\n",
       "109                         -0.058206                      -0.042816   \n",
       "22684                       -0.005830                       0.000950   \n",
       "212257                      -0.053048                      -0.169190   \n",
       "128119                      -0.086742                      -0.097948   \n",
       "181804                       0.004078                      -0.100966   \n",
       "...                               ...                            ...   \n",
       "202319                      -0.014963                      -0.177531   \n",
       "7113                         0.121631                       0.045028   \n",
       "141879                       0.026531                      -0.057264   \n",
       "185057                      -0.048078                      -0.109183   \n",
       "178487                      -0.036508                      -0.070284   \n",
       "\n",
       "        pca_embeddding_average_diff_6  pca_embeddding_average_diff_7  \\\n",
       "109                         -0.047148                      -0.084391   \n",
       "22684                        0.013027                       0.031509   \n",
       "212257                      -0.071461                       0.043429   \n",
       "128119                      -0.047534                       0.086064   \n",
       "181804                       0.034917                      -0.031786   \n",
       "...                               ...                            ...   \n",
       "202319                       0.061674                      -0.008921   \n",
       "7113                        -0.183242                      -0.089385   \n",
       "141879                      -0.063130                      -0.031770   \n",
       "185057                      -0.091880                       0.059644   \n",
       "178487                      -0.026538                      -0.038526   \n",
       "\n",
       "        pca_embeddding_average_diff_8  pca_embeddding_average_diff_9  \\\n",
       "109                          0.010583                      -0.044518   \n",
       "22684                        0.030560                      -0.068374   \n",
       "212257                       0.119771                      -0.099804   \n",
       "128119                       0.048726                      -0.054367   \n",
       "181804                       0.035693                      -0.027249   \n",
       "...                               ...                            ...   \n",
       "202319                       0.085686                      -0.091589   \n",
       "7113                         0.149621                      -0.097817   \n",
       "141879                       0.092851                      -0.175271   \n",
       "185057                       0.032890                      -0.039682   \n",
       "178487                      -0.008371                      -0.053240   \n",
       "\n",
       "        Translation  \n",
       "109               1  \n",
       "22684             0  \n",
       "212257            0  \n",
       "128119            0  \n",
       "181804            0  \n",
       "...             ...  \n",
       "202319            0  \n",
       "7113              1  \n",
       "141879            0  \n",
       "185057            0  \n",
       "178487            0  \n",
       "\n",
       "[220000 rows x 126 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_dataframe=feature_dataframe.drop(columns=correlated_features)\n",
    "feature_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_dataframe=feature_dataframe.drop(columns=['word_mover_distance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([], dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_dataframe.columns.difference(feature_retrieval.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### drop the target label and the indexes for training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_train=feature_dataframe['Translation'].astype(float)\n",
    "data_train=feature_dataframe.drop(columns=['Translation','source_id','target_id'])\n",
    "target_test=feature_retrieval['Translation'].astype(float)\n",
    "data_test=feature_retrieval.drop(columns=['Translation','source_id','target_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_columns = list(range(106, 110))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = data_train.iloc[:, keep_columns]\n",
    "data_test = data_test.iloc[:, keep_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['cosine_similarity_average', 'euclidean_distance_average',\n",
       "       'jaccard_translation_source', 'jaccard_numbers_source'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scale data into [0,1]\n",
    "scaler = preprocessing.StandardScaler()\n",
    "#scaler = preprocessing.MinMaxScaler()\n",
    "data_train[data_train.columns] = scaler.fit_transform(data_train[data_train.columns])\n",
    "data_test[data_test.columns] = scaler.transform(data_test[data_test.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "\n",
    "def downsample(imbalanced_data):\n",
    "    y = imbalanced_data[\"Translation\"].astype(int)\n",
    "    y = np.where((y == 0), 0, 1)\n",
    "    \n",
    "    # Indicies of each class' observations\n",
    "    i_class0 = np.where(y == 0)[0]\n",
    "    i_class1 = np.where(y == 1)[0]\n",
    "\n",
    "    # Number of observations in each class\n",
    "    n_class0 = len(i_class0)\n",
    "    n_class1 = len(i_class1)\n",
    "    print(\"Class 0 size: {}\".format(n_class0))\n",
    "    print(\"Class 1 size: {}\".format(n_class1))\n",
    "\n",
    "    # For every observation of class 1, randomly sample from class 0 without replacement\n",
    "    i_class0_downsampled = np.random.choice(i_class0, size=n_class1, replace=False)\n",
    "    print(\"After Downsampling:\")\n",
    "    print(\"Class 0 size: {}\".format(len(i_class0_downsampled)))\n",
    "    print(\"Class 1 size: {}\".format(n_class1))\n",
    "    index_balanced = i_class0_downsampled.tolist() + i_class1.tolist()\n",
    "    index_balanced = shuffle(index_balanced, random_state=42)\n",
    "    return imbalanced_data.iloc[index_balanced, :]\n",
    "\n",
    "#data_train[\"Translation\"] = target_train\n",
    "#data_train = downsample(data_train)\n",
    "#target_train=data_train['Translation']\n",
    "#data_train=data_train.drop(columns=['Translation'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MAP score on test set: 0.6800\n"
     ]
    }
   ],
   "source": [
    "nb = GaussianNB().fit(data_train, target_train)\n",
    "prediction = nb.predict_proba(data_test)\n",
    "print(\"The MAP score on test set: {:.4f}\".format(MAP_score(feature_retrieval['source_id'],target_test,prediction)))\n",
    "# acc = accuracy_score(target_test,prediction) \n",
    "# f1= f1_score(target_test,prediction) \n",
    "# pr= precision_score(target_test,prediction) \n",
    "# re= recall_score(target_test,prediction)\n",
    "# ll=log_loss(target_test,prediction)\n",
    "# print(\"The Accuracy on test set: {:.4f}\".format(acc))\n",
    "# print(\"The F1-Score on test set: {:.4f}\".format(f1))\n",
    "# print(\"The Precision-Score on test set: {:.4f}\".format(pr))\n",
    "# print(\"The Recall-Score on test set: {:.4f}\".format(re))\n",
    "# print(\"The Los_loss on test set: {:.4f}\".format(ll))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.65384284e-12, 1.00000000e+00],\n",
       "       [9.99868929e-01, 1.31071357e-04],\n",
       "       [9.99778234e-01, 2.21766386e-04],\n",
       "       ...,\n",
       "       [9.99797580e-01, 2.02419995e-04],\n",
       "       [9.99729662e-01, 2.70337587e-04],\n",
       "       [9.92018231e-01, 7.98176869e-03]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prediction ist schwachsinn, da nur 0 mit confidence 1 predicted wird"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MAP score on test set: 0.7500\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier().fit(data_train, target_train)\n",
    "prediction = mlp.predict_proba(data_test)\n",
    "print(\"The MAP score on test set: {:.4f}\".format(MAP_score(feature_retrieval['source_id'],target_test,prediction)))\n",
    "# acc = accuracy_score(target_test,prediction) \n",
    "# f1= f1_score(target_test,prediction) \n",
    "# pr= precision_score(target_test,prediction) \n",
    "# re= recall_score(target_test,prediction) \n",
    "# ll=log_loss(target_test,prediction)\n",
    "# print(\"The Accuracy on test set: {:.4f}\".format(acc))\n",
    "# print(\"The F1-Score on test set: {:.4f}\".format(f1))\n",
    "# print(\"The Precision-Score on test set: {:.4f}\".format(pr))\n",
    "# print(\"The Recall-Score on test set: {:.4f}\".format(re))\n",
    "# print(\"The Los_loss on test set: {:.4f}\".format(ll))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MAP score on test set: 0.6759\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(max_iter=1000000).fit(data_train.to_numpy(), target_train.to_numpy())\n",
    "prediction = lr.predict_proba(data_test.to_numpy())\n",
    "print(\"The MAP score on test set: {:.4f}\".format(MAP_score(feature_retrieval['source_id'],target_test,prediction)))\n",
    "# acc = accuracy_score(target_test,prediction) \n",
    "# f1= f1_score(target_test,prediction) \n",
    "# pr= precision_score(target_test,prediction) \n",
    "# re= recall_score(target_test,prediction) \n",
    "# ll=log_loss(target_test,prediction)\n",
    "# print(\"The Accuracy on test set: {:.4f}\".format(acc))\n",
    "# print(\"The F1-Score on test set: {:.4f}\".format(f1))\n",
    "# print(\"The Precision-Score on test set: {:.4f}\".format(pr))\n",
    "# print(\"The Recall-Score on test set: {:.4f}\".format(re))\n",
    "# print(\"The Los_loss on test set: {:.4f}\".format(ll))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: 0, Score: -0.28636\n",
      "Feature: 1, Score: 0.13939\n",
      "Feature: 2, Score: 3.51967\n",
      "Feature: 3, Score: 0.60266\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot\n",
    "# get importance\n",
    "importance = lr.coef_[0]\n",
    "# summarize feature importance\n",
    "for i,v in enumerate(importance):\n",
    "    print('Feature: %0d, Score: %.5f' % (i,v))\n",
    "# plot feature importance\n",
    "pyplot.bar([x for x in range(len(importance))], importance)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/I534344/opt/anaconda3/envs/ml/lib/python3.6/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:57:16] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=8, num_parallel_tree=1, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "model = XGBClassifier()\n",
    "model.fit(data_train.to_numpy(), target_train.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MAP score on test set: 0.6635\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict_proba(data_test).tolist()\n",
    "print(\"The MAP score on test set: {:.4f}\".format(MAP_score(feature_retrieval['source_id'],target_test,prediction)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot\n",
    "\n",
    "# feature importance\n",
    "\n",
    "pyplot.bar(range(len(model.feature_importances_)), model.feature_importances_)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try Autoencoder dimenstionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers, Input, Model\n",
    "\n",
    "target_train=feature_dataframe['Translation'].astype(float)\n",
    "data_train=feature_dataframe.drop(columns=['Translation','source_id','target_id'])\n",
    "target_test=feature_retrieval['Translation'].astype(float)\n",
    "data_test=feature_retrieval.drop(columns=['Translation','source_id','target_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler()\n",
    "#scaler = preprocessing.MinMaxScaler()\n",
    "data_train[data_train.columns] = scaler.fit_transform(data_train[data_train.columns])\n",
    "data_test[data_test.columns] = scaler.transform(data_test[data_test.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = data_train.shape[1]\n",
    "encoding_dim = 30\n",
    "print(\"Input dim: {}\".format(data_train.shape))\n",
    "\n",
    "input_df = Input(shape=(input_shape,))\n",
    "encoded = layers.Dense(encoding_dim, activation=\"linear\", kernel_initializer=keras.initializers.Ones())(input_df)\n",
    "decoded = layers.Dense(input_shape, activation=\"linear\", kernel_initializer=keras.initializers.Ones())(encoded)\n",
    "\n",
    "# encoder\n",
    "autoencoder = Model(input_df, decoded)\n",
    "\n",
    "# intermediate result\n",
    "encoder = Model(input_df, encoded)\n",
    "opt=keras.optimizers.Adam(learning_rate=0.01)\n",
    "autoencoder.compile(optimizer=opt, loss='mean_squared_error')\n",
    "\n",
    "autoencoder.fit(data_train.iloc[:200000, :], data_train.iloc[:200000, :],\n",
    "                epochs=150,\n",
    "                batch_size=256,\n",
    "                shuffle=True,\n",
    "                validation_data=(data_train.iloc[200000:, :], data_train.iloc[200000:, :]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_data_train = encoder.predict(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_data_test = encoder.predict(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(max_iter=1000000).fit(encode_data_train, target_train.to_numpy())\n",
    "prediction = lr.predict_proba(encode_data_test)\n",
    "print(\"The MAP score on test set: {:.4f}\".format(MAP_score(feature_retrieval['source_id'],target_test,prediction)))\n",
    "# acc = accuracy_score(target_test,prediction) \n",
    "# f1= f1_score(target_test,prediction) \n",
    "# pr= precision_score(target_test,prediction) \n",
    "# re= recall_score(target_test,prediction) \n",
    "# ll=log_loss(target_test,prediction)\n",
    "# print(\"The Accuracy on test set: {:.4f}\".format(acc))\n",
    "# print(\"The F1-Score on test set: {:.4f}\".format(f1))\n",
    "# print(\"The Precision-Score on test set: {:.4f}\".format(pr))\n",
    "# print(\"The Recall-Score on test set: {:.4f}\".format(re))\n",
    "# print(\"The Los_loss on test set: {:.4f}\".format(ll))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
