{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Preprocessing and Feature Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In this notebook we import the data, preprocess the data and create features for supervised and unsupervised cross-lingual-information retrieval models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## I. Import Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we import the English and German europarl datasets and combine them into a parallel sentence translation dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.dirname((os.path.abspath(''))))\n",
    "\n",
    "from src.data import create_data_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_data_subset(sentence_data_source_path='../data/external/europarl-v7.it-en.en',\n",
    "                   sentence_data_target_path='../data/external/europarl-v7.it-en.it',\n",
    "                   sample_size=25000,\n",
    "                   sentence_data_sampled_path=\"../data/interim/europarl_en_it.pkl\",)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## II. Preprocess data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we preprocess the parallel sentence data for the feature generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from nltk.corpus import stopwords\n",
    "from textblob import TextBlob as textblob_source\n",
    "from textblob_de import TextBlobDE as textblob_target\n",
    "import en_core_web_sm\n",
    "# import de_core_news_sm\n",
    "import it_core_news_sm\n",
    "# import pl_core_news_sm\n",
    "import time\n",
    "from src.data import PreprocessingEuroParl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "stopwords_source = stopwords.words('english')\n",
    "# stopwords_target = stopwords.words('german') # German stopwords\n",
    "stopwords_target = stopwords.words('italian') # Italian stopwords\n",
    "# stopwords_target = stopwords.words('polish') # Polish stopwords\n",
    "nlp_source = en_core_web_sm.load()\n",
    "# nlp_target = de_core_news_sm.load() # German pipeline\n",
    "nlp_target = it_core_news_sm.load() # Italian pipeline\n",
    "# nlp_target = pl_core_news_sm.load() # Polish pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'import_data' in 0.02 seconds.\n"
     ]
    }
   ],
   "source": [
    "# parallel_sentences = PreprocessingEuroParl(df_sampled_path=\"../data/interim/europarl_en_de.pkl\") # German\n",
    "parallel_sentences = PreprocessingEuroParl(df_sampled_path=\"../data/interim/europarl_en_it.pkl\") # Italien\n",
    "# parallel_sentences = PreprocessingEuroParl(df_sampled_path=\"../data/interim/europarl_en_pol.pkl\") # Polnisch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25000/25000 [03:14<00:00, 128.46it/s]\n",
      "100%|██████████| 25000/25000 [00:00<00:00, 175210.04it/s]\n",
      "  0%|          | 0/25000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'spacy' in 194.62 seconds.\n",
      "Finished function: 'remove_punctuation' in 0.15 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25000/25000 [00:00<00:00, 179839.54it/s]\n",
      " 38%|███▊      | 9392/25000 [00:00<00:00, 93910.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'remove_numbers' in 0.14 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25000/25000 [00:00<00:00, 92326.90it/s]\n",
      "100%|██████████| 25000/25000 [00:00<00:00, 182429.89it/s]\n",
      "  0%|          | 0/25000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'lemmatize' in 0.27 seconds.\n",
      "Finished function: 'lowercase_spacy' in 0.14 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25000/25000 [00:00<00:00, 26668.52it/s]\n",
      "  0%|          | 16/25000 [00:00<02:40, 155.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'remove_stopwords' in 0.94 seconds.\n",
      "Finished function: 'create_cleaned_token_embedding' in 196.45 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25000/25000 [03:03<00:00, 136.41it/s]\n",
      "100%|██████████| 25000/25000 [00:00<00:00, 151451.94it/s]\n",
      "  0%|          | 0/25000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'spacy' in 183.27 seconds.\n",
      "Finished function: 'remove_punctuation' in 0.17 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25000/25000 [00:00<00:00, 140138.43it/s]\n",
      " 30%|██▉       | 7474/25000 [00:00<00:00, 74738.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'remove_numbers' in 0.18 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25000/25000 [00:00<00:00, 80638.85it/s]\n",
      "100%|██████████| 25000/25000 [00:00<00:00, 171634.91it/s]\n",
      "  0%|          | 0/25000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'lemmatize' in 0.31 seconds.\n",
      "Finished function: 'lowercase_spacy' in 0.15 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25000/25000 [00:01<00:00, 15804.86it/s]\n",
      "  1%|          | 221/25000 [00:00<00:11, 2209.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'remove_stopwords' in 1.58 seconds.\n",
      "Finished function: 'create_cleaned_token_embedding' in 185.98 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25000/25000 [00:04<00:00, 5178.40it/s]\n",
      " 16%|█▌        | 4050/25000 [00:00<00:01, 20210.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'tokenize_sentence' in 4.83 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25000/25000 [00:01<00:00, 22145.61it/s]\n",
      "100%|██████████| 25000/25000 [00:00<00:00, 180539.32it/s]\n",
      " 35%|███▌      | 8866/25000 [00:00<00:00, 34186.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'remove_stopwords' in 1.13 seconds.\n",
      "Finished function: 'strip_whitespace' in 0.14 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25000/25000 [00:00<00:00, 70089.64it/s]\n",
      "  8%|▊         | 2047/25000 [00:00<00:01, 20460.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'lowercase' in 0.36 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25000/25000 [00:01<00:00, 23229.21it/s]\n",
      "  2%|▏         | 465/25000 [00:00<00:05, 4644.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'remove_stopwords' in 1.08 seconds.\n",
      "Finished function: 'create_cleaned_text' in 7.58 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25000/25000 [00:05<00:00, 4385.32it/s]\n",
      "  4%|▍         | 960/25000 [00:00<00:02, 9599.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'tokenize_sentence' in 5.7 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25000/25000 [00:01<00:00, 13169.30it/s]\n",
      "100%|██████████| 25000/25000 [00:00<00:00, 180647.56it/s]\n",
      "  0%|          | 0/25000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'remove_stopwords' in 1.9 seconds.\n",
      "Finished function: 'strip_whitespace' in 0.14 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25000/25000 [00:00<00:00, 63038.95it/s]\n",
      " 11%|█▏        | 2815/25000 [00:00<00:01, 14460.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'lowercase' in 0.4 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25000/25000 [00:01<00:00, 14186.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'remove_stopwords' in 1.76 seconds.\n",
      "Finished function: 'create_cleaned_text' in 9.97 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "parallel_sentences.preprocess_sentences(nlp_source, nlp_target, stopwords_source, stopwords_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25000/25000 [00:00<00:00, 103231.09it/s]\n",
      "100%|█████████▉| 24964/25000 [00:00<00:00, 118303.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'number_punctuations_total' in 0.24 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25000/25000 [00:00<00:00, 121369.14it/s]\n",
      "100%|██████████| 25000/25000 [00:00<00:00, 285705.41it/s]\n",
      "100%|██████████| 25000/25000 [00:00<00:00, 244303.15it/s]\n",
      "  0%|          | 0/25000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'number_punctuations_total' in 0.21 seconds.\n",
      "Finished function: 'number_words' in 0.09 seconds.\n",
      "Finished function: 'number_words' in 0.1 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25000/25000 [00:00<00:00, 38348.08it/s]\n",
      " 19%|█▉        | 4735/25000 [00:00<00:00, 47332.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'number_unique_words' in 0.65 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25000/25000 [00:00<00:00, 45282.13it/s]\n",
      " 36%|███▌      | 8963/25000 [00:00<00:00, 43989.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'number_unique_words' in 0.55 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25000/25000 [00:00<00:00, 53651.41it/s]\n",
      " 55%|█████▍    | 13707/25000 [00:00<00:00, 65546.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'number_characters' in 0.47 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25000/25000 [00:00<00:00, 70954.39it/s]\n",
      "/Users/I534344/Google Drive/crosslingual-information-retrieval/src/data/preprocess_data.py:262: RuntimeWarning: divide by zero encountered in log\n",
      "  return (character_vector / word_vector).replace(np.nan, 0).replace(np.inf, 0).replace(np.log(0), 0)\n",
      "100%|██████████| 25000/25000 [00:00<00:00, 358402.98it/s]\n",
      "100%|██████████| 25000/25000 [00:00<00:00, 308715.24it/s]\n",
      "  0%|          | 0/25000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'number_characters' in 0.35 seconds.\n",
      "Finished function: 'average_characters' in 0.02 seconds.\n",
      "Finished function: 'average_characters' in 0.0 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.07 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.08 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25000/25000 [00:00<00:00, 309646.94it/s]\n",
      "100%|██████████| 25000/25000 [00:00<00:00, 267027.94it/s]\n",
      "100%|██████████| 25000/25000 [00:00<00:00, 313786.14it/s]\n",
      "  0%|          | 0/25000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'number_punctuation_marks' in 0.08 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.1 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.08 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25000/25000 [00:00<00:00, 298821.33it/s]\n",
      "100%|██████████| 25000/25000 [00:00<00:00, 316475.77it/s]\n",
      "100%|██████████| 25000/25000 [00:00<00:00, 308150.93it/s]\n",
      "  0%|          | 0/25000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'number_punctuation_marks' in 0.09 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.08 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.08 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25000/25000 [00:00<00:00, 343283.30it/s]\n",
      "100%|██████████| 25000/25000 [00:00<00:00, 325199.34it/s]\n",
      "100%|██████████| 25000/25000 [00:00<00:00, 351255.85it/s]\n",
      "  0%|          | 0/25000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'number_punctuation_marks' in 0.08 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.08 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.07 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25000/25000 [00:00<00:00, 271921.62it/s]\n",
      "100%|██████████| 25000/25000 [00:00<00:00, 320401.87it/s]\n",
      "100%|██████████| 25000/25000 [00:00<00:00, 273505.41it/s]\n",
      "  0%|          | 0/25000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'number_punctuation_marks' in 0.09 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.08 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.09 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25000/25000 [00:00<00:00, 334059.49it/s]\n",
      "100%|██████████| 25000/25000 [00:00<00:00, 237566.01it/s]\n",
      "  0%|          | 0/25000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'number_punctuation_marks' in 0.08 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.11 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25000/25000 [00:00<00:00, 272153.11it/s]\n",
      "100%|██████████| 25000/25000 [00:00<00:00, 253223.57it/s]\n",
      "100%|██████████| 25000/25000 [00:00<00:00, 306470.34it/s]\n",
      "  0%|          | 0/25000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'number_punctuation_marks' in 0.09 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.1 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.08 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25000/25000 [00:00<00:00, 296271.52it/s]\n",
      "100%|██████████| 25000/25000 [00:00<00:00, 339654.96it/s]\n",
      "100%|██████████| 25000/25000 [00:00<00:00, 306211.69it/s]\n",
      "  0%|          | 0/25000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'number_punctuation_marks' in 0.09 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.08 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.08 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25000/25000 [00:00<00:00, 333989.27it/s]\n",
      "100%|██████████| 25000/25000 [00:00<00:00, 257092.77it/s]\n",
      "100%|██████████| 25000/25000 [00:00<00:00, 287053.03it/s]\n",
      "  0%|          | 0/25000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'number_punctuation_marks' in 0.08 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.1 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.09 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25000/25000 [00:00<00:00, 262007.76it/s]\n",
      "100%|██████████| 25000/25000 [00:00<00:00, 321975.01it/s]\n",
      "100%|██████████| 25000/25000 [00:00<00:00, 315800.00it/s]\n",
      "  0%|          | 0/25000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'number_punctuation_marks' in 0.1 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.08 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.08 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25000/25000 [00:00<00:00, 358916.99it/s]\n",
      "100%|██████████| 25000/25000 [00:00<00:00, 383131.03it/s]\n",
      "100%|██████████| 25000/25000 [00:00<00:00, 482438.84it/s]\n",
      "  0%|          | 0/25000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'number_punctuation_marks' in 0.07 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.07 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.05 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25000/25000 [00:00<00:00, 277229.44it/s]\n",
      "100%|██████████| 25000/25000 [00:00<00:00, 291884.88it/s]\n",
      "100%|██████████| 25000/25000 [00:00<00:00, 314019.18it/s]\n",
      "  0%|          | 0/25000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'number_punctuation_marks' in 0.09 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.09 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.08 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25000/25000 [00:00<00:00, 384461.33it/s]\n",
      "100%|██████████| 25000/25000 [00:00<00:00, 382110.44it/s]\n",
      "100%|██████████| 25000/25000 [00:00<00:00, 488787.37it/s]\n",
      "100%|██████████| 25000/25000 [00:00<00:00, 370309.58it/s]\n",
      "  0%|          | 0/25000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'number_punctuation_marks' in 0.07 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.07 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.05 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.07 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25000/25000 [00:00<00:00, 307529.15it/s]\n",
      "100%|██████████| 25000/25000 [00:00<00:00, 259870.14it/s]\n",
      "100%|██████████| 25000/25000 [00:00<00:00, 308497.26it/s]\n",
      "  0%|          | 0/25000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'number_punctuation_marks' in 0.08 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.1 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.08 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25000/25000 [00:00<00:00, 337618.65it/s]\n",
      "100%|██████████| 25000/25000 [00:00<00:00, 386415.09it/s]\n",
      "100%|██████████| 25000/25000 [00:00<00:00, 347173.81it/s]\n",
      "  0%|          | 0/25000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'number_punctuation_marks' in 0.08 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.07 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.07 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25000/25000 [00:00<00:00, 421770.38it/s]\n",
      "100%|██████████| 25000/25000 [00:00<00:00, 380754.85it/s]\n",
      "100%|██████████| 25000/25000 [00:00<00:00, 351105.31it/s]\n",
      "  0%|          | 0/25000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'number_punctuation_marks' in 0.06 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.07 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.07 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25000/25000 [00:00<00:00, 332623.62it/s]\n",
      "100%|██████████| 25000/25000 [00:00<00:00, 473879.11it/s]\n",
      "100%|██████████| 25000/25000 [00:00<00:00, 346837.34it/s]\n",
      "100%|██████████| 25000/25000 [00:00<00:00, 394732.76it/s]\n",
      "  0%|          | 0/25000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'number_punctuation_marks' in 0.08 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.05 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.07 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.06 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25000/25000 [00:00<00:00, 353972.41it/s]\n",
      "100%|██████████| 25000/25000 [00:00<00:00, 458865.28it/s]\n",
      "100%|██████████| 25000/25000 [00:00<00:00, 434842.97it/s]\n",
      "100%|██████████| 25000/25000 [00:00<00:00, 407006.92it/s]\n",
      "  0%|          | 0/25000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'number_punctuation_marks' in 0.07 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.06 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.06 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.06 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25000/25000 [00:00<00:00, 255788.92it/s]\n",
      "100%|██████████| 25000/25000 [00:00<00:00, 296197.87it/s]\n",
      "100%|██████████| 25000/25000 [00:00<00:00, 377359.36it/s]\n",
      "  0%|          | 0/25000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'number_punctuation_marks' in 0.1 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.09 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.07 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25000/25000 [00:00<00:00, 372506.50it/s]\n",
      "100%|██████████| 25000/25000 [00:00<00:00, 373747.94it/s]\n",
      "100%|██████████| 25000/25000 [00:00<00:00, 431466.59it/s]\n",
      "100%|██████████| 25000/25000 [00:00<00:00, 372172.00it/s]\n",
      "  0%|          | 0/25000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'number_punctuation_marks' in 0.07 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.07 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.06 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.07 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25000/25000 [00:00<00:00, 294752.47it/s]\n",
      "100%|██████████| 25000/25000 [00:00<00:00, 257846.98it/s]\n",
      "  0%|          | 0/25000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'number_punctuation_marks' in 0.09 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.1 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25000/25000 [03:16<00:00, 127.19it/s]\n",
      "  0%|          | 18/25000 [00:00<02:26, 170.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'spacy' in 196.56 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25000/25000 [02:45<00:00, 150.71it/s]\n",
      "  4%|▍         | 1083/25000 [00:00<00:02, 10827.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'spacy' in 165.88 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25000/25000 [00:00<00:00, 25724.53it/s]\n",
      " 91%|█████████ | 22743/25000 [00:00<00:00, 58682.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'number_pos' in 0.97 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25000/25000 [00:00<00:00, 115269.93it/s]\n",
      "100%|██████████| 25000/25000 [00:00<00:00, 166892.30it/s]\n",
      "  0%|          | 0/25000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'number_pos' in 0.22 seconds.\n",
      "Finished function: 'number_pos' in 0.15 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25000/25000 [00:00<00:00, 172084.74it/s]\n",
      "100%|██████████| 25000/25000 [00:00<00:00, 143444.83it/s]\n",
      "  0%|          | 0/25000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'number_pos' in 0.15 seconds.\n",
      "Finished function: 'number_pos' in 0.18 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25000/25000 [00:00<00:00, 143855.74it/s]\n",
      "  4%|▍         | 1044/25000 [00:00<00:02, 10432.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'number_pos' in 0.18 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25000/25000 [00:02<00:00, 10038.41it/s]\n",
      "  4%|▍         | 1053/25000 [00:00<00:02, 10527.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'number_times' in 2.49 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25000/25000 [00:02<00:00, 9947.71it/s] \n",
      "  4%|▎         | 928/25000 [00:00<00:02, 9278.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'number_times' in 2.52 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25000/25000 [00:02<00:00, 10206.21it/s]\n",
      "  4%|▎         | 883/25000 [00:00<00:02, 8788.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'number_times' in 2.45 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25000/25000 [00:02<00:00, 9730.21it/s] \n",
      "  7%|▋         | 1656/25000 [00:00<00:02, 7977.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'number_times' in 2.57 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25000/25000 [00:02<00:00, 9422.72it/s]\n",
      "  3%|▎         | 839/25000 [00:00<00:02, 8386.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'number_times' in 2.66 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25000/25000 [00:03<00:00, 8151.00it/s] \n",
      "100%|██████████| 25000/25000 [00:00<00:00, 155480.26it/s]\n",
      "  0%|          | 0/25000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'number_times' in 3.07 seconds.\n",
      "Finished function: 'named_numbers' in 0.16 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25000/25000 [00:00<00:00, 155235.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'named_numbers' in 0.16 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "parallel_sentences.extract_sentence_information(nlp_source, nlp_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'load_embeddings' in 1.47 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 103/25000 [00:00<00:51, 485.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'load_embeddings' in 1.49 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25000/25000 [00:38<00:00, 650.44it/s]\n",
      "  0%|          | 59/25000 [00:00<00:42, 580.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'word_embeddings' in 38.44 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25000/25000 [00:53<00:00, 465.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'word_embeddings' in 53.76 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25000/25000 [00:00<00:00, 171492.59it/s]\n",
      "  0%|          | 0/25000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'create_translation_dictionary' in 74.17 seconds.\n",
      "Finished function: 'translate_words' in 0.15 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25000/25000 [00:00<00:00, 151826.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'translate_words' in 0.17 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25000/25000 [00:09<00:00, 2511.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'tf_idf_vector' in 10.31 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25000/25000 [00:12<00:00, 1993.72it/s]\n",
      "  1%|          | 129/25000 [00:00<00:19, 1286.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'tf_idf_vector' in 12.96 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25000/25000 [00:16<00:00, 1497.79it/s]\n",
      "  1%|          | 167/25000 [00:00<00:14, 1667.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'sentence_embedding_average' in 16.69 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25000/25000 [00:23<00:00, 1081.09it/s]\n",
      "  0%|          | 19/25000 [00:00<02:11, 189.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'sentence_embedding_average' in 23.13 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 356/25000 [00:01<01:39, 248.65it/s]/Users/I534344/Google Drive/crosslingual-information-retrieval/src/data/preprocess_data.py:616: RuntimeWarning: Mean of empty slice.\n",
      "  return [pd.Series(embedding_dataframe.values.mean(axis=1))]\n",
      "100%|██████████| 25000/25000 [01:47<00:00, 232.70it/s]\n",
      "  0%|          | 17/25000 [00:00<02:28, 168.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'sentence_embedding_tf_idf' in 107.49 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25000/25000 [02:25<00:00, 171.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'sentence_embedding_tf_idf' in 145.5 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "parallel_sentences.create_embedding_information(\"proc_5k\", language_pair=\"en_it\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'load_embeddings' in 1.05 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 39/25000 [00:00<01:05, 383.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'load_embeddings' in 0.96 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25000/25000 [00:57<00:00, 433.18it/s]\n",
      "  0%|          | 45/25000 [00:00<00:55, 449.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'word_embeddings' in 57.73 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25000/25000 [00:55<00:00, 447.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'word_embeddings' in 55.88 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25000/25000 [00:00<00:00, 219421.07it/s]\n",
      "  0%|          | 0/25000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'create_translation_dictionary' in 66.05 seconds.\n",
      "Finished function: 'translate_words' in 0.12 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25000/25000 [00:00<00:00, 189350.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'translate_words' in 0.13 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25000/25000 [00:09<00:00, 2669.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'tf_idf_vector' in 9.67 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25000/25000 [00:13<00:00, 1911.45it/s]\n",
      "  0%|          | 106/25000 [00:00<00:23, 1057.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'tf_idf_vector' in 13.39 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25000/25000 [00:12<00:00, 2009.17it/s]\n",
      "  1%|          | 181/25000 [00:00<00:13, 1807.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'sentence_embedding_average' in 12.44 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25000/25000 [00:13<00:00, 1851.43it/s]\n",
      "  0%|          | 30/25000 [00:00<01:23, 298.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'sentence_embedding_average' in 13.51 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25000/25000 [01:35<00:00, 260.75it/s]\n",
      "  0%|          | 17/25000 [00:00<02:29, 167.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'sentence_embedding_tf_idf' in 95.89 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25000/25000 [01:51<00:00, 224.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'sentence_embedding_tf_idf' in 111.46 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "parallel_sentences.create_embedding_information(\"proc_b_1k\", language_pair=\"en_it\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'load_embeddings' in 0.79 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 44/25000 [00:00<00:58, 425.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'load_embeddings' in 0.64 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25000/25000 [00:45<00:00, 546.68it/s]\n",
      "  0%|          | 55/25000 [00:00<00:45, 547.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'word_embeddings' in 45.73 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25000/25000 [00:44<00:00, 556.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'word_embeddings' in 44.91 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25000/25000 [00:00<00:00, 216966.66it/s]\n",
      "  0%|          | 0/25000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'create_translation_dictionary' in 75.22 seconds.\n",
      "Finished function: 'translate_words' in 0.12 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25000/25000 [00:00<00:00, 152191.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'translate_words' in 0.17 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25000/25000 [00:09<00:00, 2585.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'tf_idf_vector' in 10.0 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25000/25000 [00:12<00:00, 1945.22it/s]\n",
      "  0%|          | 111/25000 [00:00<00:22, 1108.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'tf_idf_vector' in 13.25 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25000/25000 [00:18<00:00, 1346.49it/s]\n",
      "  1%|          | 140/25000 [00:00<00:17, 1398.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'sentence_embedding_average' in 18.57 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25000/25000 [00:14<00:00, 1705.18it/s]\n",
      "  0%|          | 26/25000 [00:00<01:38, 253.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'sentence_embedding_average' in 14.66 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25000/25000 [02:02<00:00, 203.67it/s]\n",
      "  0%|          | 19/25000 [00:00<02:17, 181.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'sentence_embedding_tf_idf' in 122.77 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25000/25000 [01:51<00:00, 224.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'sentence_embedding_tf_idf' in 111.5 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "parallel_sentences.create_embedding_information(\"vecmap\", language_pair=\"en_it\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_sentences.preprocessed.to_json(\"../data/interim/preprocessed_data_en_it.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_source</th>\n",
       "      <th>id_target</th>\n",
       "      <th>token_preprocessed_embedding_source</th>\n",
       "      <th>token_preprocessed_embedding_target</th>\n",
       "      <th>Translation</th>\n",
       "      <th>number_punctuations_total_source</th>\n",
       "      <th>number_punctuations_total_target</th>\n",
       "      <th>number_words_source</th>\n",
       "      <th>number_words_target</th>\n",
       "      <th>number_unique_words_source</th>\n",
       "      <th>...</th>\n",
       "      <th>sentence_embedding_average_proc_b_1k_source</th>\n",
       "      <th>sentence_embedding_average_proc_b_1k_target</th>\n",
       "      <th>sentence_embedding_tf_idf_proc_b_1k_source</th>\n",
       "      <th>sentence_embedding_tf_idf_proc_b_1k_target</th>\n",
       "      <th>translated_to_target_vecmap_source</th>\n",
       "      <th>translated_to_source_vecmap_target</th>\n",
       "      <th>sentence_embedding_average_vecmap_source</th>\n",
       "      <th>sentence_embedding_average_vecmap_target</th>\n",
       "      <th>sentence_embedding_tf_idf_vecmap_source</th>\n",
       "      <th>sentence_embedding_tf_idf_vecmap_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[finally, mr, president, although, fall, withi...</td>\n",
       "      <td>[ultimare, signore, presidente, competere, com...</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>38</td>\n",
       "      <td>39</td>\n",
       "      <td>35</td>\n",
       "      <td>...</td>\n",
       "      <td>[[0.008693028401467018, 0.009497930798234473, ...</td>\n",
       "      <td>[[0.008830122081288957, 0.004547863627094022, ...</td>\n",
       "      <td>[[0.0018075439090904097, 0.0013963363123755275...</td>\n",
       "      <td>[[0.0015286852722734012, 0.0007927902201681273...</td>\n",
       "      <td>[finalmente, signor, presidente, tuttavia, cad...</td>\n",
       "      <td>[finalize, lord, president, compete, commissio...</td>\n",
       "      <td>[[-0.2608074678984635, 0.035465999670764976, 0...</td>\n",
       "      <td>[[-0.2317512307439328, 0.043051783598082906, 0...</td>\n",
       "      <td>[[-0.04178289919088128, 0.003289124538910825, ...</td>\n",
       "      <td>[[-0.03635919295923167, 0.0053623071707199, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[applause]</td>\n",
       "      <td>[applausi]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>[[0.0347091443836689, 0.08055263757705688, 0.0...</td>\n",
       "      <td>[[-0.027894562110304832, 0.10238229483366013, ...</td>\n",
       "      <td>[[0.0347091443836689, 0.08055263757705688, 0.0...</td>\n",
       "      <td>[[-0.027894562110304832, 0.10238229483366013, ...</td>\n",
       "      <td>[applausi]</td>\n",
       "      <td>[applause]</td>\n",
       "      <td>[[-0.10786788910627365, 0.14334604144096375, -...</td>\n",
       "      <td>[[-0.14058560132980347, 0.10015597939491272, -...</td>\n",
       "      <td>[[-0.10786788910627365, 0.14334604144096375, -...</td>\n",
       "      <td>[[-0.14058560132980347, 0.10015597939491272, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>[lisbon, continuation]</td>\n",
       "      <td>[lisbona, proseguimento]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>[[-0.020988833159208298, 0.04784630052745342, ...</td>\n",
       "      <td>[[-0.0201482642441988, 0.029058500658720732, 0...</td>\n",
       "      <td>[[-0.005021797963031628, 0.031505242847675384,...</td>\n",
       "      <td>[[-0.012601990050846867, 0.01683720292953982, ...</td>\n",
       "      <td>[lisbona, prosecuzione]</td>\n",
       "      <td>[lisbon, continuation]</td>\n",
       "      <td>[[-0.02069856971502304, -0.1291940463706851, 0...</td>\n",
       "      <td>[[-0.04886355251073837, -0.13083997648209333, ...</td>\n",
       "      <td>[[-0.04082566372040908, -0.07944126290264207, ...</td>\n",
       "      <td>[[-0.07017921368832104, -0.07720816915820333, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>[identical, murder, attempt, recently, town, m...</td>\n",
       "      <td>[tentare, omicidio, identico, essere, stare, p...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>18</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>[[0.03894698836042413, 0.013754402486873525, 0...</td>\n",
       "      <td>[[0.021405176129466033, 0.032778284019407106, ...</td>\n",
       "      <td>[[0.010250564928934999, 0.0027849285443413904,...</td>\n",
       "      <td>[[0.005357049436194455, 0.0063608610116189495,...</td>\n",
       "      <td>[identico, omicidio, tentativo, recentemente, ...</td>\n",
       "      <td>[attempt, murder, identical, therefore, stay, ...</td>\n",
       "      <td>[[-0.18444362449060595, -0.007816310356637197,...</td>\n",
       "      <td>[[-0.18242603102151086, 0.03894012695287957, 0...</td>\n",
       "      <td>[[-0.04227790194857881, -0.00697155921507797, ...</td>\n",
       "      <td>[[-0.0341803192431627, 0.004996396428697362, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>[reconsider, soon, practically, possible]</td>\n",
       "      <td>[verrà, riconsiderare, appena, essere, pratica...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>[[0.003843584709102288, 0.06975685886573046, 0...</td>\n",
       "      <td>[[0.021365371843179066, 0.017269847448915243, ...</td>\n",
       "      <td>[[0.0025937276066553857, 0.037731961813923534,...</td>\n",
       "      <td>[[0.011209410370540865, 0.0070219193348595695,...</td>\n",
       "      <td>[riconsiderare, presto, praticamente, possibile]</td>\n",
       "      <td>[gets, reconsider, immediately, therefore, vir...</td>\n",
       "      <td>[[-0.3457260988652706, 0.11624429188668728, 0....</td>\n",
       "      <td>[[-0.32295674333969754, 0.08559711432705323, 0...</td>\n",
       "      <td>[[-0.16844998753889942, 0.057748788697695064, ...</td>\n",
       "      <td>[[-0.11822048330145368, 0.03690763003978965, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>24995</td>\n",
       "      <td>24995</td>\n",
       "      <td>[discussion, underway, establish, help, would,...</td>\n",
       "      <td>[correre, discussione, stabilire, forma, aiuta...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>[[0.027733889951681096, 0.045572447086063526, ...</td>\n",
       "      <td>[[-0.0012786872684955597, 0.01170461175206583,...</td>\n",
       "      <td>[[0.009949558184369987, 0.01824453850351808, 0...</td>\n",
       "      <td>[[0.002030095925314283, 0.002094960642065595, ...</td>\n",
       "      <td>[discussione, avviato, stabilire, aiuto, dovut...</td>\n",
       "      <td>[overtake, discussion, determine, form, help, ...</td>\n",
       "      <td>[[-0.345364381869634, 0.04808976097653309, 0.2...</td>\n",
       "      <td>[[-0.2989570051431656, 0.041093380481470376, 0...</td>\n",
       "      <td>[[-0.13079217395478768, 0.01262385431881695, 0...</td>\n",
       "      <td>[[-0.1001236591809881, 0.01070314706811008, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>24996</td>\n",
       "      <td>24996</td>\n",
       "      <td>[need, large, majority]</td>\n",
       "      <td>[adesso, servire, maggioranza, ampio]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>[[-0.024014365548888843, 0.013163011521100998,...</td>\n",
       "      <td>[[0.013197294436395168, 0.04709733300842345, 0...</td>\n",
       "      <td>[[-0.007652249980452337, 0.005586281052024325,...</td>\n",
       "      <td>[[0.005589276491623362, 0.023743840989073752, ...</td>\n",
       "      <td>[bisogna, piccole, maggioranza]</td>\n",
       "      <td>[anyway, serve, majority, broad]</td>\n",
       "      <td>[[-0.32679545879364014, -0.02295448196431001, ...</td>\n",
       "      <td>[[-0.2798319607973099, -0.015366747509688139, ...</td>\n",
       "      <td>[[-0.1793727918531777, -0.01970709230942802, 0...</td>\n",
       "      <td>[[-0.14012105415330461, -0.007039710147790793,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>24997</td>\n",
       "      <td>24997</td>\n",
       "      <td>[list, publicly, available, intend, debate, to...</td>\n",
       "      <td>[tali, elenco, essere, pubblico, dovere, esser...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>[[-0.02947679255157709, 0.0017494010244263336,...</td>\n",
       "      <td>[[0.026079811376985163, -0.0184820672031492, 0...</td>\n",
       "      <td>[[-0.011494453582837134, -0.001609825355740220...</td>\n",
       "      <td>[[0.008537422638065442, -0.008387655900818757,...</td>\n",
       "      <td>[lista, pubblicamente, disponibile, permetterm...</td>\n",
       "      <td>[certain, list, therefore, public, obligation,...</td>\n",
       "      <td>[[-0.2680252157151699, 0.010025895680882968, 0...</td>\n",
       "      <td>[[-0.26727680712938306, 0.001577067608013749, ...</td>\n",
       "      <td>[[-0.09347213943120848, 0.0061355563743250244,...</td>\n",
       "      <td>[[-0.08303151566023889, -0.0011806212530717536...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>24998</td>\n",
       "      <td>24998</td>\n",
       "      <td>[however, ring, friend, different, project, pr...</td>\n",
       "      <td>[e', però, altro, discorrere, riguardare, anel...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>24</td>\n",
       "      <td>...</td>\n",
       "      <td>[[0.027616000079433434, 0.023816229969573516, ...</td>\n",
       "      <td>[[0.01671971460261072, 0.010999239597974034, 0...</td>\n",
       "      <td>[[0.004424109903798761, 0.004199808899204925, ...</td>\n",
       "      <td>[[0.002870340549292681, 0.0009921893565988488,...</td>\n",
       "      <td>[tuttavia, anello, amico, diverse, progetto, p...</td>\n",
       "      <td>[however, another, relate, ring, friend, relat...</td>\n",
       "      <td>[[-0.2592687489038023, 0.021379880510115374, 0...</td>\n",
       "      <td>[[-0.2660550732786457, 0.040747578954324126, 0...</td>\n",
       "      <td>[[-0.05026916672191941, 0.005777651995093183, ...</td>\n",
       "      <td>[[-0.04288726434918977, 0.006473223171571389, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>24999</td>\n",
       "      <td>24999</td>\n",
       "      <td>[serious, psychological, problem, face, must, ...</td>\n",
       "      <td>[grave, problema, psicologico, soffrire, dover...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>18</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>[[0.009784272146027754, -0.007276826031396494,...</td>\n",
       "      <td>[[-0.001753557110479211, 0.005773750599473715,...</td>\n",
       "      <td>[[0.002023493030493372, -0.0019439963871515776...</td>\n",
       "      <td>[[0.0016318387084215578, 0.0022976337280727695...</td>\n",
       "      <td>[grave, psicologico, problema, viso, devono, q...</td>\n",
       "      <td>[serious, problem, psychological, suffer, obli...</td>\n",
       "      <td>[[-0.2642882990048212, -0.0021345418893307555,...</td>\n",
       "      <td>[[-0.25573601135436225, 0.04136127551250598, 0...</td>\n",
       "      <td>[[-0.05511838036684588, -0.00389641966414871, ...</td>\n",
       "      <td>[[-0.053235560454585724, 0.010306224228506395,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows × 111 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id_source  id_target  \\\n",
       "0              0          0   \n",
       "1              1          1   \n",
       "2              2          2   \n",
       "3              3          3   \n",
       "4              4          4   \n",
       "...          ...        ...   \n",
       "24995      24995      24995   \n",
       "24996      24996      24996   \n",
       "24997      24997      24997   \n",
       "24998      24998      24998   \n",
       "24999      24999      24999   \n",
       "\n",
       "                     token_preprocessed_embedding_source  \\\n",
       "0      [finally, mr, president, although, fall, withi...   \n",
       "1                                             [applause]   \n",
       "2                                 [lisbon, continuation]   \n",
       "3      [identical, murder, attempt, recently, town, m...   \n",
       "4              [reconsider, soon, practically, possible]   \n",
       "...                                                  ...   \n",
       "24995  [discussion, underway, establish, help, would,...   \n",
       "24996                            [need, large, majority]   \n",
       "24997  [list, publicly, available, intend, debate, to...   \n",
       "24998  [however, ring, friend, different, project, pr...   \n",
       "24999  [serious, psychological, problem, face, must, ...   \n",
       "\n",
       "                     token_preprocessed_embedding_target  Translation  \\\n",
       "0      [ultimare, signore, presidente, competere, com...            1   \n",
       "1                                             [applausi]            1   \n",
       "2                               [lisbona, proseguimento]            1   \n",
       "3      [tentare, omicidio, identico, essere, stare, p...            1   \n",
       "4      [verrà, riconsiderare, appena, essere, pratica...            1   \n",
       "...                                                  ...          ...   \n",
       "24995  [correre, discussione, stabilire, forma, aiuta...            1   \n",
       "24996              [adesso, servire, maggioranza, ampio]            1   \n",
       "24997  [tali, elenco, essere, pubblico, dovere, esser...            1   \n",
       "24998  [e', però, altro, discorrere, riguardare, anel...            1   \n",
       "24999  [grave, problema, psicologico, soffrire, dover...            1   \n",
       "\n",
       "       number_punctuations_total_source  number_punctuations_total_target  \\\n",
       "0                                    10                                 9   \n",
       "1                                     2                                 2   \n",
       "2                                     2                                 2   \n",
       "3                                     0                                 1   \n",
       "4                                     0                                 0   \n",
       "...                                 ...                               ...   \n",
       "24995                                 0                                 0   \n",
       "24996                                 0                                 0   \n",
       "24997                                 0                                 0   \n",
       "24998                                 4                                 6   \n",
       "24999                                 3                                 3   \n",
       "\n",
       "       number_words_source  number_words_target  number_unique_words_source  \\\n",
       "0                       38                   39                          35   \n",
       "1                        1                    1                           1   \n",
       "2                        2                    2                           2   \n",
       "3                       14                   18                          14   \n",
       "4                        4                    5                           4   \n",
       "...                    ...                  ...                         ...   \n",
       "24995                    6                    7                           6   \n",
       "24996                    3                    4                           3   \n",
       "24997                    8                   10                           8   \n",
       "24998                   29                   29                          24   \n",
       "24999                   20                   18                          17   \n",
       "\n",
       "       ...        sentence_embedding_average_proc_b_1k_source  \\\n",
       "0      ...  [[0.008693028401467018, 0.009497930798234473, ...   \n",
       "1      ...  [[0.0347091443836689, 0.08055263757705688, 0.0...   \n",
       "2      ...  [[-0.020988833159208298, 0.04784630052745342, ...   \n",
       "3      ...  [[0.03894698836042413, 0.013754402486873525, 0...   \n",
       "4      ...  [[0.003843584709102288, 0.06975685886573046, 0...   \n",
       "...    ...                                                ...   \n",
       "24995  ...  [[0.027733889951681096, 0.045572447086063526, ...   \n",
       "24996  ...  [[-0.024014365548888843, 0.013163011521100998,...   \n",
       "24997  ...  [[-0.02947679255157709, 0.0017494010244263336,...   \n",
       "24998  ...  [[0.027616000079433434, 0.023816229969573516, ...   \n",
       "24999  ...  [[0.009784272146027754, -0.007276826031396494,...   \n",
       "\n",
       "             sentence_embedding_average_proc_b_1k_target  \\\n",
       "0      [[0.008830122081288957, 0.004547863627094022, ...   \n",
       "1      [[-0.027894562110304832, 0.10238229483366013, ...   \n",
       "2      [[-0.0201482642441988, 0.029058500658720732, 0...   \n",
       "3      [[0.021405176129466033, 0.032778284019407106, ...   \n",
       "4      [[0.021365371843179066, 0.017269847448915243, ...   \n",
       "...                                                  ...   \n",
       "24995  [[-0.0012786872684955597, 0.01170461175206583,...   \n",
       "24996  [[0.013197294436395168, 0.04709733300842345, 0...   \n",
       "24997  [[0.026079811376985163, -0.0184820672031492, 0...   \n",
       "24998  [[0.01671971460261072, 0.010999239597974034, 0...   \n",
       "24999  [[-0.001753557110479211, 0.005773750599473715,...   \n",
       "\n",
       "              sentence_embedding_tf_idf_proc_b_1k_source  \\\n",
       "0      [[0.0018075439090904097, 0.0013963363123755275...   \n",
       "1      [[0.0347091443836689, 0.08055263757705688, 0.0...   \n",
       "2      [[-0.005021797963031628, 0.031505242847675384,...   \n",
       "3      [[0.010250564928934999, 0.0027849285443413904,...   \n",
       "4      [[0.0025937276066553857, 0.037731961813923534,...   \n",
       "...                                                  ...   \n",
       "24995  [[0.009949558184369987, 0.01824453850351808, 0...   \n",
       "24996  [[-0.007652249980452337, 0.005586281052024325,...   \n",
       "24997  [[-0.011494453582837134, -0.001609825355740220...   \n",
       "24998  [[0.004424109903798761, 0.004199808899204925, ...   \n",
       "24999  [[0.002023493030493372, -0.0019439963871515776...   \n",
       "\n",
       "              sentence_embedding_tf_idf_proc_b_1k_target  \\\n",
       "0      [[0.0015286852722734012, 0.0007927902201681273...   \n",
       "1      [[-0.027894562110304832, 0.10238229483366013, ...   \n",
       "2      [[-0.012601990050846867, 0.01683720292953982, ...   \n",
       "3      [[0.005357049436194455, 0.0063608610116189495,...   \n",
       "4      [[0.011209410370540865, 0.0070219193348595695,...   \n",
       "...                                                  ...   \n",
       "24995  [[0.002030095925314283, 0.002094960642065595, ...   \n",
       "24996  [[0.005589276491623362, 0.023743840989073752, ...   \n",
       "24997  [[0.008537422638065442, -0.008387655900818757,...   \n",
       "24998  [[0.002870340549292681, 0.0009921893565988488,...   \n",
       "24999  [[0.0016318387084215578, 0.0022976337280727695...   \n",
       "\n",
       "                      translated_to_target_vecmap_source  \\\n",
       "0      [finalmente, signor, presidente, tuttavia, cad...   \n",
       "1                                             [applausi]   \n",
       "2                                [lisbona, prosecuzione]   \n",
       "3      [identico, omicidio, tentativo, recentemente, ...   \n",
       "4       [riconsiderare, presto, praticamente, possibile]   \n",
       "...                                                  ...   \n",
       "24995  [discussione, avviato, stabilire, aiuto, dovut...   \n",
       "24996                    [bisogna, piccole, maggioranza]   \n",
       "24997  [lista, pubblicamente, disponibile, permetterm...   \n",
       "24998  [tuttavia, anello, amico, diverse, progetto, p...   \n",
       "24999  [grave, psicologico, problema, viso, devono, q...   \n",
       "\n",
       "                      translated_to_source_vecmap_target  \\\n",
       "0      [finalize, lord, president, compete, commissio...   \n",
       "1                                             [applause]   \n",
       "2                                 [lisbon, continuation]   \n",
       "3      [attempt, murder, identical, therefore, stay, ...   \n",
       "4      [gets, reconsider, immediately, therefore, vir...   \n",
       "...                                                  ...   \n",
       "24995  [overtake, discussion, determine, form, help, ...   \n",
       "24996                   [anyway, serve, majority, broad]   \n",
       "24997  [certain, list, therefore, public, obligation,...   \n",
       "24998  [however, another, relate, ring, friend, relat...   \n",
       "24999  [serious, problem, psychological, suffer, obli...   \n",
       "\n",
       "                sentence_embedding_average_vecmap_source  \\\n",
       "0      [[-0.2608074678984635, 0.035465999670764976, 0...   \n",
       "1      [[-0.10786788910627365, 0.14334604144096375, -...   \n",
       "2      [[-0.02069856971502304, -0.1291940463706851, 0...   \n",
       "3      [[-0.18444362449060595, -0.007816310356637197,...   \n",
       "4      [[-0.3457260988652706, 0.11624429188668728, 0....   \n",
       "...                                                  ...   \n",
       "24995  [[-0.345364381869634, 0.04808976097653309, 0.2...   \n",
       "24996  [[-0.32679545879364014, -0.02295448196431001, ...   \n",
       "24997  [[-0.2680252157151699, 0.010025895680882968, 0...   \n",
       "24998  [[-0.2592687489038023, 0.021379880510115374, 0...   \n",
       "24999  [[-0.2642882990048212, -0.0021345418893307555,...   \n",
       "\n",
       "                sentence_embedding_average_vecmap_target  \\\n",
       "0      [[-0.2317512307439328, 0.043051783598082906, 0...   \n",
       "1      [[-0.14058560132980347, 0.10015597939491272, -...   \n",
       "2      [[-0.04886355251073837, -0.13083997648209333, ...   \n",
       "3      [[-0.18242603102151086, 0.03894012695287957, 0...   \n",
       "4      [[-0.32295674333969754, 0.08559711432705323, 0...   \n",
       "...                                                  ...   \n",
       "24995  [[-0.2989570051431656, 0.041093380481470376, 0...   \n",
       "24996  [[-0.2798319607973099, -0.015366747509688139, ...   \n",
       "24997  [[-0.26727680712938306, 0.001577067608013749, ...   \n",
       "24998  [[-0.2660550732786457, 0.040747578954324126, 0...   \n",
       "24999  [[-0.25573601135436225, 0.04136127551250598, 0...   \n",
       "\n",
       "                 sentence_embedding_tf_idf_vecmap_source  \\\n",
       "0      [[-0.04178289919088128, 0.003289124538910825, ...   \n",
       "1      [[-0.10786788910627365, 0.14334604144096375, -...   \n",
       "2      [[-0.04082566372040908, -0.07944126290264207, ...   \n",
       "3      [[-0.04227790194857881, -0.00697155921507797, ...   \n",
       "4      [[-0.16844998753889942, 0.057748788697695064, ...   \n",
       "...                                                  ...   \n",
       "24995  [[-0.13079217395478768, 0.01262385431881695, 0...   \n",
       "24996  [[-0.1793727918531777, -0.01970709230942802, 0...   \n",
       "24997  [[-0.09347213943120848, 0.0061355563743250244,...   \n",
       "24998  [[-0.05026916672191941, 0.005777651995093183, ...   \n",
       "24999  [[-0.05511838036684588, -0.00389641966414871, ...   \n",
       "\n",
       "                 sentence_embedding_tf_idf_vecmap_target  \n",
       "0      [[-0.03635919295923167, 0.0053623071707199, 0....  \n",
       "1      [[-0.14058560132980347, 0.10015597939491272, -...  \n",
       "2      [[-0.07017921368832104, -0.07720816915820333, ...  \n",
       "3      [[-0.0341803192431627, 0.004996396428697362, 0...  \n",
       "4      [[-0.11822048330145368, 0.03690763003978965, 0...  \n",
       "...                                                  ...  \n",
       "24995  [[-0.1001236591809881, 0.01070314706811008, 0....  \n",
       "24996  [[-0.14012105415330461, -0.007039710147790793,...  \n",
       "24997  [[-0.08303151566023889, -0.0011806212530717536...  \n",
       "24998  [[-0.04288726434918977, 0.006473223171571389, ...  \n",
       "24999  [[-0.053235560454585724, 0.010306224228506395,...  \n",
       "\n",
       "[25000 rows x 111 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parallel_sentences.preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_source</th>\n",
       "      <th>text_source</th>\n",
       "      <th>text_target</th>\n",
       "      <th>id_target</th>\n",
       "      <th>text_preprocessed_source</th>\n",
       "      <th>text_preprocessed_target</th>\n",
       "      <th>text_source_spacy</th>\n",
       "      <th>text_target_spacy</th>\n",
       "      <th>word_embedding_proc_5k_source</th>\n",
       "      <th>word_embedding_proc_5k_target</th>\n",
       "      <th>tf_idf_proc_5k_source</th>\n",
       "      <th>tf_idf_proc_5k_target</th>\n",
       "      <th>word_embedding_proc_b_1k_source</th>\n",
       "      <th>word_embedding_proc_b_1k_target</th>\n",
       "      <th>tf_idf_proc_b_1k_source</th>\n",
       "      <th>tf_idf_proc_b_1k_target</th>\n",
       "      <th>word_embedding_vecmap_source</th>\n",
       "      <th>word_embedding_vecmap_target</th>\n",
       "      <th>tf_idf_vecmap_source</th>\n",
       "      <th>tf_idf_vecmap_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>And, finally, Mr President, although it does n...</td>\n",
       "      <td>Da ultimo, signor Presidente, per quanto non c...</td>\n",
       "      <td>0</td>\n",
       "      <td>[,, finally, ,, mr, president, ,, although, fa...</td>\n",
       "      <td>[ultimo, ,, signor, presidente, ,, competa, co...</td>\n",
       "      <td>[And, ,, finally, ,, Mr, President, ,, althoug...</td>\n",
       "      <td>[Da, ultimo, ,, signor, Presidente, ,, per, qu...</td>\n",
       "      <td>finally        mr  president  although  ...</td>\n",
       "      <td>ultimare   signore  presidente  competere...</td>\n",
       "      <td>{'finally': 0.15004748845222704, 'mr': 0.09151...</td>\n",
       "      <td>{'ultimare': 0.15208587310966074, 'signore': 0...</td>\n",
       "      <td>finally        mr  president  although  ...</td>\n",
       "      <td>ultimare   signore  presidente  competere...</td>\n",
       "      <td>{'finally': 0.15004748845222704, 'mr': 0.09151...</td>\n",
       "      <td>{'ultimare': 0.15208587310966074, 'signore': 0...</td>\n",
       "      <td>finally        mr  president  although  ...</td>\n",
       "      <td>ultimare   signore  presidente  competere...</td>\n",
       "      <td>{'finally': 0.15004748845222704, 'mr': 0.09151...</td>\n",
       "      <td>{'ultimare': 0.15208587310966074, 'signore': 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>(Applause)</td>\n",
       "      <td>(Applausi)</td>\n",
       "      <td>1</td>\n",
       "      <td>[(, applause, )]</td>\n",
       "      <td>[(, applausi, )]</td>\n",
       "      <td>[(, Applause, )]</td>\n",
       "      <td>[(, Applausi, )]</td>\n",
       "      <td>applause\n",
       "0   -0.003095\n",
       "1    0.091659\n",
       "2   ...</td>\n",
       "      <td>applausi\n",
       "0   -0.027895\n",
       "1    0.102382\n",
       "2   ...</td>\n",
       "      <td>{'applause': 1.0}</td>\n",
       "      <td>{'applausi': 1.0}</td>\n",
       "      <td>applause\n",
       "0    0.034709\n",
       "1    0.080553\n",
       "2   ...</td>\n",
       "      <td>applausi\n",
       "0   -0.027895\n",
       "1    0.102382\n",
       "2   ...</td>\n",
       "      <td>{'applause': 1.0}</td>\n",
       "      <td>{'applausi': 1.0}</td>\n",
       "      <td>applause\n",
       "0   -0.107868\n",
       "1    0.143346\n",
       "2   ...</td>\n",
       "      <td>applausi\n",
       "0   -0.140586\n",
       "1    0.100156\n",
       "2   ...</td>\n",
       "      <td>{'applause': 1.0}</td>\n",
       "      <td>{'applausi': 1.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Lisbon (continuation)</td>\n",
       "      <td>Lisbona (proseguimento)</td>\n",
       "      <td>2</td>\n",
       "      <td>[lisbon, (, continuation, )]</td>\n",
       "      <td>[lisbona, (, proseguimento, )]</td>\n",
       "      <td>[Lisbon, (, continuation, )]</td>\n",
       "      <td>[Lisbona, (, proseguimento, )]</td>\n",
       "      <td>lisbon  continuation\n",
       "0   -0.067397     ...</td>\n",
       "      <td>lisbona  proseguimento\n",
       "0   -0.017876    ...</td>\n",
       "      <td>{'lisbon': 0.5995482209311499, 'continuation':...</td>\n",
       "      <td>{'lisbona': 0.5696539880474568, 'proseguimento...</td>\n",
       "      <td>lisbon  continuation\n",
       "0   -0.070327     ...</td>\n",
       "      <td>lisbona  proseguimento\n",
       "0   -0.017876    ...</td>\n",
       "      <td>{'lisbon': 0.5995482209311499, 'continuation':...</td>\n",
       "      <td>{'lisbona': 0.5696539880474568, 'proseguimento...</td>\n",
       "      <td>lisbon  continuation\n",
       "0    0.144877     ...</td>\n",
       "      <td>lisbona  proseguimento\n",
       "0    0.135594    ...</td>\n",
       "      <td>{'lisbon': 0.5995482209311499, 'continuation':...</td>\n",
       "      <td>{'lisbona': 0.5696539880474568, 'proseguimento...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>An identical murder was attempted very recentl...</td>\n",
       "      <td>Un tentato omicidio identico a questo è stato ...</td>\n",
       "      <td>3</td>\n",
       "      <td>[identical, murder, attempted, recently, town,...</td>\n",
       "      <td>[tentato, omicidio, identico, stato, perpetrat...</td>\n",
       "      <td>[An, identical, murder, was, attempted, very, ...</td>\n",
       "      <td>[Un, tentato, omicidio, identico, a, questo, è...</td>\n",
       "      <td>identical    murder   attempt  recently  ...</td>\n",
       "      <td>tentare  omicidio  identico    essere   ...</td>\n",
       "      <td>{'identical': 0.29620584974051617, 'murder': 0...</td>\n",
       "      <td>{'tentare': 0.20705547145212297, 'omicidio': 0...</td>\n",
       "      <td>identical    murder   attempt  recently  ...</td>\n",
       "      <td>tentare  omicidio  identico    essere   ...</td>\n",
       "      <td>{'identical': 0.29620584974051617, 'murder': 0...</td>\n",
       "      <td>{'tentare': 0.20705547145212297, 'omicidio': 0...</td>\n",
       "      <td>identical    murder   attempt  recently  ...</td>\n",
       "      <td>tentare  omicidio  identico    essere   ...</td>\n",
       "      <td>{'identical': 0.29620584974051617, 'murder': 0...</td>\n",
       "      <td>{'tentare': 0.20705547145212297, 'omicidio': 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>It will be reconsidered as soon as is practica...</td>\n",
       "      <td>Verrà riconsiderata non appena sarà praticamen...</td>\n",
       "      <td>4</td>\n",
       "      <td>[reconsidered, soon, practically, possible, .]</td>\n",
       "      <td>[verrà, riconsiderata, appena, praticamente, p...</td>\n",
       "      <td>[It, will, be, reconsidered, as, soon, as, is,...</td>\n",
       "      <td>[Verrà, riconsiderata, non, appena, sarà, prat...</td>\n",
       "      <td>reconsider      soon  practically  possib...</td>\n",
       "      <td>verrà  riconsiderare    appena    esse...</td>\n",
       "      <td>{'reconsider': 0.5963543599059239, 'soon': 0.4...</td>\n",
       "      <td>{'verrà': 0.5690474904743331, 'riconsiderare':...</td>\n",
       "      <td>reconsider      soon  practically  possib...</td>\n",
       "      <td>verrà  riconsiderare    appena    esse...</td>\n",
       "      <td>{'reconsider': 0.5963543599059239, 'soon': 0.4...</td>\n",
       "      <td>{'verrà': 0.5690474904743331, 'riconsiderare':...</td>\n",
       "      <td>reconsider      soon  practically  possib...</td>\n",
       "      <td>verrà  riconsiderare    appena    esse...</td>\n",
       "      <td>{'reconsider': 0.5963543599059239, 'soon': 0.4...</td>\n",
       "      <td>{'verrà': 0.5690474904743331, 'riconsiderare':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>24995</td>\n",
       "      <td>Discussions are underway to establish what hel...</td>\n",
       "      <td>Sono in corso discussioni per stabilire quali ...</td>\n",
       "      <td>24995</td>\n",
       "      <td>[discussions, underway, establish, help, would...</td>\n",
       "      <td>[corso, discussioni, stabilire, quali, forme, ...</td>\n",
       "      <td>[Discussions, are, underway, to, establish, wh...</td>\n",
       "      <td>[Sono, in, corso, discussioni, per, stabilire,...</td>\n",
       "      <td>discussion  underway  establish      help...</td>\n",
       "      <td>correre  discussione  stabilire     form...</td>\n",
       "      <td>{'discussion': 0.37636434315557893, 'underway'...</td>\n",
       "      <td>{'correre': 0.3674241790185676, 'discussione':...</td>\n",
       "      <td>discussion  underway  establish      help...</td>\n",
       "      <td>correre  discussione  stabilire     form...</td>\n",
       "      <td>{'discussion': 0.37636434315557893, 'underway'...</td>\n",
       "      <td>{'correre': 0.3674241790185676, 'discussione':...</td>\n",
       "      <td>discussion  underway  establish      help...</td>\n",
       "      <td>correre  discussione  stabilire     form...</td>\n",
       "      <td>{'discussion': 0.37636434315557893, 'underway'...</td>\n",
       "      <td>{'correre': 0.3674241790185676, 'discussione':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>24996</td>\n",
       "      <td>We now need that large majority.</td>\n",
       "      <td>Adesso ci serve una maggioranza ampia.</td>\n",
       "      <td>24996</td>\n",
       "      <td>[need, large, majority, .]</td>\n",
       "      <td>[adesso, serve, maggioranza, ampia, .]</td>\n",
       "      <td>[We, now, need, that, large, majority, .]</td>\n",
       "      <td>[Adesso, ci, serve, una, maggioranza, ampia, .]</td>\n",
       "      <td>need     large  majority\n",
       "0   -0.04593...</td>\n",
       "      <td>adesso   servire  maggioranza     ampio...</td>\n",
       "      <td>{'need': 0.43167925904307497, 'large': 0.61841...</td>\n",
       "      <td>{'adesso': 0.5096849295725233, 'servire': 0.51...</td>\n",
       "      <td>need     large  majority\n",
       "0   -0.04532...</td>\n",
       "      <td>adesso   servire  maggioranza     ampio...</td>\n",
       "      <td>{'need': 0.43167925904307497, 'large': 0.61841...</td>\n",
       "      <td>{'adesso': 0.5096849295725233, 'servire': 0.51...</td>\n",
       "      <td>need     large  majority\n",
       "0   -0.18137...</td>\n",
       "      <td>adesso   servire  maggioranza     ampio...</td>\n",
       "      <td>{'need': 0.43167925904307497, 'large': 0.61841...</td>\n",
       "      <td>{'adesso': 0.5096849295725233, 'servire': 0.51...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>24997</td>\n",
       "      <td>These lists are publicly available and are int...</td>\n",
       "      <td>Tali elenchi sono pubblici e dovrebbero essere...</td>\n",
       "      <td>24997</td>\n",
       "      <td>[lists, publicly, available, intended, debate,...</td>\n",
       "      <td>[tali, elenchi, pubblici, dovrebbero, essere, ...</td>\n",
       "      <td>[These, lists, are, publicly, available, and, ...</td>\n",
       "      <td>[Tali, elenchi, sono, pubblici, e, dovrebbero,...</td>\n",
       "      <td>list  publicly  available    intend  ...</td>\n",
       "      <td>tali    elenco    essere  pubblico   ...</td>\n",
       "      <td>{'list': 0.356935026424723, 'publicly': 0.4921...</td>\n",
       "      <td>{'tali': 0.37609964295086695, 'elenco': 0.4827...</td>\n",
       "      <td>list  publicly  available    intend  ...</td>\n",
       "      <td>tali    elenco    essere  pubblico   ...</td>\n",
       "      <td>{'list': 0.356935026424723, 'publicly': 0.4921...</td>\n",
       "      <td>{'tali': 0.37609964295086695, 'elenco': 0.4827...</td>\n",
       "      <td>list  publicly  available    intend  ...</td>\n",
       "      <td>tali    elenco    essere  pubblico   ...</td>\n",
       "      <td>{'list': 0.356935026424723, 'publicly': 0.4921...</td>\n",
       "      <td>{'tali': 0.37609964295086695, 'elenco': 0.4827...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>24998</td>\n",
       "      <td>However, the ring of friends is a different pr...</td>\n",
       "      <td>E' però un altro discorso quello che riguarda ...</td>\n",
       "      <td>24998</td>\n",
       "      <td>[however, ,, ring, friends, different, project...</td>\n",
       "      <td>[', però, altro, discorso, riguarda, l'anello,...</td>\n",
       "      <td>[However, ,, the, ring, of, friends, is, a, di...</td>\n",
       "      <td>[E', però, un, altro, discorso, quello, che, r...</td>\n",
       "      <td>however      ring    friend  different  ...</td>\n",
       "      <td>però     altro  riguardare    anello ...</td>\n",
       "      <td>{'however': 0.11754323865835557, 'ring': 0.235...</td>\n",
       "      <td>{'e'': 0.12661952741185759, 'però': 0.14103306...</td>\n",
       "      <td>however      ring    friend  different  ...</td>\n",
       "      <td>però     altro  riguardare    anello ...</td>\n",
       "      <td>{'however': 0.11754323865835557, 'ring': 0.235...</td>\n",
       "      <td>{'e'': 0.12661952741185759, 'però': 0.14103306...</td>\n",
       "      <td>however      ring    friend  different  ...</td>\n",
       "      <td>però     altro  riguardare    anello ...</td>\n",
       "      <td>{'however': 0.11754323865835557, 'ring': 0.235...</td>\n",
       "      <td>{'e'': 0.12661952741185759, 'però': 0.14103306...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>24999</td>\n",
       "      <td>The serious psychological problems they face m...</td>\n",
       "      <td>Ai gravi problemi psicologici di cui soffrono ...</td>\n",
       "      <td>24999</td>\n",
       "      <td>[serious, psychological, problems, face, must,...</td>\n",
       "      <td>[gravi, problemi, psicologici, soffrono, dobbi...</td>\n",
       "      <td>[The, serious, psychological, problems, they, ...</td>\n",
       "      <td>[Ai, gravi, problemi, psicologici, di, cui, so...</td>\n",
       "      <td>serious  psychological   problem      fa...</td>\n",
       "      <td>grave  problema  psicologico  soffrire...</td>\n",
       "      <td>{'serious': 0.17665014990419023, 'psychologica...</td>\n",
       "      <td>{'grave': 0.20525204435642808, 'problema': 0.1...</td>\n",
       "      <td>serious  psychological   problem      fa...</td>\n",
       "      <td>grave  problema  psicologico  soffrire...</td>\n",
       "      <td>{'serious': 0.17665014990419023, 'psychologica...</td>\n",
       "      <td>{'grave': 0.20525204435642808, 'problema': 0.1...</td>\n",
       "      <td>serious  psychological   problem      fa...</td>\n",
       "      <td>grave  problema  psicologico  soffrire...</td>\n",
       "      <td>{'serious': 0.17665014990419023, 'psychologica...</td>\n",
       "      <td>{'grave': 0.20525204435642808, 'problema': 0.1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id_source                                        text_source  \\\n",
       "0              0  And, finally, Mr President, although it does n...   \n",
       "1              1                                         (Applause)   \n",
       "2              2                              Lisbon (continuation)   \n",
       "3              3  An identical murder was attempted very recentl...   \n",
       "4              4  It will be reconsidered as soon as is practica...   \n",
       "...          ...                                                ...   \n",
       "24995      24995  Discussions are underway to establish what hel...   \n",
       "24996      24996                   We now need that large majority.   \n",
       "24997      24997  These lists are publicly available and are int...   \n",
       "24998      24998  However, the ring of friends is a different pr...   \n",
       "24999      24999  The serious psychological problems they face m...   \n",
       "\n",
       "                                             text_target  id_target  \\\n",
       "0      Da ultimo, signor Presidente, per quanto non c...          0   \n",
       "1                                             (Applausi)          1   \n",
       "2                                Lisbona (proseguimento)          2   \n",
       "3      Un tentato omicidio identico a questo è stato ...          3   \n",
       "4      Verrà riconsiderata non appena sarà praticamen...          4   \n",
       "...                                                  ...        ...   \n",
       "24995  Sono in corso discussioni per stabilire quali ...      24995   \n",
       "24996             Adesso ci serve una maggioranza ampia.      24996   \n",
       "24997  Tali elenchi sono pubblici e dovrebbero essere...      24997   \n",
       "24998  E' però un altro discorso quello che riguarda ...      24998   \n",
       "24999  Ai gravi problemi psicologici di cui soffrono ...      24999   \n",
       "\n",
       "                                text_preprocessed_source  \\\n",
       "0      [,, finally, ,, mr, president, ,, although, fa...   \n",
       "1                                       [(, applause, )]   \n",
       "2                           [lisbon, (, continuation, )]   \n",
       "3      [identical, murder, attempted, recently, town,...   \n",
       "4         [reconsidered, soon, practically, possible, .]   \n",
       "...                                                  ...   \n",
       "24995  [discussions, underway, establish, help, would...   \n",
       "24996                         [need, large, majority, .]   \n",
       "24997  [lists, publicly, available, intended, debate,...   \n",
       "24998  [however, ,, ring, friends, different, project...   \n",
       "24999  [serious, psychological, problems, face, must,...   \n",
       "\n",
       "                                text_preprocessed_target  \\\n",
       "0      [ultimo, ,, signor, presidente, ,, competa, co...   \n",
       "1                                       [(, applausi, )]   \n",
       "2                         [lisbona, (, proseguimento, )]   \n",
       "3      [tentato, omicidio, identico, stato, perpetrat...   \n",
       "4      [verrà, riconsiderata, appena, praticamente, p...   \n",
       "...                                                  ...   \n",
       "24995  [corso, discussioni, stabilire, quali, forme, ...   \n",
       "24996             [adesso, serve, maggioranza, ampia, .]   \n",
       "24997  [tali, elenchi, pubblici, dovrebbero, essere, ...   \n",
       "24998  [', però, altro, discorso, riguarda, l'anello,...   \n",
       "24999  [gravi, problemi, psicologici, soffrono, dobbi...   \n",
       "\n",
       "                                       text_source_spacy  \\\n",
       "0      [And, ,, finally, ,, Mr, President, ,, althoug...   \n",
       "1                                       [(, Applause, )]   \n",
       "2                           [Lisbon, (, continuation, )]   \n",
       "3      [An, identical, murder, was, attempted, very, ...   \n",
       "4      [It, will, be, reconsidered, as, soon, as, is,...   \n",
       "...                                                  ...   \n",
       "24995  [Discussions, are, underway, to, establish, wh...   \n",
       "24996          [We, now, need, that, large, majority, .]   \n",
       "24997  [These, lists, are, publicly, available, and, ...   \n",
       "24998  [However, ,, the, ring, of, friends, is, a, di...   \n",
       "24999  [The, serious, psychological, problems, they, ...   \n",
       "\n",
       "                                       text_target_spacy  \\\n",
       "0      [Da, ultimo, ,, signor, Presidente, ,, per, qu...   \n",
       "1                                       [(, Applausi, )]   \n",
       "2                         [Lisbona, (, proseguimento, )]   \n",
       "3      [Un, tentato, omicidio, identico, a, questo, è...   \n",
       "4      [Verrà, riconsiderata, non, appena, sarà, prat...   \n",
       "...                                                  ...   \n",
       "24995  [Sono, in, corso, discussioni, per, stabilire,...   \n",
       "24996    [Adesso, ci, serve, una, maggioranza, ampia, .]   \n",
       "24997  [Tali, elenchi, sono, pubblici, e, dovrebbero,...   \n",
       "24998  [E', però, un, altro, discorso, quello, che, r...   \n",
       "24999  [Ai, gravi, problemi, psicologici, di, cui, so...   \n",
       "\n",
       "                           word_embedding_proc_5k_source  \\\n",
       "0            finally        mr  president  although  ...   \n",
       "1           applause\n",
       "0   -0.003095\n",
       "1    0.091659\n",
       "2   ...   \n",
       "2             lisbon  continuation\n",
       "0   -0.067397     ...   \n",
       "3           identical    murder   attempt  recently  ...   \n",
       "4           reconsider      soon  practically  possib...   \n",
       "...                                                  ...   \n",
       "24995       discussion  underway  establish      help...   \n",
       "24996           need     large  majority\n",
       "0   -0.04593...   \n",
       "24997           list  publicly  available    intend  ...   \n",
       "24998        however      ring    friend  different  ...   \n",
       "24999        serious  psychological   problem      fa...   \n",
       "\n",
       "                           word_embedding_proc_5k_target  \\\n",
       "0           ultimare   signore  presidente  competere...   \n",
       "1           applausi\n",
       "0   -0.027895\n",
       "1    0.102382\n",
       "2   ...   \n",
       "2            lisbona  proseguimento\n",
       "0   -0.017876    ...   \n",
       "3            tentare  omicidio  identico    essere   ...   \n",
       "4              verrà  riconsiderare    appena    esse...   \n",
       "...                                                  ...   \n",
       "24995        correre  discussione  stabilire     form...   \n",
       "24996         adesso   servire  maggioranza     ampio...   \n",
       "24997           tali    elenco    essere  pubblico   ...   \n",
       "24998           però     altro  riguardare    anello ...   \n",
       "24999          grave  problema  psicologico  soffrire...   \n",
       "\n",
       "                                   tf_idf_proc_5k_source  \\\n",
       "0      {'finally': 0.15004748845222704, 'mr': 0.09151...   \n",
       "1                                      {'applause': 1.0}   \n",
       "2      {'lisbon': 0.5995482209311499, 'continuation':...   \n",
       "3      {'identical': 0.29620584974051617, 'murder': 0...   \n",
       "4      {'reconsider': 0.5963543599059239, 'soon': 0.4...   \n",
       "...                                                  ...   \n",
       "24995  {'discussion': 0.37636434315557893, 'underway'...   \n",
       "24996  {'need': 0.43167925904307497, 'large': 0.61841...   \n",
       "24997  {'list': 0.356935026424723, 'publicly': 0.4921...   \n",
       "24998  {'however': 0.11754323865835557, 'ring': 0.235...   \n",
       "24999  {'serious': 0.17665014990419023, 'psychologica...   \n",
       "\n",
       "                                   tf_idf_proc_5k_target  \\\n",
       "0      {'ultimare': 0.15208587310966074, 'signore': 0...   \n",
       "1                                      {'applausi': 1.0}   \n",
       "2      {'lisbona': 0.5696539880474568, 'proseguimento...   \n",
       "3      {'tentare': 0.20705547145212297, 'omicidio': 0...   \n",
       "4      {'verrà': 0.5690474904743331, 'riconsiderare':...   \n",
       "...                                                  ...   \n",
       "24995  {'correre': 0.3674241790185676, 'discussione':...   \n",
       "24996  {'adesso': 0.5096849295725233, 'servire': 0.51...   \n",
       "24997  {'tali': 0.37609964295086695, 'elenco': 0.4827...   \n",
       "24998  {'e'': 0.12661952741185759, 'però': 0.14103306...   \n",
       "24999  {'grave': 0.20525204435642808, 'problema': 0.1...   \n",
       "\n",
       "                         word_embedding_proc_b_1k_source  \\\n",
       "0            finally        mr  president  although  ...   \n",
       "1           applause\n",
       "0    0.034709\n",
       "1    0.080553\n",
       "2   ...   \n",
       "2             lisbon  continuation\n",
       "0   -0.070327     ...   \n",
       "3           identical    murder   attempt  recently  ...   \n",
       "4           reconsider      soon  practically  possib...   \n",
       "...                                                  ...   \n",
       "24995       discussion  underway  establish      help...   \n",
       "24996           need     large  majority\n",
       "0   -0.04532...   \n",
       "24997           list  publicly  available    intend  ...   \n",
       "24998        however      ring    friend  different  ...   \n",
       "24999        serious  psychological   problem      fa...   \n",
       "\n",
       "                         word_embedding_proc_b_1k_target  \\\n",
       "0           ultimare   signore  presidente  competere...   \n",
       "1           applausi\n",
       "0   -0.027895\n",
       "1    0.102382\n",
       "2   ...   \n",
       "2            lisbona  proseguimento\n",
       "0   -0.017876    ...   \n",
       "3            tentare  omicidio  identico    essere   ...   \n",
       "4              verrà  riconsiderare    appena    esse...   \n",
       "...                                                  ...   \n",
       "24995        correre  discussione  stabilire     form...   \n",
       "24996         adesso   servire  maggioranza     ampio...   \n",
       "24997           tali    elenco    essere  pubblico   ...   \n",
       "24998           però     altro  riguardare    anello ...   \n",
       "24999          grave  problema  psicologico  soffrire...   \n",
       "\n",
       "                                 tf_idf_proc_b_1k_source  \\\n",
       "0      {'finally': 0.15004748845222704, 'mr': 0.09151...   \n",
       "1                                      {'applause': 1.0}   \n",
       "2      {'lisbon': 0.5995482209311499, 'continuation':...   \n",
       "3      {'identical': 0.29620584974051617, 'murder': 0...   \n",
       "4      {'reconsider': 0.5963543599059239, 'soon': 0.4...   \n",
       "...                                                  ...   \n",
       "24995  {'discussion': 0.37636434315557893, 'underway'...   \n",
       "24996  {'need': 0.43167925904307497, 'large': 0.61841...   \n",
       "24997  {'list': 0.356935026424723, 'publicly': 0.4921...   \n",
       "24998  {'however': 0.11754323865835557, 'ring': 0.235...   \n",
       "24999  {'serious': 0.17665014990419023, 'psychologica...   \n",
       "\n",
       "                                 tf_idf_proc_b_1k_target  \\\n",
       "0      {'ultimare': 0.15208587310966074, 'signore': 0...   \n",
       "1                                      {'applausi': 1.0}   \n",
       "2      {'lisbona': 0.5696539880474568, 'proseguimento...   \n",
       "3      {'tentare': 0.20705547145212297, 'omicidio': 0...   \n",
       "4      {'verrà': 0.5690474904743331, 'riconsiderare':...   \n",
       "...                                                  ...   \n",
       "24995  {'correre': 0.3674241790185676, 'discussione':...   \n",
       "24996  {'adesso': 0.5096849295725233, 'servire': 0.51...   \n",
       "24997  {'tali': 0.37609964295086695, 'elenco': 0.4827...   \n",
       "24998  {'e'': 0.12661952741185759, 'però': 0.14103306...   \n",
       "24999  {'grave': 0.20525204435642808, 'problema': 0.1...   \n",
       "\n",
       "                            word_embedding_vecmap_source  \\\n",
       "0            finally        mr  president  although  ...   \n",
       "1           applause\n",
       "0   -0.107868\n",
       "1    0.143346\n",
       "2   ...   \n",
       "2             lisbon  continuation\n",
       "0    0.144877     ...   \n",
       "3           identical    murder   attempt  recently  ...   \n",
       "4           reconsider      soon  practically  possib...   \n",
       "...                                                  ...   \n",
       "24995       discussion  underway  establish      help...   \n",
       "24996           need     large  majority\n",
       "0   -0.18137...   \n",
       "24997           list  publicly  available    intend  ...   \n",
       "24998        however      ring    friend  different  ...   \n",
       "24999        serious  psychological   problem      fa...   \n",
       "\n",
       "                            word_embedding_vecmap_target  \\\n",
       "0           ultimare   signore  presidente  competere...   \n",
       "1           applausi\n",
       "0   -0.140586\n",
       "1    0.100156\n",
       "2   ...   \n",
       "2            lisbona  proseguimento\n",
       "0    0.135594    ...   \n",
       "3            tentare  omicidio  identico    essere   ...   \n",
       "4              verrà  riconsiderare    appena    esse...   \n",
       "...                                                  ...   \n",
       "24995        correre  discussione  stabilire     form...   \n",
       "24996         adesso   servire  maggioranza     ampio...   \n",
       "24997           tali    elenco    essere  pubblico   ...   \n",
       "24998           però     altro  riguardare    anello ...   \n",
       "24999          grave  problema  psicologico  soffrire...   \n",
       "\n",
       "                                    tf_idf_vecmap_source  \\\n",
       "0      {'finally': 0.15004748845222704, 'mr': 0.09151...   \n",
       "1                                      {'applause': 1.0}   \n",
       "2      {'lisbon': 0.5995482209311499, 'continuation':...   \n",
       "3      {'identical': 0.29620584974051617, 'murder': 0...   \n",
       "4      {'reconsider': 0.5963543599059239, 'soon': 0.4...   \n",
       "...                                                  ...   \n",
       "24995  {'discussion': 0.37636434315557893, 'underway'...   \n",
       "24996  {'need': 0.43167925904307497, 'large': 0.61841...   \n",
       "24997  {'list': 0.356935026424723, 'publicly': 0.4921...   \n",
       "24998  {'however': 0.11754323865835557, 'ring': 0.235...   \n",
       "24999  {'serious': 0.17665014990419023, 'psychologica...   \n",
       "\n",
       "                                    tf_idf_vecmap_target  \n",
       "0      {'ultimare': 0.15208587310966074, 'signore': 0...  \n",
       "1                                      {'applausi': 1.0}  \n",
       "2      {'lisbona': 0.5696539880474568, 'proseguimento...  \n",
       "3      {'tentare': 0.20705547145212297, 'omicidio': 0...  \n",
       "4      {'verrà': 0.5690474904743331, 'riconsiderare':...  \n",
       "...                                                  ...  \n",
       "24995  {'correre': 0.3674241790185676, 'discussione':...  \n",
       "24996  {'adesso': 0.5096849295725233, 'servire': 0.51...  \n",
       "24997  {'tali': 0.37609964295086695, 'elenco': 0.4827...  \n",
       "24998  {'e'': 0.12661952741185759, 'però': 0.14103306...  \n",
       "24999  {'grave': 0.20525204435642808, 'problema': 0.1...  \n",
       "\n",
       "[25000 rows x 20 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parallel_sentences.dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "preprocessed_data = pd.read_json(\"../data/interim/preprocessed_data_en_it.json\")\n",
    "parallel_sentences = PreprocessingEuroParl(df_sampled_path=\"../data/interim/europarl_en_it.pkl\")\n",
    "parallel_sentences.preprocessed = preprocessed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_sentences.preprocessed.columns[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Create data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we create the datasets for the training of the supervised model and the data for the supervised and unsupervised retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from src.data import DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_model = 20000\n",
    "n_queries = 100\n",
    "n_retrieval = 5000\n",
    "k = 10\n",
    "sample_size_k = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: '__init__' in 0.0 seconds.\n"
     ]
    }
   ],
   "source": [
    "dataset = DataSet(parallel_sentences.preprocessed)\n",
    "#dataset = DataSet(preprocessed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'split_model_retrieval' in 0.0 seconds.\n"
     ]
    }
   ],
   "source": [
    "dataset.split_model_retrieval(n_model, n_retrieval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.create_model_index(n_model, k, sample_size_k,\n",
    "     \"sentence_embedding_tf_idf_proc_5k_source\", \"sentence_embedding_tf_idf_proc_5k_target\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.model_dataset_index.reset_index(drop=True).to_feather(\"../data/processed/dataset_model_index_en_it.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# pd.read_feather(\"../data/processed/dataset_model_index.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset.create_retrieval_index(n_queries)\n",
    "import pandas as pd\n",
    "# If your pandas version is old, use this instead\n",
    "query = pd.DataFrame({\"id_source\": dataset.retrieval_subset.iloc[:n_queries][\"id_source\"]})\n",
    "documents = pd.DataFrame({\"id_target\": dataset.retrieval_subset[\"id_target\"]})\n",
    "index = pd.MultiIndex.from_product([dataset.retrieval_subset.iloc[:n_queries][\"id_source\"], dataset.retrieval_subset[\"id_target\"]], names = [\"id_source\", \"id_target\"])\n",
    "dataset.retrieval_dataset_index = pd.DataFrame(index = index).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.retrieval_dataset_index.reset_index(drop=True).to_feather(\"../data/processed/dataset_retrieval_index_en_it.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# pd.read_feather(\"../data/processed/dataset_retrieval_index.feather\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%% md\n"
    }
   },
   "source": [
    "## IV. Create features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we create features for our model, that are sentence based and should be created before the text is preprocessed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#%autoreload 2\n",
    "from src.features import feature_generation_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# with open(r\"../data/processed/correlated_features.pkl\", \"rb\") as file:\n",
    "#    chosen_features = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generation of the training data for the supervised classifciation model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "features_model = feature_generation_class.FeatureGeneration(dataset.model_dataset_index, \n",
    "                                                             parallel_sentences.preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "features_model.create_feature_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_model.create_sentence_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_model.create_embedding_features(\"proc_5k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_model.create_embedding_features(\"proc_b_1k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_model.create_embedding_features(\"vecmap\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_model.feature_dataframe.reset_index(drop=True).to_feather(\"../data/processed/feature_model_en_it.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# pd.read_feather(\"../data/processed/feature_model.feather\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generation of the data for the crosslingual information retrieval task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_retrieval = feature_generation_class.FeatureGeneration(dataset.retrieval_dataset_index, \n",
    "                                                            parallel_sentences.preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'create_feature_dataframe' in 0.03 seconds.\n"
     ]
    }
   ],
   "source": [
    "features_retrieval.create_feature_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'difference_numerical' in 0.11 seconds.\n",
      "Finished function: 'relative_difference_numerical' in 0.02 seconds.\n",
      "Finished function: 'normalized_difference_numerical' in 0.03 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/I534344/Google Drive/crosslingual-information-retrieval/src/features/sentence_features.py:21: RuntimeWarning: divide by zero encountered in log\n",
      "  return abs(target_array - source_array).replace(np.nan, 0).replace(np.inf, 0).replace(np.log(0), 0)\n",
      "/Users/I534344/Google Drive/crosslingual-information-retrieval/src/features/sentence_features.py:38: RuntimeWarning: divide by zero encountered in log\n",
      "  0), 0)\n",
      "/Users/I534344/Google Drive/crosslingual-information-retrieval/src/features/sentence_features.py:58: RuntimeWarning: divide by zero encountered in log\n",
      "  np.log(0), 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'difference_numerical' in 0.01 seconds.\n",
      "Finished function: 'relative_difference_numerical' in 0.02 seconds.\n",
      "Finished function: 'normalized_difference_numerical' in 0.04 seconds.\n",
      "Finished function: 'difference_numerical' in 0.02 seconds.\n",
      "Finished function: 'relative_difference_numerical' in 0.03 seconds.\n",
      "Finished function: 'normalized_difference_numerical' in 0.03 seconds.\n",
      "Finished function: 'difference_numerical' in 0.01 seconds.\n",
      "Finished function: 'relative_difference_numerical' in 0.03 seconds.\n",
      "Finished function: 'normalized_difference_numerical' in 0.03 seconds.\n",
      "Finished function: 'difference_numerical' in 0.01 seconds.\n",
      "Finished function: 'relative_difference_numerical' in 0.02 seconds.\n",
      "Finished function: 'normalized_difference_numerical' in 0.03 seconds.\n",
      "Finished function: 'difference_numerical' in 0.02 seconds.\n",
      "Finished function: 'relative_difference_numerical' in 0.03 seconds.\n",
      "Finished function: 'normalized_difference_numerical' in 0.03 seconds.\n",
      "Finished function: 'difference_numerical' in 0.01 seconds.\n",
      "Finished function: 'relative_difference_numerical' in 0.02 seconds.\n",
      "Finished function: 'normalized_difference_numerical' in 0.02 seconds.\n",
      "Finished function: 'difference_numerical' in 0.01 seconds.\n",
      "Finished function: 'relative_difference_numerical' in 0.02 seconds.\n",
      "Finished function: 'normalized_difference_numerical' in 0.04 seconds.\n",
      "Finished function: 'difference_numerical' in 0.02 seconds.\n",
      "Finished function: 'relative_difference_numerical' in 0.02 seconds.\n",
      "Finished function: 'normalized_difference_numerical' in 0.04 seconds.\n",
      "Finished function: 'difference_numerical' in 0.02 seconds.\n",
      "Finished function: 'relative_difference_numerical' in 0.02 seconds.\n",
      "Finished function: 'normalized_difference_numerical' in 0.03 seconds.\n",
      "Finished function: 'difference_numerical' in 0.03 seconds.\n",
      "Finished function: 'relative_difference_numerical' in 0.02 seconds.\n",
      "Finished function: 'normalized_difference_numerical' in 0.03 seconds.\n",
      "Finished function: 'difference_numerical' in 0.01 seconds.\n",
      "Finished function: 'relative_difference_numerical' in 0.02 seconds.\n",
      "Finished function: 'normalized_difference_numerical' in 0.04 seconds.\n",
      "Finished function: 'difference_numerical' in 0.03 seconds.\n",
      "Finished function: 'relative_difference_numerical' in 0.03 seconds.\n",
      "Finished function: 'normalized_difference_numerical' in 0.04 seconds.\n",
      "Finished function: 'difference_numerical' in 0.03 seconds.\n",
      "Finished function: 'relative_difference_numerical' in 0.04 seconds.\n",
      "Finished function: 'normalized_difference_numerical' in 0.02 seconds.\n",
      "Finished function: 'difference_numerical' in 0.02 seconds.\n",
      "Finished function: 'relative_difference_numerical' in 0.02 seconds.\n",
      "Finished function: 'normalized_difference_numerical' in 0.02 seconds.\n",
      "Finished function: 'difference_numerical' in 0.01 seconds.\n",
      "Finished function: 'relative_difference_numerical' in 0.03 seconds.\n",
      "Finished function: 'normalized_difference_numerical' in 0.04 seconds.\n",
      "Finished function: 'difference_numerical' in 0.02 seconds.\n",
      "Finished function: 'relative_difference_numerical' in 0.02 seconds.\n",
      "Finished function: 'normalized_difference_numerical' in 0.05 seconds.\n",
      "Finished function: 'difference_numerical' in 0.02 seconds.\n",
      "Finished function: 'relative_difference_numerical' in 0.03 seconds.\n",
      "Finished function: 'normalized_difference_numerical' in 0.04 seconds.\n",
      "Finished function: 'difference_numerical' in 0.01 seconds.\n",
      "Finished function: 'relative_difference_numerical' in 0.03 seconds.\n",
      "Finished function: 'normalized_difference_numerical' in 0.03 seconds.\n",
      "Finished function: 'difference_numerical' in 0.02 seconds.\n",
      "Finished function: 'relative_difference_numerical' in 0.03 seconds.\n",
      "Finished function: 'normalized_difference_numerical' in 0.03 seconds.\n",
      "Finished function: 'difference_numerical' in 0.01 seconds.\n",
      "Finished function: 'relative_difference_numerical' in 0.01 seconds.\n",
      "Finished function: 'normalized_difference_numerical' in 0.04 seconds.\n",
      "Finished function: 'difference_numerical' in 0.01 seconds.\n",
      "Finished function: 'relative_difference_numerical' in 0.02 seconds.\n",
      "Finished function: 'normalized_difference_numerical' in 0.04 seconds.\n",
      "Finished function: 'difference_numerical' in 0.01 seconds.\n",
      "Finished function: 'relative_difference_numerical' in 0.03 seconds.\n",
      "Finished function: 'normalized_difference_numerical' in 0.03 seconds.\n",
      "Finished function: 'difference_numerical' in 0.01 seconds.\n",
      "Finished function: 'relative_difference_numerical' in 0.02 seconds.\n",
      "Finished function: 'normalized_difference_numerical' in 0.04 seconds.\n",
      "Finished function: 'difference_numerical' in 0.03 seconds.\n",
      "Finished function: 'relative_difference_numerical' in 0.04 seconds.\n",
      "Finished function: 'normalized_difference_numerical' in 0.05 seconds.\n",
      "Finished function: 'difference_numerical' in 0.03 seconds.\n",
      "Finished function: 'relative_difference_numerical' in 0.03 seconds.\n",
      "Finished function: 'normalized_difference_numerical' in 0.06 seconds.\n",
      "Finished function: 'difference_numerical' in 0.04 seconds.\n",
      "Finished function: 'relative_difference_numerical' in 0.03 seconds.\n",
      "Finished function: 'normalized_difference_numerical' in 0.05 seconds.\n",
      "Finished function: 'difference_numerical' in 0.02 seconds.\n",
      "Finished function: 'relative_difference_numerical' in 0.06 seconds.\n",
      "Finished function: 'normalized_difference_numerical' in 0.03 seconds.\n",
      "Finished function: 'difference_numerical' in 0.02 seconds.\n",
      "Finished function: 'relative_difference_numerical' in 0.03 seconds.\n",
      "Finished function: 'normalized_difference_numerical' in 0.03 seconds.\n",
      "Finished function: 'difference_numerical' in 0.04 seconds.\n",
      "Finished function: 'relative_difference_numerical' in 0.02 seconds.\n",
      "Finished function: 'normalized_difference_numerical' in 0.05 seconds.\n",
      "Finished function: 'difference_numerical' in 0.02 seconds.\n",
      "Finished function: 'relative_difference_numerical' in 0.02 seconds.\n",
      "Finished function: 'normalized_difference_numerical' in 0.05 seconds.\n",
      "Finished function: 'difference_numerical' in 0.02 seconds.\n",
      "Finished function: 'relative_difference_numerical' in 0.03 seconds.\n",
      "Finished function: 'normalized_difference_numerical' in 0.03 seconds.\n",
      "Finished function: 'difference_numerical' in 0.02 seconds.\n",
      "Finished function: 'relative_difference_numerical' in 0.02 seconds.\n",
      "Finished function: 'normalized_difference_numerical' in 0.02 seconds.\n",
      "Finished function: 'difference_numerical' in 0.01 seconds.\n",
      "Finished function: 'relative_difference_numerical' in 0.02 seconds.\n",
      "Finished function: 'normalized_difference_numerical' in 0.02 seconds.\n",
      "Finished function: 'difference_numerical' in 0.01 seconds.\n",
      "Finished function: 'relative_difference_numerical' in 0.01 seconds.\n",
      "Finished function: 'normalized_difference_numerical' in 0.03 seconds.\n",
      "Finished function: 'difference_numerical' in 0.02 seconds.\n",
      "Finished function: 'relative_difference_numerical' in 0.01 seconds.\n",
      "Finished function: 'normalized_difference_numerical' in 0.02 seconds.\n",
      "Finished function: 'difference_numerical' in 0.03 seconds.\n",
      "Finished function: 'relative_difference_numerical' in 0.01 seconds.\n",
      "Finished function: 'normalized_difference_numerical' in 0.03 seconds.\n",
      "Finished function: 'difference_numerical' in 0.02 seconds.\n",
      "Finished function: 'relative_difference_numerical' in 0.02 seconds.\n",
      "Finished function: 'normalized_difference_numerical' in 0.02 seconds.\n",
      "Finished function: 'difference_numerical' in 0.02 seconds.\n",
      "Finished function: 'relative_difference_numerical' in 0.01 seconds.\n",
      "Finished function: 'normalized_difference_numerical' in 0.03 seconds.\n",
      "Finished function: 'difference_numerical' in 0.01 seconds.\n",
      "Finished function: 'relative_difference_numerical' in 0.02 seconds.\n",
      "Finished function: 'normalized_difference_numerical' in 0.02 seconds.\n",
      "Finished function: 'difference_numerical' in 0.01 seconds.\n",
      "Finished function: 'relative_difference_numerical' in 0.02 seconds.\n",
      "Finished function: 'normalized_difference_numerical' in 0.02 seconds.\n",
      "Finished function: 'difference_numerical' in 0.01 seconds.\n",
      "Finished function: 'relative_difference_numerical' in 0.01 seconds.\n",
      "Finished function: 'normalized_difference_numerical' in 0.02 seconds.\n",
      "Finished function: 'difference_numerical' in 0.01 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/500000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'relative_difference_numerical' in 0.02 seconds.\n",
      "Finished function: 'normalized_difference_numerical' in 0.02 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500000/500000 [00:11<00:00, 41836.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'jaccard' in 12.1 seconds.\n",
      "Finished function: 'create_sentence_features' in 18.0 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "features_retrieval.create_sentence_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500000/500000 [04:26<00:00, 1878.83it/s]\n",
      "  0%|          | 0/500000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'cosine_similarity_vector' in 266.2 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500000/500000 [03:31<00:00, 2362.75it/s]\n",
      "  0%|          | 302/500000 [00:00<02:45, 3018.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'cosine_similarity_vector' in 211.71 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500000/500000 [02:51<00:00, 2923.89it/s]\n",
      "  0%|          | 0/500000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'euclidean_distance_vector' in 171.08 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500000/500000 [02:29<00:00, 3348.84it/s]\n",
      "  0%|          | 0/500000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'euclidean_distance_vector' in 149.41 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500000/500000 [00:12<00:00, 39142.67it/s]\n",
      "  0%|          | 1995/500000 [00:00<00:24, 19944.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'jaccard' in 12.87 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500000/500000 [00:19<00:00, 26076.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'jaccard' in 19.26 seconds.\n",
      "Finished function: 'create_embedding_features' in 830.61 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "features_retrieval.create_embedding_features(\"proc_5k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500000/500000 [03:27<00:00, 2404.07it/s]\n",
      "  0%|          | 0/500000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'cosine_similarity_vector' in 208.07 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500000/500000 [03:24<00:00, 2444.37it/s]\n",
      "  0%|          | 320/500000 [00:00<02:36, 3194.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'cosine_similarity_vector' in 204.65 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500000/500000 [02:13<00:00, 3756.44it/s]\n",
      "  0%|          | 694/500000 [00:00<02:28, 3356.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'euclidean_distance_vector' in 133.16 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500000/500000 [02:20<00:00, 3567.88it/s]\n",
      "  1%|          | 3426/500000 [00:00<00:14, 34222.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'euclidean_distance_vector' in 140.19 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500000/500000 [00:12<00:00, 41363.17it/s]\n",
      "  1%|          | 3563/500000 [00:00<00:13, 35625.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'jaccard' in 12.17 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500000/500000 [00:11<00:00, 41815.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'jaccard' in 12.04 seconds.\n",
      "Finished function: 'create_embedding_features' in 710.35 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "features_retrieval.create_embedding_features(\"proc_b_1k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500000/500000 [03:15<00:00, 2555.87it/s]\n",
      "  0%|          | 175/500000 [00:00<04:45, 1748.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'cosine_similarity_vector' in 195.71 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500000/500000 [03:16<00:00, 2539.70it/s]\n",
      "  0%|          | 699/500000 [00:00<02:29, 3345.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'cosine_similarity_vector' in 196.97 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500000/500000 [02:13<00:00, 3745.78it/s]\n",
      "  0%|          | 700/500000 [00:00<02:29, 3350.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'euclidean_distance_vector' in 133.53 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500000/500000 [02:13<00:00, 3756.71it/s]\n",
      "  1%|          | 3630/500000 [00:00<00:13, 36293.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'euclidean_distance_vector' in 133.15 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500000/500000 [00:15<00:00, 32559.28it/s]\n",
      "  0%|          | 2465/500000 [00:00<00:20, 24645.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'jaccard' in 15.43 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500000/500000 [00:12<00:00, 39087.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'jaccard' in 12.89 seconds.\n",
      "Finished function: 'create_embedding_features' in 687.71 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "features_retrieval.create_embedding_features(\"vecmap\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_retrieval.feature_dataframe.reset_index(drop=True).to_feather(\"../data/processed/feature_retrieval_en_it.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# pd.read_feather(\"../data/processed/feature_retrieval.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
