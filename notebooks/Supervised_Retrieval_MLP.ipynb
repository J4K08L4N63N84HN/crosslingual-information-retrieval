{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Supervised Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In this notebook we use the supervised classification model for a supervised crosslingual information retrieval task using the scikit learn inbuild MLPClassifier. We will first prepare the data and then use a pipeline of forward feature selection and hyperparameter optimization via grid search. We see that our default settings perform best, since we do not have the computing power and time to test various different network architectures. After training our model, we use the trained model for English-German on Italian, Polish and Document level, and see that the results for the other languages are pretty good, but on document level as expected not really."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from src.models.predict_model import MAP_score, threshold_counts,feature_selection, pipeline_model_optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## I. Import Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we import the feature dataframe for the retrieval task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_dataframe=pd.read_feather(\"../data/processed/feature_model_en_de.feather\")\n",
    "feature_retrieval=pd.read_feather(\"../data/processed/feature_retrieval_en_de.feather\")\n",
    "feature_dataframe = feature_dataframe.rename(columns={\"id_source\": \"source_id\", \"id_target\": \"target_id\"})\n",
    "feature_retrieval = feature_retrieval.rename(columns={\"id_source\": \"source_id\", \"id_target\": \"target_id\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_id</th>\n",
       "      <th>target_id</th>\n",
       "      <th>Translation</th>\n",
       "      <th>number_punctuations_total_difference</th>\n",
       "      <th>number_punctuations_total_difference_relative</th>\n",
       "      <th>number_punctuations_total_difference_normalized</th>\n",
       "      <th>number_words_difference</th>\n",
       "      <th>number_words_difference_relative</th>\n",
       "      <th>number_words_difference_normalized</th>\n",
       "      <th>number_unique_words_difference</th>\n",
       "      <th>...</th>\n",
       "      <th>cosine_similarity_average_proc_b_1k</th>\n",
       "      <th>cosine_similarity_tf_idf_proc_b_1k</th>\n",
       "      <th>euclidean_distance_average_proc_b_1k</th>\n",
       "      <th>euclidean_distance_tf_idf_proc_b_1k</th>\n",
       "      <th>jaccard_translation_proc_b_1k</th>\n",
       "      <th>cosine_similarity_average_vecmap</th>\n",
       "      <th>cosine_similarity_tf_idf_vecmap</th>\n",
       "      <th>euclidean_distance_average_vecmap</th>\n",
       "      <th>euclidean_distance_tf_idf_vecmap</th>\n",
       "      <th>jaccard_translation_vecmap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.094256</td>\n",
       "      <td>3</td>\n",
       "      <td>0.016575</td>\n",
       "      <td>0.094256</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>0.938824</td>\n",
       "      <td>0.922837</td>\n",
       "      <td>0.188550</td>\n",
       "      <td>0.025019</td>\n",
       "      <td>0.069408</td>\n",
       "      <td>0.851877</td>\n",
       "      <td>0.816036</td>\n",
       "      <td>0.227537</td>\n",
       "      <td>0.029612</td>\n",
       "      <td>0.074080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.928516</td>\n",
       "      <td>0.911385</td>\n",
       "      <td>0.191291</td>\n",
       "      <td>0.035125</td>\n",
       "      <td>0.246975</td>\n",
       "      <td>0.881250</td>\n",
       "      <td>0.846294</td>\n",
       "      <td>0.197129</td>\n",
       "      <td>0.036056</td>\n",
       "      <td>0.258936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>1</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.841325</td>\n",
       "      <td>0.834805</td>\n",
       "      <td>0.308668</td>\n",
       "      <td>0.072557</td>\n",
       "      <td>0.176154</td>\n",
       "      <td>0.729274</td>\n",
       "      <td>0.726981</td>\n",
       "      <td>0.328892</td>\n",
       "      <td>0.075238</td>\n",
       "      <td>0.224167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004762</td>\n",
       "      <td>2</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.004762</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.881792</td>\n",
       "      <td>0.873648</td>\n",
       "      <td>0.255657</td>\n",
       "      <td>0.051406</td>\n",
       "      <td>0.173542</td>\n",
       "      <td>0.771814</td>\n",
       "      <td>0.758749</td>\n",
       "      <td>0.281536</td>\n",
       "      <td>0.053657</td>\n",
       "      <td>0.173542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005517</td>\n",
       "      <td>4</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.005517</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.916279</td>\n",
       "      <td>0.894702</td>\n",
       "      <td>0.227575</td>\n",
       "      <td>0.047172</td>\n",
       "      <td>0.186111</td>\n",
       "      <td>0.874617</td>\n",
       "      <td>0.839182</td>\n",
       "      <td>0.238205</td>\n",
       "      <td>0.049603</td>\n",
       "      <td>0.205495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219995</th>\n",
       "      <td>19999</td>\n",
       "      <td>4647</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.079032</td>\n",
       "      <td>8</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.079032</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.874105</td>\n",
       "      <td>0.859388</td>\n",
       "      <td>0.280235</td>\n",
       "      <td>0.065319</td>\n",
       "      <td>0.092105</td>\n",
       "      <td>0.783083</td>\n",
       "      <td>0.739614</td>\n",
       "      <td>0.302003</td>\n",
       "      <td>0.072655</td>\n",
       "      <td>0.078947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219996</th>\n",
       "      <td>19999</td>\n",
       "      <td>685</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>8</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.856001</td>\n",
       "      <td>0.852788</td>\n",
       "      <td>0.322840</td>\n",
       "      <td>0.066262</td>\n",
       "      <td>0.068498</td>\n",
       "      <td>0.738716</td>\n",
       "      <td>0.726509</td>\n",
       "      <td>0.375336</td>\n",
       "      <td>0.076159</td>\n",
       "      <td>0.069173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219997</th>\n",
       "      <td>19999</td>\n",
       "      <td>10689</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.036957</td>\n",
       "      <td>2</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.036957</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.886237</td>\n",
       "      <td>0.852108</td>\n",
       "      <td>0.263981</td>\n",
       "      <td>0.067731</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.819358</td>\n",
       "      <td>0.759386</td>\n",
       "      <td>0.275182</td>\n",
       "      <td>0.070944</td>\n",
       "      <td>0.063508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219998</th>\n",
       "      <td>19999</td>\n",
       "      <td>9172</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>9</td>\n",
       "      <td>0.191489</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.871786</td>\n",
       "      <td>0.855601</td>\n",
       "      <td>0.276340</td>\n",
       "      <td>0.065629</td>\n",
       "      <td>0.054054</td>\n",
       "      <td>0.785261</td>\n",
       "      <td>0.750286</td>\n",
       "      <td>0.295176</td>\n",
       "      <td>0.071319</td>\n",
       "      <td>0.054805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219999</th>\n",
       "      <td>19999</td>\n",
       "      <td>7757</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>9</td>\n",
       "      <td>0.191489</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.871778</td>\n",
       "      <td>0.853861</td>\n",
       "      <td>0.275271</td>\n",
       "      <td>0.067035</td>\n",
       "      <td>0.125490</td>\n",
       "      <td>0.791036</td>\n",
       "      <td>0.757378</td>\n",
       "      <td>0.292175</td>\n",
       "      <td>0.070834</td>\n",
       "      <td>0.127273</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>220000 rows × 148 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        source_id  target_id  Translation  \\\n",
       "0               0          0            1   \n",
       "1               1          1            1   \n",
       "2               2          2            1   \n",
       "3               3          3            1   \n",
       "4               4          4            1   \n",
       "...           ...        ...          ...   \n",
       "219995      19999       4647            0   \n",
       "219996      19999        685            0   \n",
       "219997      19999      10689            0   \n",
       "219998      19999       9172            0   \n",
       "219999      19999       7757            0   \n",
       "\n",
       "        number_punctuations_total_difference  \\\n",
       "0                                         10   \n",
       "1                                          0   \n",
       "2                                          3   \n",
       "3                                          0   \n",
       "4                                          0   \n",
       "...                                      ...   \n",
       "219995                                     3   \n",
       "219996                                     2   \n",
       "219997                                     1   \n",
       "219998                                     1   \n",
       "219999                                     1   \n",
       "\n",
       "        number_punctuations_total_difference_relative  \\\n",
       "0                                            0.555556   \n",
       "1                                            0.000000   \n",
       "2                                            1.000000   \n",
       "3                                            0.000000   \n",
       "4                                            0.000000   \n",
       "...                                               ...   \n",
       "219995                                       0.600000   \n",
       "219996                                       0.500000   \n",
       "219997                                       0.333333   \n",
       "219998                                       0.333333   \n",
       "219999                                       0.333333   \n",
       "\n",
       "        number_punctuations_total_difference_normalized  \\\n",
       "0                                              0.094256   \n",
       "1                                              0.000000   \n",
       "2                                              0.142857   \n",
       "3                                              0.004762   \n",
       "4                                              0.005517   \n",
       "...                                                 ...   \n",
       "219995                                         0.079032   \n",
       "219996                                         0.050000   \n",
       "219997                                         0.036957   \n",
       "219998                                         0.016667   \n",
       "219999                                         0.016667   \n",
       "\n",
       "        number_words_difference  number_words_difference_relative  \\\n",
       "0                             3                          0.016575   \n",
       "1                             0                          0.000000   \n",
       "2                             1                          0.027027   \n",
       "3                             2                          0.037037   \n",
       "4                             4                          0.076923   \n",
       "...                         ...                               ...   \n",
       "219995                        8                          0.173913   \n",
       "219996                        8                          0.173913   \n",
       "219997                        2                          0.050000   \n",
       "219998                        9                          0.191489   \n",
       "219999                        9                          0.191489   \n",
       "\n",
       "        number_words_difference_normalized  number_unique_words_difference  \\\n",
       "0                                 0.094256                              12   \n",
       "1                                 0.000000                               5   \n",
       "2                                 0.142857                               1   \n",
       "3                                 0.004762                               5   \n",
       "4                                 0.005517                               2   \n",
       "...                                    ...                             ...   \n",
       "219995                            0.079032                               9   \n",
       "219996                            0.050000                               9   \n",
       "219997                            0.036957                               2   \n",
       "219998                            0.016667                               7   \n",
       "219999                            0.016667                               8   \n",
       "\n",
       "        ...  cosine_similarity_average_proc_b_1k  \\\n",
       "0       ...                             0.938824   \n",
       "1       ...                             0.928516   \n",
       "2       ...                             0.841325   \n",
       "3       ...                             0.881792   \n",
       "4       ...                             0.916279   \n",
       "...     ...                                  ...   \n",
       "219995  ...                             0.874105   \n",
       "219996  ...                             0.856001   \n",
       "219997  ...                             0.886237   \n",
       "219998  ...                             0.871786   \n",
       "219999  ...                             0.871778   \n",
       "\n",
       "        cosine_similarity_tf_idf_proc_b_1k  \\\n",
       "0                                 0.922837   \n",
       "1                                 0.911385   \n",
       "2                                 0.834805   \n",
       "3                                 0.873648   \n",
       "4                                 0.894702   \n",
       "...                                    ...   \n",
       "219995                            0.859388   \n",
       "219996                            0.852788   \n",
       "219997                            0.852108   \n",
       "219998                            0.855601   \n",
       "219999                            0.853861   \n",
       "\n",
       "        euclidean_distance_average_proc_b_1k  \\\n",
       "0                                   0.188550   \n",
       "1                                   0.191291   \n",
       "2                                   0.308668   \n",
       "3                                   0.255657   \n",
       "4                                   0.227575   \n",
       "...                                      ...   \n",
       "219995                              0.280235   \n",
       "219996                              0.322840   \n",
       "219997                              0.263981   \n",
       "219998                              0.276340   \n",
       "219999                              0.275271   \n",
       "\n",
       "        euclidean_distance_tf_idf_proc_b_1k  jaccard_translation_proc_b_1k  \\\n",
       "0                                  0.025019                       0.069408   \n",
       "1                                  0.035125                       0.246975   \n",
       "2                                  0.072557                       0.176154   \n",
       "3                                  0.051406                       0.173542   \n",
       "4                                  0.047172                       0.186111   \n",
       "...                                     ...                            ...   \n",
       "219995                             0.065319                       0.092105   \n",
       "219996                             0.066262                       0.068498   \n",
       "219997                             0.067731                       0.062500   \n",
       "219998                             0.065629                       0.054054   \n",
       "219999                             0.067035                       0.125490   \n",
       "\n",
       "        cosine_similarity_average_vecmap  cosine_similarity_tf_idf_vecmap  \\\n",
       "0                               0.851877                         0.816036   \n",
       "1                               0.881250                         0.846294   \n",
       "2                               0.729274                         0.726981   \n",
       "3                               0.771814                         0.758749   \n",
       "4                               0.874617                         0.839182   \n",
       "...                                  ...                              ...   \n",
       "219995                          0.783083                         0.739614   \n",
       "219996                          0.738716                         0.726509   \n",
       "219997                          0.819358                         0.759386   \n",
       "219998                          0.785261                         0.750286   \n",
       "219999                          0.791036                         0.757378   \n",
       "\n",
       "        euclidean_distance_average_vecmap  euclidean_distance_tf_idf_vecmap  \\\n",
       "0                                0.227537                          0.029612   \n",
       "1                                0.197129                          0.036056   \n",
       "2                                0.328892                          0.075238   \n",
       "3                                0.281536                          0.053657   \n",
       "4                                0.238205                          0.049603   \n",
       "...                                   ...                               ...   \n",
       "219995                           0.302003                          0.072655   \n",
       "219996                           0.375336                          0.076159   \n",
       "219997                           0.275182                          0.070944   \n",
       "219998                           0.295176                          0.071319   \n",
       "219999                           0.292175                          0.070834   \n",
       "\n",
       "        jaccard_translation_vecmap  \n",
       "0                         0.074080  \n",
       "1                         0.258936  \n",
       "2                         0.224167  \n",
       "3                         0.173542  \n",
       "4                         0.205495  \n",
       "...                            ...  \n",
       "219995                    0.078947  \n",
       "219996                    0.069173  \n",
       "219997                    0.063508  \n",
       "219998                    0.054805  \n",
       "219999                    0.127273  \n",
       "\n",
       "[220000 rows x 148 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Delete all columns with only one value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_mask = feature_dataframe.apply(threshold_counts, threshold=1)\n",
    "feature_dataframe = feature_dataframe.loc[:, column_mask]\n",
    "feature_retrieval = feature_retrieval.loc[:, column_mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Supervised Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Start with one feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_features = [\"jaccard_translation_proc_5k\"]\n",
    "not_add = [\"Translation\", \"source_id\", \"target_id\"]\n",
    "added_features = feature_dataframe.columns[~feature_dataframe.columns.isin(start_features+not_add)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------First do Forward Selection-----------------\n",
      "\n",
      "Current Iteration through feature list: 1\n",
      "The initial MAP score on test set: 0.7535\n",
      "Updated MAP score on test set with new feature jaccard_translation_vecmap: 0.7718\n",
      "Updated MAP score on test set with new feature euclidean_distance_tf_idf_vecmap: 0.7857\n",
      "Updated MAP score on test set with new feature euclidean_distance_tf_idf_proc_b_1k: 0.8035\n",
      "Updated MAP score on test set with new feature number_VERB_difference: 0.8425\n",
      "Updated MAP score on test set with new feature number_ADJ_difference: 0.8427\n",
      "Updated MAP score on test set with new feature number_#_difference_normalized: 0.8458\n",
      "\n",
      "Current Iteration through feature list: 2\n",
      "The initial MAP score on test set: 0.8458\n",
      "Updated MAP score on test set with new feature number_ADJ_difference_relative: 0.8476\n",
      "\n",
      "Current Iteration through feature list: 3\n",
      "The initial MAP score on test set: 0.8476\n",
      "\n",
      "-----------------Result of Feature Selection-----------------\n",
      "\n",
      "Best MAP Score after feature selection: 0.8475974148299663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Hyperparameter Tuning:   0%|          | 0/72 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "-----------------Start Hyperparameter-tuning with Grid Search-----------------\n",
      "Number of Parameter Combinations: 72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Hyperparameter Tuning:   1%|▏         | 1/72 [00:20<24:03, 20.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current Best Hyperpamaters: {'hidden_layer_sizes': (100,), 'activation': 'logistic', 'solver': 'sgd', 'alpha': 0.0001, 'learning_rate': 'constant', 'random_state': 42, 'early_stopping': True, 'MAP_score': 0.7833685807702923}\n",
      "With Map Score 0.7834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:   4%|▍         | 3/72 [01:46<40:33, 35.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current Best Hyperpamaters: {'hidden_layer_sizes': (100,), 'activation': 'logistic', 'solver': 'sgd', 'alpha': 0.05, 'learning_rate': 'constant', 'random_state': 42, 'early_stopping': True, 'MAP_score': 0.7833710991012302}\n",
      "With Map Score 0.7834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:   7%|▋         | 5/72 [03:21<45:24, 40.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current Best Hyperpamaters: {'hidden_layer_sizes': (100,), 'activation': 'logistic', 'solver': 'adam', 'alpha': 0.0001, 'learning_rate': 'constant', 'random_state': 42, 'early_stopping': True, 'MAP_score': 0.8168707825996413}\n",
      "With Map Score 0.8169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  18%|█▊        | 13/72 [08:59<48:46, 49.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current Best Hyperpamaters: {'hidden_layer_sizes': (100,), 'activation': 'tanh', 'solver': 'adam', 'alpha': 0.0001, 'learning_rate': 'constant', 'random_state': 42, 'early_stopping': True, 'MAP_score': 0.8243364612412717}\n",
      "With Map Score 0.8243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  51%|█████▏    | 37/72 [47:19<2:09:03, 221.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current Best Hyperpamaters: {'hidden_layer_sizes': (50, 100), 'activation': 'tanh', 'solver': 'adam', 'alpha': 0.0001, 'learning_rate': 'constant', 'random_state': 42, 'early_stopping': True, 'MAP_score': 0.8251010878830725}\n",
      "With Map Score 0.8251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  54%|█████▍    | 39/72 [52:27<1:41:45, 185.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current Best Hyperpamaters: {'hidden_layer_sizes': (50, 100), 'activation': 'tanh', 'solver': 'adam', 'alpha': 0.05, 'learning_rate': 'constant', 'random_state': 42, 'early_stopping': True, 'MAP_score': 0.827774949656375}\n",
      "With Map Score 0.8278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  62%|██████▎   | 45/72 [1:32:00<3:02:39, 405.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current Best Hyperpamaters: {'hidden_layer_sizes': (50, 100), 'activation': 'relu', 'solver': 'adam', 'alpha': 0.0001, 'learning_rate': 'constant', 'random_state': 42, 'early_stopping': True, 'MAP_score': 0.8288211837073144}\n",
      "With Map Score 0.8288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  85%|████████▍ | 61/72 [2:43:14<42:11, 230.12s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current Best Hyperpamaters: {'hidden_layer_sizes': (50, 75, 100), 'activation': 'tanh', 'solver': 'adam', 'alpha': 0.0001, 'learning_rate': 'constant', 'random_state': 42, 'early_stopping': True, 'MAP_score': 0.8357811020975123}\n",
      "With Map Score 0.8358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning: 100%|██████████| 72/72 [3:11:59<00:00, 159.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------Result of Hyperparameter Tuning-----------------\n",
      "\n",
      "Best Hyperamater Settting: {'hidden_layer_sizes': (50, 75, 100), 'activation': 'tanh', 'solver': 'adam', 'alpha': 0.0001, 'learning_rate': 'constant', 'random_state': 42, 'early_stopping': True}\n",
      "With MAP Score: 0.8358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = MLPClassifier(random_state= 0, early_stopping=True,max_iter=100000)\n",
    "scaler = preprocessing.StandardScaler()\n",
    "\n",
    "MLP_parameter_grid = {\n",
    "    'hidden_layer_sizes': [(100,), (50,100,), (50,75,100,)],\n",
    "    'activation': ['logistic','tanh', 'relu'],\n",
    "    'solver': ['sgd', 'adam'],\n",
    "    'alpha': [0.0001, 0.05],\n",
    "    'learning_rate': ['constant','adaptive'],\n",
    "    'random_state' :[0],\n",
    "    'early_stopping':[True]\n",
    "}\n",
    "MLP_best_features, MLP_best_parameter_combination, MLP_best_map_score, MLP_all_parameter_combination = \\\n",
    "pipeline_model_optimization(model, MLP_parameter_grid, scaler, feature_dataframe, \n",
    "                            feature_retrieval, start_features, \n",
    "                            added_features, \n",
    "                            threshold_map_feature_selection=0.0001)\n",
    "# Current Hyperpamaters: {'hidden_layer_sizes': (100,), 'activation': 'relu', 'solver': 'adam', 'alpha': 0.0001, 'learning_rate': 'adaptive', 'random_state': 42, 'early_stopping': True}\n",
    "# MAP score on test set with current hyperpamaters: 0.8667"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------First do Forward Selection-----------------\n",
      "\n",
      "Current Iteration through feature list: 1\n",
      "The initial MAP score on test set: 0.8476\n",
      "\n",
      "-----------------Result of Feature Selection-----------------\n",
      "\n",
      "Best MAP Score after feature selection: 0.8475974148299663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Hyperparameter Tuning:   0%|          | 0/48 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "-----------------Start Hyperparameter-tuning with Grid Search-----------------\n",
      "Number of Parameter Combinations: 48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\nikla\\pycharmprojects\\crosslingual-information-retrieval\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "Hyperparameter Tuning:   2%|▏         | 1/48 [00:28<22:01, 28.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current Best Hyperpamaters: {'hidden_layer_sizes': (5,), 'activation': 'tanh', 'solver': 'lbfgs', 'alpha': 0.0001, 'learning_rate': 'constant', 'random_state': 0, 'early_stopping': True, 'MAP_score': 0.8193988871674549}\n",
      "With Map Score 0.8194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\nikla\\pycharmprojects\\crosslingual-information-retrieval\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "Hyperparameter Tuning:   6%|▋         | 3/48 [01:33<24:18, 32.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current Best Hyperpamaters: {'hidden_layer_sizes': (5,), 'activation': 'tanh', 'solver': 'adam', 'alpha': 0.0001, 'learning_rate': 'constant', 'random_state': 0, 'early_stopping': True, 'MAP_score': 0.8261110022139623}\n",
      "With Map Score 0.8261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  17%|█▋        | 8/48 [03:36<15:26, 23.16s/it]c:\\users\\nikla\\pycharmprojects\\crosslingual-information-retrieval\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "Hyperparameter Tuning:  19%|█▉        | 9/48 [04:18<18:53, 29.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current Best Hyperpamaters: {'hidden_layer_sizes': (5, 3, 2), 'activation': 'tanh', 'solver': 'lbfgs', 'alpha': 0.0001, 'learning_rate': 'constant', 'random_state': 0, 'early_stopping': True, 'MAP_score': 0.8358773709922623}\n",
      "With Map Score 0.8359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\nikla\\pycharmprojects\\crosslingual-information-retrieval\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "Hyperparameter Tuning:  25%|██▌       | 12/48 [07:00<28:05, 46.81s/it]c:\\users\\nikla\\pycharmprojects\\crosslingual-information-retrieval\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "Hyperparameter Tuning:  27%|██▋       | 13/48 [07:36<25:26, 43.62s/it]c:\\users\\nikla\\pycharmprojects\\crosslingual-information-retrieval\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "Hyperparameter Tuning:  33%|███▎      | 16/48 [09:39<22:33, 42.28s/it]c:\\users\\nikla\\pycharmprojects\\crosslingual-information-retrieval\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "Hyperparameter Tuning:  35%|███▌      | 17/48 [10:16<21:03, 40.76s/it]c:\\users\\nikla\\pycharmprojects\\crosslingual-information-retrieval\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "Hyperparameter Tuning:  42%|████▏     | 20/48 [11:52<15:56, 34.14s/it]c:\\users\\nikla\\pycharmprojects\\crosslingual-information-retrieval\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "Hyperparameter Tuning:  44%|████▍     | 21/48 [12:22<14:45, 32.81s/it]c:\\users\\nikla\\pycharmprojects\\crosslingual-information-retrieval\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "Hyperparameter Tuning:  50%|█████     | 24/48 [13:48<11:58, 29.93s/it]c:\\users\\nikla\\pycharmprojects\\crosslingual-information-retrieval\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "Hyperparameter Tuning:  52%|█████▏    | 25/48 [14:24<12:13, 31.91s/it]c:\\users\\nikla\\pycharmprojects\\crosslingual-information-retrieval\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "Hyperparameter Tuning:  67%|██████▋   | 32/48 [18:03<08:13, 30.85s/it]c:\\users\\nikla\\pycharmprojects\\crosslingual-information-retrieval\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "Hyperparameter Tuning:  69%|██████▉   | 33/48 [18:45<08:31, 34.13s/it]c:\\users\\nikla\\pycharmprojects\\crosslingual-information-retrieval\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "Hyperparameter Tuning:  75%|███████▌  | 36/48 [21:00<08:19, 41.63s/it]c:\\users\\nikla\\pycharmprojects\\crosslingual-information-retrieval\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "Hyperparameter Tuning:  77%|███████▋  | 37/48 [21:33<07:06, 38.78s/it]c:\\users\\nikla\\pycharmprojects\\crosslingual-information-retrieval\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "Hyperparameter Tuning:  83%|████████▎ | 40/48 [23:17<04:51, 36.41s/it]c:\\users\\nikla\\pycharmprojects\\crosslingual-information-retrieval\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "Hyperparameter Tuning:  85%|████████▌ | 41/48 [24:11<04:52, 41.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current Best Hyperpamaters: {'hidden_layer_sizes': (8, 3, 2), 'activation': 'tanh', 'solver': 'lbfgs', 'alpha': 0.0001, 'learning_rate': 'constant', 'random_state': 0, 'early_stopping': True, 'MAP_score': 0.8374879871682634}\n",
      "With Map Score 0.8375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\nikla\\pycharmprojects\\crosslingual-information-retrieval\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "Hyperparameter Tuning:  92%|█████████▏| 44/48 [26:57<03:21, 50.30s/it]c:\\users\\nikla\\pycharmprojects\\crosslingual-information-retrieval\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "Hyperparameter Tuning:  94%|█████████▍| 45/48 [27:36<02:21, 47.08s/it]c:\\users\\nikla\\pycharmprojects\\crosslingual-information-retrieval\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "Hyperparameter Tuning: 100%|██████████| 48/48 [30:34<00:00, 38.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------Result of Hyperparameter Tuning-----------------\n",
      "\n",
      "Best Hyperamater Settting: {'hidden_layer_sizes': (8, 3, 2), 'activation': 'tanh', 'solver': 'lbfgs', 'alpha': 0.0001, 'learning_rate': 'constant', 'random_state': 0, 'early_stopping': True}\n",
      "With MAP Score: 0.8375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = MLPClassifier(random_state= 0, early_stopping=True,max_iter=100000)\n",
    "scaler = preprocessing.StandardScaler()\n",
    "\n",
    "MLP_parameter_grid = {\n",
    "    'hidden_layer_sizes': [(5,), (5,3,2), (6,3,),(6,2),(7,3,),(8,3,2)],\n",
    "    'activation': ['tanh', 'relu'],\n",
    "    'solver': ['lbfgs', 'adam'],\n",
    "    'alpha': [0.0001],\n",
    "    'learning_rate': ['constant','adaptive'],\n",
    "    'random_state' :[0],\n",
    "    'early_stopping':[True]\n",
    "}\n",
    "MLP_best_features, MLP_best_parameter_combination, MLP_best_map_score, MLP_all_parameter_combination = \\\n",
    "pipeline_model_optimization(model, MLP_parameter_grid, scaler, feature_dataframe, \n",
    "                            feature_retrieval, start_features, \n",
    "                            added_features, \n",
    "                            threshold_map_feature_selection=0.0001)\n",
    "# Current Hyperpamaters: {'hidden_layer_sizes': (7, 3), 'activation': 'relu', 'solver': 'adam', 'alpha': 0.0001, 'learning_rate': 'adaptive', 'random_state': 42, 'early_stopping': True}\n",
    "# MAP score on test set with current hyperpamaters: 0.8674"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# our model did not improve so we will dicard\n",
    "scaler = preprocessing.StandardScaler()\n",
    "model = MLPClassifier(hidden_layer_sizes=(7,3),random_state=0, alpha=0.0001,   early_stopping=True)\n",
    "feature_selection(model,scaler,feature_dataframe,feature_retrieval,start_features,added_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_features=['jaccard_translation_proc_5k','jaccard_translation_vecmap','euclidean_distance_tf_idf_vecmap','euclidean_distance_tf_idf_proc_b_1k','number_VERB_difference','number_ADJ_difference','number_#_difference_normalized','number_ADJ_difference_relative']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The initial MAP score on test set: 0.8476\n"
     ]
    }
   ],
   "source": [
    "#final model 0.8476\n",
    "scaler = preprocessing.StandardScaler()\n",
    "model = MLPClassifier(hidden_layer_sizes=(100,),random_state=0, alpha=0.0001,  early_stopping=True,max_iter=1000000)\n",
    "target_train = feature_dataframe['Translation']\n",
    "target_test = feature_retrieval['Translation']\n",
    "data_train = feature_dataframe.filter(items=start_features)\n",
    "data_test = feature_retrieval.filter(items=start_features)\n",
    "# scale the features\n",
    "data_train[data_train.columns] = scaler.fit_transform(data_train[data_train.columns])\n",
    "data_test[data_test.columns] = scaler.transform(data_test[data_test.columns])\n",
    "# fit the model and get the initial MapScore\n",
    "model.fit(data_train.to_numpy(), target_train.to_numpy())\n",
    "prediction = model.predict_proba(data_test.to_numpy())\n",
    "MapScore = MAP_score(feature_retrieval['source_id'], target_test, prediction)\n",
    "print(\"The initial MAP score on test set: {:.4f}\".format(MapScore))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# save the model to disk\n",
    "filename = 'finalized_model_MLP.sav'\n",
    "pickle.dump(model, open(filename, 'wb'))\n",
    " \n",
    "\n",
    "# load the model from disk\n",
    "loaded_model = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['jaccard_translation_proc_5k',\n",
       " 'jaccard_translation_vecmap',\n",
       " 'euclidean_distance_tf_idf_vecmap',\n",
       " 'euclidean_distance_tf_idf_proc_b_1k',\n",
       " 'number_VERB_difference',\n",
       " 'number_ADJ_difference',\n",
       " 'number_#_difference_normalized',\n",
       " 'number_ADJ_difference_relative']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#final features of the model\n",
    "len(start_features)\n",
    "start_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III. Other languages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the model on English-Italian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_id</th>\n",
       "      <th>target_id</th>\n",
       "      <th>Translation</th>\n",
       "      <th>number_punctuations_total_difference</th>\n",
       "      <th>number_punctuations_total_difference_relative</th>\n",
       "      <th>number_punctuations_total_difference_normalized</th>\n",
       "      <th>number_words_difference</th>\n",
       "      <th>number_words_difference_relative</th>\n",
       "      <th>number_words_difference_normalized</th>\n",
       "      <th>number_unique_words_difference</th>\n",
       "      <th>...</th>\n",
       "      <th>cosine_similarity_average_proc_b_1k</th>\n",
       "      <th>cosine_similarity_tf_idf_proc_b_1k</th>\n",
       "      <th>euclidean_distance_average_proc_b_1k</th>\n",
       "      <th>euclidean_distance_tf_idf_proc_b_1k</th>\n",
       "      <th>jaccard_translation_proc_b_1k</th>\n",
       "      <th>cosine_similarity_average_vecmap</th>\n",
       "      <th>cosine_similarity_tf_idf_vecmap</th>\n",
       "      <th>euclidean_distance_average_vecmap</th>\n",
       "      <th>euclidean_distance_tf_idf_vecmap</th>\n",
       "      <th>jaccard_translation_vecmap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20000</td>\n",
       "      <td>20000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.046218</td>\n",
       "      <td>2</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.046218</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854424</td>\n",
       "      <td>0.852184</td>\n",
       "      <td>0.294122</td>\n",
       "      <td>0.074822</td>\n",
       "      <td>0.192029</td>\n",
       "      <td>0.824711</td>\n",
       "      <td>0.820362</td>\n",
       "      <td>0.271466</td>\n",
       "      <td>0.068599</td>\n",
       "      <td>0.192029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20000</td>\n",
       "      <td>20001</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.034314</td>\n",
       "      <td>7</td>\n",
       "      <td>0.189189</td>\n",
       "      <td>0.034314</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.821553</td>\n",
       "      <td>0.759180</td>\n",
       "      <td>0.338124</td>\n",
       "      <td>0.084507</td>\n",
       "      <td>0.060662</td>\n",
       "      <td>0.733241</td>\n",
       "      <td>0.616938</td>\n",
       "      <td>0.351165</td>\n",
       "      <td>0.090769</td>\n",
       "      <td>0.060662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20000</td>\n",
       "      <td>20002</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.007353</td>\n",
       "      <td>6</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.007353</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.752849</td>\n",
       "      <td>0.665112</td>\n",
       "      <td>0.386866</td>\n",
       "      <td>0.099398</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.540558</td>\n",
       "      <td>0.339125</td>\n",
       "      <td>0.432807</td>\n",
       "      <td>0.114732</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20000</td>\n",
       "      <td>20003</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.072193</td>\n",
       "      <td>6</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.072193</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.776020</td>\n",
       "      <td>0.708160</td>\n",
       "      <td>0.356853</td>\n",
       "      <td>0.093711</td>\n",
       "      <td>0.032292</td>\n",
       "      <td>0.615510</td>\n",
       "      <td>0.475073</td>\n",
       "      <td>0.384684</td>\n",
       "      <td>0.103048</td>\n",
       "      <td>0.031754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20000</td>\n",
       "      <td>20004</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030691</td>\n",
       "      <td>6</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.030691</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.781948</td>\n",
       "      <td>0.717154</td>\n",
       "      <td>0.360449</td>\n",
       "      <td>0.096081</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.659130</td>\n",
       "      <td>0.557169</td>\n",
       "      <td>0.376907</td>\n",
       "      <td>0.100984</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499995</th>\n",
       "      <td>20099</td>\n",
       "      <td>24995</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>2</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.629671</td>\n",
       "      <td>0.571876</td>\n",
       "      <td>0.485150</td>\n",
       "      <td>0.138779</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.340138</td>\n",
       "      <td>0.254788</td>\n",
       "      <td>0.544548</td>\n",
       "      <td>0.155010</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499996</th>\n",
       "      <td>20099</td>\n",
       "      <td>24996</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>5</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.608893</td>\n",
       "      <td>0.541164</td>\n",
       "      <td>0.521543</td>\n",
       "      <td>0.206140</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.352565</td>\n",
       "      <td>0.252309</td>\n",
       "      <td>0.584824</td>\n",
       "      <td>0.224727</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499997</th>\n",
       "      <td>20099</td>\n",
       "      <td>24997</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>5</td>\n",
       "      <td>0.185185</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.634123</td>\n",
       "      <td>0.549922</td>\n",
       "      <td>0.471551</td>\n",
       "      <td>0.135978</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.317182</td>\n",
       "      <td>0.216514</td>\n",
       "      <td>0.537252</td>\n",
       "      <td>0.150231</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499998</th>\n",
       "      <td>20099</td>\n",
       "      <td>24998</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.168306</td>\n",
       "      <td>44</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.168306</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.700972</td>\n",
       "      <td>0.652883</td>\n",
       "      <td>0.426266</td>\n",
       "      <td>0.122974</td>\n",
       "      <td>0.009434</td>\n",
       "      <td>0.404160</td>\n",
       "      <td>0.338733</td>\n",
       "      <td>0.492635</td>\n",
       "      <td>0.124281</td>\n",
       "      <td>0.009434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499999</th>\n",
       "      <td>20099</td>\n",
       "      <td>24999</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.187719</td>\n",
       "      <td>24</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>0.187719</td>\n",
       "      <td>21</td>\n",
       "      <td>...</td>\n",
       "      <td>0.685971</td>\n",
       "      <td>0.631229</td>\n",
       "      <td>0.440733</td>\n",
       "      <td>0.121077</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.397442</td>\n",
       "      <td>0.325282</td>\n",
       "      <td>0.503212</td>\n",
       "      <td>0.127697</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500000 rows × 148 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        source_id  target_id  Translation  \\\n",
       "0           20000      20000            1   \n",
       "1           20000      20001            0   \n",
       "2           20000      20002            0   \n",
       "3           20000      20003            0   \n",
       "4           20000      20004            0   \n",
       "...           ...        ...          ...   \n",
       "499995      20099      24995            0   \n",
       "499996      20099      24996            0   \n",
       "499997      20099      24997            0   \n",
       "499998      20099      24998            0   \n",
       "499999      20099      24999            0   \n",
       "\n",
       "        number_punctuations_total_difference  \\\n",
       "0                                          1   \n",
       "1                                          0   \n",
       "2                                          1   \n",
       "3                                          1   \n",
       "4                                          0   \n",
       "...                                      ...   \n",
       "499995                                     4   \n",
       "499996                                     4   \n",
       "499997                                     4   \n",
       "499998                                     2   \n",
       "499999                                     1   \n",
       "\n",
       "        number_punctuations_total_difference_relative  \\\n",
       "0                                            0.333333   \n",
       "1                                            0.000000   \n",
       "2                                            0.200000   \n",
       "3                                            0.333333   \n",
       "4                                            0.000000   \n",
       "...                                               ...   \n",
       "499995                                       1.000000   \n",
       "499996                                       1.000000   \n",
       "499997                                       1.000000   \n",
       "499998                                       0.200000   \n",
       "499999                                       0.142857   \n",
       "\n",
       "        number_punctuations_total_difference_normalized  \\\n",
       "0                                              0.046218   \n",
       "1                                              0.034314   \n",
       "2                                              0.007353   \n",
       "3                                              0.072193   \n",
       "4                                              0.030691   \n",
       "...                                                 ...   \n",
       "499995                                         0.266667   \n",
       "499996                                         0.266667   \n",
       "499997                                         0.266667   \n",
       "499998                                         0.168306   \n",
       "499999                                         0.187719   \n",
       "\n",
       "        number_words_difference  number_words_difference_relative  \\\n",
       "0                             2                          0.071429   \n",
       "1                             7                          0.189189   \n",
       "2                             6                          0.166667   \n",
       "3                             6                          0.166667   \n",
       "4                             6                          0.166667   \n",
       "...                         ...                               ...   \n",
       "499995                        2                          0.083333   \n",
       "499996                        5                          0.294118   \n",
       "499997                        5                          0.185185   \n",
       "499998                       44                          0.666667   \n",
       "499999                       24                          0.521739   \n",
       "\n",
       "        number_words_difference_normalized  number_unique_words_difference  \\\n",
       "0                                 0.046218                               3   \n",
       "1                                 0.034314                               7   \n",
       "2                                 0.007353                               6   \n",
       "3                                 0.072193                               2   \n",
       "4                                 0.030691                               0   \n",
       "...                                    ...                             ...   \n",
       "499995                            0.266667                               3   \n",
       "499996                            0.266667                               4   \n",
       "499997                            0.266667                               6   \n",
       "499998                            0.168306                              30   \n",
       "499999                            0.187719                              21   \n",
       "\n",
       "        ...  cosine_similarity_average_proc_b_1k  \\\n",
       "0       ...                             0.854424   \n",
       "1       ...                             0.821553   \n",
       "2       ...                             0.752849   \n",
       "3       ...                             0.776020   \n",
       "4       ...                             0.781948   \n",
       "...     ...                                  ...   \n",
       "499995  ...                             0.629671   \n",
       "499996  ...                             0.608893   \n",
       "499997  ...                             0.634123   \n",
       "499998  ...                             0.700972   \n",
       "499999  ...                             0.685971   \n",
       "\n",
       "        cosine_similarity_tf_idf_proc_b_1k  \\\n",
       "0                                 0.852184   \n",
       "1                                 0.759180   \n",
       "2                                 0.665112   \n",
       "3                                 0.708160   \n",
       "4                                 0.717154   \n",
       "...                                    ...   \n",
       "499995                            0.571876   \n",
       "499996                            0.541164   \n",
       "499997                            0.549922   \n",
       "499998                            0.652883   \n",
       "499999                            0.631229   \n",
       "\n",
       "        euclidean_distance_average_proc_b_1k  \\\n",
       "0                                   0.294122   \n",
       "1                                   0.338124   \n",
       "2                                   0.386866   \n",
       "3                                   0.356853   \n",
       "4                                   0.360449   \n",
       "...                                      ...   \n",
       "499995                              0.485150   \n",
       "499996                              0.521543   \n",
       "499997                              0.471551   \n",
       "499998                              0.426266   \n",
       "499999                              0.440733   \n",
       "\n",
       "        euclidean_distance_tf_idf_proc_b_1k  jaccard_translation_proc_b_1k  \\\n",
       "0                                  0.074822                       0.192029   \n",
       "1                                  0.084507                       0.060662   \n",
       "2                                  0.099398                       0.000000   \n",
       "3                                  0.093711                       0.032292   \n",
       "4                                  0.096081                       0.000000   \n",
       "...                                     ...                            ...   \n",
       "499995                             0.138779                       0.000000   \n",
       "499996                             0.206140                       0.000000   \n",
       "499997                             0.135978                       0.000000   \n",
       "499998                             0.122974                       0.009434   \n",
       "499999                             0.121077                       0.000000   \n",
       "\n",
       "        cosine_similarity_average_vecmap  cosine_similarity_tf_idf_vecmap  \\\n",
       "0                               0.824711                         0.820362   \n",
       "1                               0.733241                         0.616938   \n",
       "2                               0.540558                         0.339125   \n",
       "3                               0.615510                         0.475073   \n",
       "4                               0.659130                         0.557169   \n",
       "...                                  ...                              ...   \n",
       "499995                          0.340138                         0.254788   \n",
       "499996                          0.352565                         0.252309   \n",
       "499997                          0.317182                         0.216514   \n",
       "499998                          0.404160                         0.338733   \n",
       "499999                          0.397442                         0.325282   \n",
       "\n",
       "        euclidean_distance_average_vecmap  euclidean_distance_tf_idf_vecmap  \\\n",
       "0                                0.271466                          0.068599   \n",
       "1                                0.351165                          0.090769   \n",
       "2                                0.432807                          0.114732   \n",
       "3                                0.384684                          0.103048   \n",
       "4                                0.376907                          0.100984   \n",
       "...                                   ...                               ...   \n",
       "499995                           0.544548                          0.155010   \n",
       "499996                           0.584824                          0.224727   \n",
       "499997                           0.537252                          0.150231   \n",
       "499998                           0.492635                          0.124281   \n",
       "499999                           0.503212                          0.127697   \n",
       "\n",
       "        jaccard_translation_vecmap  \n",
       "0                         0.192029  \n",
       "1                         0.060662  \n",
       "2                         0.000000  \n",
       "3                         0.031754  \n",
       "4                         0.000000  \n",
       "...                            ...  \n",
       "499995                    0.000000  \n",
       "499996                    0.000000  \n",
       "499997                    0.000000  \n",
       "499998                    0.009434  \n",
       "499999                    0.000000  \n",
       "\n",
       "[500000 rows x 148 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_retrieval_it=pd.read_feather(\"../data/processed/feature_retrieval_en_it.feather\")\n",
    "feature_retrieval_it =feature_retrieval_it.rename(columns={\"id_source\": \"source_id\", \"id_target\": \"target_id\"})\n",
    "feature_retrieval_it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>jaccard_translation_proc_5k</th>\n",
       "      <th>jaccard_translation_vecmap</th>\n",
       "      <th>euclidean_distance_tf_idf_vecmap</th>\n",
       "      <th>euclidean_distance_tf_idf_proc_b_1k</th>\n",
       "      <th>number_VERB_difference</th>\n",
       "      <th>number_ADJ_difference</th>\n",
       "      <th>number_#_difference_normalized</th>\n",
       "      <th>number_ADJ_difference_relative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.219697</td>\n",
       "      <td>0.192029</td>\n",
       "      <td>0.068599</td>\n",
       "      <td>0.074822</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.060662</td>\n",
       "      <td>0.060662</td>\n",
       "      <td>0.090769</td>\n",
       "      <td>0.084507</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.114732</td>\n",
       "      <td>0.099398</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.032292</td>\n",
       "      <td>0.031754</td>\n",
       "      <td>0.103048</td>\n",
       "      <td>0.093711</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100984</td>\n",
       "      <td>0.096081</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499995</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.155010</td>\n",
       "      <td>0.138779</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499996</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.224727</td>\n",
       "      <td>0.206140</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499997</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.150231</td>\n",
       "      <td>0.135978</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499998</th>\n",
       "      <td>0.009434</td>\n",
       "      <td>0.009434</td>\n",
       "      <td>0.124281</td>\n",
       "      <td>0.122974</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499999</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.127697</td>\n",
       "      <td>0.121077</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        jaccard_translation_proc_5k  jaccard_translation_vecmap  \\\n",
       "0                          0.219697                    0.192029   \n",
       "1                          0.060662                    0.060662   \n",
       "2                          0.000000                    0.000000   \n",
       "3                          0.032292                    0.031754   \n",
       "4                          0.000000                    0.000000   \n",
       "...                             ...                         ...   \n",
       "499995                     0.000000                    0.000000   \n",
       "499996                     0.000000                    0.000000   \n",
       "499997                     0.000000                    0.000000   \n",
       "499998                     0.009434                    0.009434   \n",
       "499999                     0.000000                    0.000000   \n",
       "\n",
       "        euclidean_distance_tf_idf_vecmap  euclidean_distance_tf_idf_proc_b_1k  \\\n",
       "0                               0.068599                             0.074822   \n",
       "1                               0.090769                             0.084507   \n",
       "2                               0.114732                             0.099398   \n",
       "3                               0.103048                             0.093711   \n",
       "4                               0.100984                             0.096081   \n",
       "...                                  ...                                  ...   \n",
       "499995                          0.155010                             0.138779   \n",
       "499996                          0.224727                             0.206140   \n",
       "499997                          0.150231                             0.135978   \n",
       "499998                          0.124281                             0.122974   \n",
       "499999                          0.127697                             0.121077   \n",
       "\n",
       "        number_VERB_difference  number_ADJ_difference  \\\n",
       "0                            0                      0   \n",
       "1                            1                      1   \n",
       "2                            2                      1   \n",
       "3                            0                      0   \n",
       "4                            3                      2   \n",
       "...                        ...                    ...   \n",
       "499995                       1                      1   \n",
       "499996                       1                      1   \n",
       "499997                       1                      1   \n",
       "499998                       4                      6   \n",
       "499999                       2                      4   \n",
       "\n",
       "        number_#_difference_normalized  number_ADJ_difference_relative  \n",
       "0                                  0.0                        0.000000  \n",
       "1                                  0.0                        0.333333  \n",
       "2                                  0.0                        0.333333  \n",
       "3                                  0.0                        0.000000  \n",
       "4                                  0.0                        0.500000  \n",
       "...                                ...                             ...  \n",
       "499995                             0.0                        1.000000  \n",
       "499996                             0.0                        1.000000  \n",
       "499997                             0.0                        1.000000  \n",
       "499998                             0.0                        1.000000  \n",
       "499999                             0.0                        1.000000  \n",
       "\n",
       "[500000 rows x 8 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_test = feature_retrieval_it['Translation']\n",
    "data_test = feature_retrieval_it.filter(items=start_features)\n",
    "data_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>jaccard_translation_proc_5k</th>\n",
       "      <th>jaccard_translation_vecmap</th>\n",
       "      <th>euclidean_distance_tf_idf_vecmap</th>\n",
       "      <th>euclidean_distance_tf_idf_proc_b_1k</th>\n",
       "      <th>number_VERB_difference</th>\n",
       "      <th>number_ADJ_difference</th>\n",
       "      <th>number_#_difference_normalized</th>\n",
       "      <th>number_ADJ_difference_relative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.697973</td>\n",
       "      <td>2.136147</td>\n",
       "      <td>-0.224990</td>\n",
       "      <td>-0.082522</td>\n",
       "      <td>-1.145620</td>\n",
       "      <td>-1.074044</td>\n",
       "      <td>-0.007071</td>\n",
       "      <td>-1.253327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.141238</td>\n",
       "      <td>-0.206646</td>\n",
       "      <td>0.090893</td>\n",
       "      <td>0.056906</td>\n",
       "      <td>-0.592309</td>\n",
       "      <td>-0.513583</td>\n",
       "      <td>-0.007071</td>\n",
       "      <td>-0.345023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.224216</td>\n",
       "      <td>-1.288483</td>\n",
       "      <td>0.432320</td>\n",
       "      <td>0.271281</td>\n",
       "      <td>-0.038998</td>\n",
       "      <td>-0.513583</td>\n",
       "      <td>-0.007071</td>\n",
       "      <td>-0.345023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.647722</td>\n",
       "      <td>-0.722184</td>\n",
       "      <td>0.265843</td>\n",
       "      <td>0.189407</td>\n",
       "      <td>-1.145620</td>\n",
       "      <td>-1.074044</td>\n",
       "      <td>-0.007071</td>\n",
       "      <td>-1.253327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.224216</td>\n",
       "      <td>-1.288483</td>\n",
       "      <td>0.236446</td>\n",
       "      <td>0.223524</td>\n",
       "      <td>0.514313</td>\n",
       "      <td>0.046877</td>\n",
       "      <td>-0.007071</td>\n",
       "      <td>0.109130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499995</th>\n",
       "      <td>-1.224216</td>\n",
       "      <td>-1.288483</td>\n",
       "      <td>1.006231</td>\n",
       "      <td>0.838213</td>\n",
       "      <td>-0.592309</td>\n",
       "      <td>-0.513583</td>\n",
       "      <td>-0.007071</td>\n",
       "      <td>1.471587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499996</th>\n",
       "      <td>-1.224216</td>\n",
       "      <td>-1.288483</td>\n",
       "      <td>1.999589</td>\n",
       "      <td>1.807956</td>\n",
       "      <td>-0.592309</td>\n",
       "      <td>-0.513583</td>\n",
       "      <td>-0.007071</td>\n",
       "      <td>1.471587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499997</th>\n",
       "      <td>-1.224216</td>\n",
       "      <td>-1.288483</td>\n",
       "      <td>0.938138</td>\n",
       "      <td>0.797892</td>\n",
       "      <td>-0.592309</td>\n",
       "      <td>-0.513583</td>\n",
       "      <td>-0.007071</td>\n",
       "      <td>1.471587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499998</th>\n",
       "      <td>-1.055794</td>\n",
       "      <td>-1.120238</td>\n",
       "      <td>0.568392</td>\n",
       "      <td>0.610689</td>\n",
       "      <td>1.067623</td>\n",
       "      <td>2.288720</td>\n",
       "      <td>-0.007071</td>\n",
       "      <td>1.471587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499999</th>\n",
       "      <td>-1.224216</td>\n",
       "      <td>-1.288483</td>\n",
       "      <td>0.617055</td>\n",
       "      <td>0.583371</td>\n",
       "      <td>-0.038998</td>\n",
       "      <td>1.167799</td>\n",
       "      <td>-0.007071</td>\n",
       "      <td>1.471587</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        jaccard_translation_proc_5k  jaccard_translation_vecmap  \\\n",
       "0                          2.697973                    2.136147   \n",
       "1                         -0.141238                   -0.206646   \n",
       "2                         -1.224216                   -1.288483   \n",
       "3                         -0.647722                   -0.722184   \n",
       "4                         -1.224216                   -1.288483   \n",
       "...                             ...                         ...   \n",
       "499995                    -1.224216                   -1.288483   \n",
       "499996                    -1.224216                   -1.288483   \n",
       "499997                    -1.224216                   -1.288483   \n",
       "499998                    -1.055794                   -1.120238   \n",
       "499999                    -1.224216                   -1.288483   \n",
       "\n",
       "        euclidean_distance_tf_idf_vecmap  euclidean_distance_tf_idf_proc_b_1k  \\\n",
       "0                              -0.224990                            -0.082522   \n",
       "1                               0.090893                             0.056906   \n",
       "2                               0.432320                             0.271281   \n",
       "3                               0.265843                             0.189407   \n",
       "4                               0.236446                             0.223524   \n",
       "...                                  ...                                  ...   \n",
       "499995                          1.006231                             0.838213   \n",
       "499996                          1.999589                             1.807956   \n",
       "499997                          0.938138                             0.797892   \n",
       "499998                          0.568392                             0.610689   \n",
       "499999                          0.617055                             0.583371   \n",
       "\n",
       "        number_VERB_difference  number_ADJ_difference  \\\n",
       "0                    -1.145620              -1.074044   \n",
       "1                    -0.592309              -0.513583   \n",
       "2                    -0.038998              -0.513583   \n",
       "3                    -1.145620              -1.074044   \n",
       "4                     0.514313               0.046877   \n",
       "...                        ...                    ...   \n",
       "499995               -0.592309              -0.513583   \n",
       "499996               -0.592309              -0.513583   \n",
       "499997               -0.592309              -0.513583   \n",
       "499998                1.067623               2.288720   \n",
       "499999               -0.038998               1.167799   \n",
       "\n",
       "        number_#_difference_normalized  number_ADJ_difference_relative  \n",
       "0                            -0.007071                       -1.253327  \n",
       "1                            -0.007071                       -0.345023  \n",
       "2                            -0.007071                       -0.345023  \n",
       "3                            -0.007071                       -1.253327  \n",
       "4                            -0.007071                        0.109130  \n",
       "...                                ...                             ...  \n",
       "499995                       -0.007071                        1.471587  \n",
       "499996                       -0.007071                        1.471587  \n",
       "499997                       -0.007071                        1.471587  \n",
       "499998                       -0.007071                        1.471587  \n",
       "499999                       -0.007071                        1.471587  \n",
       "\n",
       "[500000 rows x 8 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test[data_test.columns] = scaler.transform(data_test[data_test.columns])\n",
    "data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Italian MAP score on test set: 0.8167\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict_proba(data_test)\n",
    "MapScore = MAP_score(feature_retrieval_it['source_id'], target_test, prediction)\n",
    "print(\"The Italian MAP score on test set: {:.4f}\".format(MapScore))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the model on English-Polish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_id</th>\n",
       "      <th>target_id</th>\n",
       "      <th>Translation</th>\n",
       "      <th>number_punctuations_total_difference</th>\n",
       "      <th>number_punctuations_total_difference_relative</th>\n",
       "      <th>number_punctuations_total_difference_normalized</th>\n",
       "      <th>number_words_difference</th>\n",
       "      <th>number_words_difference_relative</th>\n",
       "      <th>number_words_difference_normalized</th>\n",
       "      <th>number_unique_words_difference</th>\n",
       "      <th>...</th>\n",
       "      <th>cosine_similarity_average_proc_b_1k</th>\n",
       "      <th>cosine_similarity_tf_idf_proc_b_1k</th>\n",
       "      <th>euclidean_distance_average_proc_b_1k</th>\n",
       "      <th>euclidean_distance_tf_idf_proc_b_1k</th>\n",
       "      <th>jaccard_translation_proc_b_1k</th>\n",
       "      <th>cosine_similarity_average_vecmap</th>\n",
       "      <th>cosine_similarity_tf_idf_vecmap</th>\n",
       "      <th>euclidean_distance_average_vecmap</th>\n",
       "      <th>euclidean_distance_tf_idf_vecmap</th>\n",
       "      <th>jaccard_translation_vecmap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20000</td>\n",
       "      <td>20000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.217391</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.834714</td>\n",
       "      <td>0.787117</td>\n",
       "      <td>0.343884</td>\n",
       "      <td>0.096155</td>\n",
       "      <td>0.244485</td>\n",
       "      <td>0.802804</td>\n",
       "      <td>0.713881</td>\n",
       "      <td>0.337174</td>\n",
       "      <td>0.100275</td>\n",
       "      <td>0.242647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20000</td>\n",
       "      <td>20001</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.736686</td>\n",
       "      <td>0.695557</td>\n",
       "      <td>0.449273</td>\n",
       "      <td>0.171380</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.670068</td>\n",
       "      <td>0.575405</td>\n",
       "      <td>0.452836</td>\n",
       "      <td>0.173662</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20000</td>\n",
       "      <td>20002</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.123596</td>\n",
       "      <td>64</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.123596</td>\n",
       "      <td>53</td>\n",
       "      <td>...</td>\n",
       "      <td>0.859428</td>\n",
       "      <td>0.801389</td>\n",
       "      <td>0.306350</td>\n",
       "      <td>0.114496</td>\n",
       "      <td>0.050166</td>\n",
       "      <td>0.831464</td>\n",
       "      <td>0.732550</td>\n",
       "      <td>0.313809</td>\n",
       "      <td>0.113891</td>\n",
       "      <td>0.049837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20000</td>\n",
       "      <td>20003</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>7</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.703519</td>\n",
       "      <td>0.662172</td>\n",
       "      <td>0.456495</td>\n",
       "      <td>0.162102</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.585979</td>\n",
       "      <td>0.515644</td>\n",
       "      <td>0.483511</td>\n",
       "      <td>0.166323</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20000</td>\n",
       "      <td>20004</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>12</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>0.765796</td>\n",
       "      <td>0.681011</td>\n",
       "      <td>0.385775</td>\n",
       "      <td>0.112808</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.627124</td>\n",
       "      <td>0.444584</td>\n",
       "      <td>0.426907</td>\n",
       "      <td>0.126310</td>\n",
       "      <td>0.030303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499995</th>\n",
       "      <td>20099</td>\n",
       "      <td>24995</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>7</td>\n",
       "      <td>0.137255</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.791923</td>\n",
       "      <td>0.728771</td>\n",
       "      <td>0.331753</td>\n",
       "      <td>0.075849</td>\n",
       "      <td>0.026671</td>\n",
       "      <td>0.536269</td>\n",
       "      <td>0.325363</td>\n",
       "      <td>0.381850</td>\n",
       "      <td>0.088468</td>\n",
       "      <td>0.025978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499996</th>\n",
       "      <td>20099</td>\n",
       "      <td>24996</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>15</td>\n",
       "      <td>0.348837</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.779662</td>\n",
       "      <td>0.718409</td>\n",
       "      <td>0.357416</td>\n",
       "      <td>0.084390</td>\n",
       "      <td>0.047379</td>\n",
       "      <td>0.694737</td>\n",
       "      <td>0.528046</td>\n",
       "      <td>0.351784</td>\n",
       "      <td>0.088915</td>\n",
       "      <td>0.030835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499997</th>\n",
       "      <td>20099</td>\n",
       "      <td>24997</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>10</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.773840</td>\n",
       "      <td>0.736827</td>\n",
       "      <td>0.350169</td>\n",
       "      <td>0.074033</td>\n",
       "      <td>0.013514</td>\n",
       "      <td>0.465373</td>\n",
       "      <td>0.364922</td>\n",
       "      <td>0.427608</td>\n",
       "      <td>0.090424</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499998</th>\n",
       "      <td>20099</td>\n",
       "      <td>24998</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>9</td>\n",
       "      <td>0.183673</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.731214</td>\n",
       "      <td>0.671121</td>\n",
       "      <td>0.383888</td>\n",
       "      <td>0.084993</td>\n",
       "      <td>0.069884</td>\n",
       "      <td>0.440550</td>\n",
       "      <td>0.286580</td>\n",
       "      <td>0.444644</td>\n",
       "      <td>0.100719</td>\n",
       "      <td>0.054094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499999</th>\n",
       "      <td>20099</td>\n",
       "      <td>24999</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9</td>\n",
       "      <td>0.183673</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.773172</td>\n",
       "      <td>0.704177</td>\n",
       "      <td>0.347123</td>\n",
       "      <td>0.079189</td>\n",
       "      <td>0.026671</td>\n",
       "      <td>0.517924</td>\n",
       "      <td>0.349405</td>\n",
       "      <td>0.390221</td>\n",
       "      <td>0.088363</td>\n",
       "      <td>0.026334</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500000 rows × 148 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        source_id  target_id  Translation  \\\n",
       "0           20000      20000            1   \n",
       "1           20000      20001            0   \n",
       "2           20000      20002            0   \n",
       "3           20000      20003            0   \n",
       "4           20000      20004            0   \n",
       "...           ...        ...          ...   \n",
       "499995      20099      24995            0   \n",
       "499996      20099      24996            0   \n",
       "499997      20099      24997            0   \n",
       "499998      20099      24998            0   \n",
       "499999      20099      24999            0   \n",
       "\n",
       "        number_punctuations_total_difference  \\\n",
       "0                                          0   \n",
       "1                                          0   \n",
       "2                                         11   \n",
       "3                                          2   \n",
       "4                                          2   \n",
       "...                                      ...   \n",
       "499995                                     4   \n",
       "499996                                     2   \n",
       "499997                                     1   \n",
       "499998                                     1   \n",
       "499999                                     0   \n",
       "\n",
       "        number_punctuations_total_difference_relative  \\\n",
       "0                                                 0.0   \n",
       "1                                                 0.0   \n",
       "2                                                 1.0   \n",
       "3                                                 1.0   \n",
       "4                                                 1.0   \n",
       "...                                               ...   \n",
       "499995                                            1.0   \n",
       "499996                                            1.0   \n",
       "499997                                            1.0   \n",
       "499998                                            1.0   \n",
       "499999                                            0.0   \n",
       "\n",
       "        number_punctuations_total_difference_normalized  \\\n",
       "0                                              0.000000   \n",
       "1                                              0.000000   \n",
       "2                                              0.123596   \n",
       "3                                              0.222222   \n",
       "4                                              0.071429   \n",
       "...                                                 ...   \n",
       "499995                                         0.153846   \n",
       "499996                                         0.125000   \n",
       "499997                                         0.050000   \n",
       "499998                                         0.047619   \n",
       "499999                                         0.000000   \n",
       "\n",
       "        number_words_difference  number_words_difference_relative  \\\n",
       "0                             5                          0.217391   \n",
       "1                             7                          0.333333   \n",
       "2                            64                          0.695652   \n",
       "3                             7                          0.333333   \n",
       "4                            12                          0.300000   \n",
       "...                         ...                               ...   \n",
       "499995                        7                          0.137255   \n",
       "499996                       15                          0.348837   \n",
       "499997                       10                          0.208333   \n",
       "499998                        9                          0.183673   \n",
       "499999                        9                          0.183673   \n",
       "\n",
       "        number_words_difference_normalized  number_unique_words_difference  \\\n",
       "0                                 0.000000                               3   \n",
       "1                                 0.000000                               5   \n",
       "2                                 0.123596                              53   \n",
       "3                                 0.222222                               5   \n",
       "4                                 0.071429                              12   \n",
       "...                                    ...                             ...   \n",
       "499995                            0.153846                               1   \n",
       "499996                            0.125000                               7   \n",
       "499997                            0.050000                               2   \n",
       "499998                            0.047619                               2   \n",
       "499999                            0.000000                               1   \n",
       "\n",
       "        ...  cosine_similarity_average_proc_b_1k  \\\n",
       "0       ...                             0.834714   \n",
       "1       ...                             0.736686   \n",
       "2       ...                             0.859428   \n",
       "3       ...                             0.703519   \n",
       "4       ...                             0.765796   \n",
       "...     ...                                  ...   \n",
       "499995  ...                             0.791923   \n",
       "499996  ...                             0.779662   \n",
       "499997  ...                             0.773840   \n",
       "499998  ...                             0.731214   \n",
       "499999  ...                             0.773172   \n",
       "\n",
       "        cosine_similarity_tf_idf_proc_b_1k  \\\n",
       "0                                 0.787117   \n",
       "1                                 0.695557   \n",
       "2                                 0.801389   \n",
       "3                                 0.662172   \n",
       "4                                 0.681011   \n",
       "...                                    ...   \n",
       "499995                            0.728771   \n",
       "499996                            0.718409   \n",
       "499997                            0.736827   \n",
       "499998                            0.671121   \n",
       "499999                            0.704177   \n",
       "\n",
       "        euclidean_distance_average_proc_b_1k  \\\n",
       "0                                   0.343884   \n",
       "1                                   0.449273   \n",
       "2                                   0.306350   \n",
       "3                                   0.456495   \n",
       "4                                   0.385775   \n",
       "...                                      ...   \n",
       "499995                              0.331753   \n",
       "499996                              0.357416   \n",
       "499997                              0.350169   \n",
       "499998                              0.383888   \n",
       "499999                              0.347123   \n",
       "\n",
       "        euclidean_distance_tf_idf_proc_b_1k  jaccard_translation_proc_b_1k  \\\n",
       "0                                  0.096155                       0.244485   \n",
       "1                                  0.171380                       0.000000   \n",
       "2                                  0.114496                       0.050166   \n",
       "3                                  0.162102                       0.000000   \n",
       "4                                  0.112808                       0.030303   \n",
       "...                                     ...                            ...   \n",
       "499995                             0.075849                       0.026671   \n",
       "499996                             0.084390                       0.047379   \n",
       "499997                             0.074033                       0.013514   \n",
       "499998                             0.084993                       0.069884   \n",
       "499999                             0.079189                       0.026671   \n",
       "\n",
       "        cosine_similarity_average_vecmap  cosine_similarity_tf_idf_vecmap  \\\n",
       "0                               0.802804                         0.713881   \n",
       "1                               0.670068                         0.575405   \n",
       "2                               0.831464                         0.732550   \n",
       "3                               0.585979                         0.515644   \n",
       "4                               0.627124                         0.444584   \n",
       "...                                  ...                              ...   \n",
       "499995                          0.536269                         0.325363   \n",
       "499996                          0.694737                         0.528046   \n",
       "499997                          0.465373                         0.364922   \n",
       "499998                          0.440550                         0.286580   \n",
       "499999                          0.517924                         0.349405   \n",
       "\n",
       "        euclidean_distance_average_vecmap  euclidean_distance_tf_idf_vecmap  \\\n",
       "0                                0.337174                          0.100275   \n",
       "1                                0.452836                          0.173662   \n",
       "2                                0.313809                          0.113891   \n",
       "3                                0.483511                          0.166323   \n",
       "4                                0.426907                          0.126310   \n",
       "...                                   ...                               ...   \n",
       "499995                           0.381850                          0.088468   \n",
       "499996                           0.351784                          0.088915   \n",
       "499997                           0.427608                          0.090424   \n",
       "499998                           0.444644                          0.100719   \n",
       "499999                           0.390221                          0.088363   \n",
       "\n",
       "        jaccard_translation_vecmap  \n",
       "0                         0.242647  \n",
       "1                         0.000000  \n",
       "2                         0.049837  \n",
       "3                         0.000000  \n",
       "4                         0.030303  \n",
       "...                            ...  \n",
       "499995                    0.025978  \n",
       "499996                    0.030835  \n",
       "499997                    0.000000  \n",
       "499998                    0.054094  \n",
       "499999                    0.026334  \n",
       "\n",
       "[500000 rows x 148 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_retrieval_pl=pd.read_feather(\"../data/processed/feature_retrieval_en_pl.feather\")\n",
    "feature_retrieval_pl = feature_retrieval_pl.rename(columns={\"id_source\": \"source_id\", \"id_target\": \"target_id\"})\n",
    "feature_retrieval_pl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>jaccard_translation_proc_5k</th>\n",
       "      <th>jaccard_translation_vecmap</th>\n",
       "      <th>euclidean_distance_tf_idf_vecmap</th>\n",
       "      <th>euclidean_distance_tf_idf_proc_b_1k</th>\n",
       "      <th>number_VERB_difference</th>\n",
       "      <th>number_ADJ_difference</th>\n",
       "      <th>number_#_difference_normalized</th>\n",
       "      <th>number_ADJ_difference_relative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.242647</td>\n",
       "      <td>0.242647</td>\n",
       "      <td>0.100275</td>\n",
       "      <td>0.096155</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.027778</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.173662</td>\n",
       "      <td>0.171380</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.043275</td>\n",
       "      <td>0.049837</td>\n",
       "      <td>0.113891</td>\n",
       "      <td>0.114496</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166323</td>\n",
       "      <td>0.162102</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.126310</td>\n",
       "      <td>0.112808</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499995</th>\n",
       "      <td>0.040936</td>\n",
       "      <td>0.025978</td>\n",
       "      <td>0.088468</td>\n",
       "      <td>0.075849</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499996</th>\n",
       "      <td>0.031281</td>\n",
       "      <td>0.030835</td>\n",
       "      <td>0.088915</td>\n",
       "      <td>0.084390</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499997</th>\n",
       "      <td>0.013514</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.090424</td>\n",
       "      <td>0.074033</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499998</th>\n",
       "      <td>0.069884</td>\n",
       "      <td>0.054094</td>\n",
       "      <td>0.100719</td>\n",
       "      <td>0.084993</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499999</th>\n",
       "      <td>0.026671</td>\n",
       "      <td>0.026334</td>\n",
       "      <td>0.088363</td>\n",
       "      <td>0.079189</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        jaccard_translation_proc_5k  jaccard_translation_vecmap  \\\n",
       "0                          0.242647                    0.242647   \n",
       "1                          0.027778                    0.000000   \n",
       "2                          0.043275                    0.049837   \n",
       "3                          0.000000                    0.000000   \n",
       "4                          0.030303                    0.030303   \n",
       "...                             ...                         ...   \n",
       "499995                     0.040936                    0.025978   \n",
       "499996                     0.031281                    0.030835   \n",
       "499997                     0.013514                    0.000000   \n",
       "499998                     0.069884                    0.054094   \n",
       "499999                     0.026671                    0.026334   \n",
       "\n",
       "        euclidean_distance_tf_idf_vecmap  euclidean_distance_tf_idf_proc_b_1k  \\\n",
       "0                               0.100275                             0.096155   \n",
       "1                               0.173662                             0.171380   \n",
       "2                               0.113891                             0.114496   \n",
       "3                               0.166323                             0.162102   \n",
       "4                               0.126310                             0.112808   \n",
       "...                                  ...                                  ...   \n",
       "499995                          0.088468                             0.075849   \n",
       "499996                          0.088915                             0.084390   \n",
       "499997                          0.090424                             0.074033   \n",
       "499998                          0.100719                             0.084993   \n",
       "499999                          0.088363                             0.079189   \n",
       "\n",
       "        number_VERB_difference  number_ADJ_difference  \\\n",
       "0                            1                      1   \n",
       "1                            0                      2   \n",
       "2                            4                     12   \n",
       "3                            0                      1   \n",
       "4                            1                      1   \n",
       "...                        ...                    ...   \n",
       "499995                       0                      1   \n",
       "499996                       2                      1   \n",
       "499997                       3                      1   \n",
       "499998                       2                      1   \n",
       "499999                       1                      1   \n",
       "\n",
       "        number_#_difference_normalized  number_ADJ_difference_relative  \n",
       "0                                  0.0                        0.333333  \n",
       "1                                  0.0                        1.000000  \n",
       "2                                  0.0                        0.750000  \n",
       "3                                  0.0                        0.333333  \n",
       "4                                  0.0                        0.200000  \n",
       "...                                ...                             ...  \n",
       "499995                             0.0                        0.333333  \n",
       "499996                             0.0                        0.200000  \n",
       "499997                             0.0                        0.200000  \n",
       "499998                             0.0                        0.200000  \n",
       "499999                             0.0                        0.200000  \n",
       "\n",
       "[500000 rows x 8 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_test = feature_retrieval_pl['Translation']\n",
    "data_test = feature_retrieval_pl.filter(items=start_features)\n",
    "data_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>jaccard_translation_proc_5k</th>\n",
       "      <th>jaccard_translation_vecmap</th>\n",
       "      <th>euclidean_distance_tf_idf_vecmap</th>\n",
       "      <th>euclidean_distance_tf_idf_proc_b_1k</th>\n",
       "      <th>number_VERB_difference</th>\n",
       "      <th>number_ADJ_difference</th>\n",
       "      <th>number_#_difference_normalized</th>\n",
       "      <th>number_ADJ_difference_relative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.107695</td>\n",
       "      <td>3.038866</td>\n",
       "      <td>0.226334</td>\n",
       "      <td>0.224596</td>\n",
       "      <td>-0.592309</td>\n",
       "      <td>-0.513583</td>\n",
       "      <td>-0.007071</td>\n",
       "      <td>-0.345023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.728307</td>\n",
       "      <td>-1.288483</td>\n",
       "      <td>1.271983</td>\n",
       "      <td>1.307549</td>\n",
       "      <td>-1.145620</td>\n",
       "      <td>0.046877</td>\n",
       "      <td>-0.007071</td>\n",
       "      <td>1.471587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.451635</td>\n",
       "      <td>-0.399701</td>\n",
       "      <td>0.420348</td>\n",
       "      <td>0.488642</td>\n",
       "      <td>1.067623</td>\n",
       "      <td>5.651484</td>\n",
       "      <td>-0.007071</td>\n",
       "      <td>0.790358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.224216</td>\n",
       "      <td>-1.288483</td>\n",
       "      <td>1.167412</td>\n",
       "      <td>1.173976</td>\n",
       "      <td>-1.145620</td>\n",
       "      <td>-0.513583</td>\n",
       "      <td>-0.007071</td>\n",
       "      <td>-0.345023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.683224</td>\n",
       "      <td>-0.748061</td>\n",
       "      <td>0.597295</td>\n",
       "      <td>0.464334</td>\n",
       "      <td>-0.592309</td>\n",
       "      <td>-0.513583</td>\n",
       "      <td>-0.007071</td>\n",
       "      <td>-0.708344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499995</th>\n",
       "      <td>-0.493402</td>\n",
       "      <td>-0.825186</td>\n",
       "      <td>0.058106</td>\n",
       "      <td>-0.067736</td>\n",
       "      <td>-1.145620</td>\n",
       "      <td>-0.513583</td>\n",
       "      <td>-0.007071</td>\n",
       "      <td>-0.345023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499996</th>\n",
       "      <td>-0.665773</td>\n",
       "      <td>-0.738575</td>\n",
       "      <td>0.064478</td>\n",
       "      <td>0.055222</td>\n",
       "      <td>-0.038998</td>\n",
       "      <td>-0.513583</td>\n",
       "      <td>-0.007071</td>\n",
       "      <td>-0.708344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499997</th>\n",
       "      <td>-0.982963</td>\n",
       "      <td>-1.288483</td>\n",
       "      <td>0.085979</td>\n",
       "      <td>-0.093870</td>\n",
       "      <td>0.514313</td>\n",
       "      <td>-0.513583</td>\n",
       "      <td>-0.007071</td>\n",
       "      <td>-0.708344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499998</th>\n",
       "      <td>0.023407</td>\n",
       "      <td>-0.323782</td>\n",
       "      <td>0.232667</td>\n",
       "      <td>0.063907</td>\n",
       "      <td>-0.038998</td>\n",
       "      <td>-0.513583</td>\n",
       "      <td>-0.007071</td>\n",
       "      <td>-0.708344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499999</th>\n",
       "      <td>-0.748058</td>\n",
       "      <td>-0.818844</td>\n",
       "      <td>0.056609</td>\n",
       "      <td>-0.019650</td>\n",
       "      <td>-0.592309</td>\n",
       "      <td>-0.513583</td>\n",
       "      <td>-0.007071</td>\n",
       "      <td>-0.708344</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        jaccard_translation_proc_5k  jaccard_translation_vecmap  \\\n",
       "0                          3.107695                    3.038866   \n",
       "1                         -0.728307                   -1.288483   \n",
       "2                         -0.451635                   -0.399701   \n",
       "3                         -1.224216                   -1.288483   \n",
       "4                         -0.683224                   -0.748061   \n",
       "...                             ...                         ...   \n",
       "499995                    -0.493402                   -0.825186   \n",
       "499996                    -0.665773                   -0.738575   \n",
       "499997                    -0.982963                   -1.288483   \n",
       "499998                     0.023407                   -0.323782   \n",
       "499999                    -0.748058                   -0.818844   \n",
       "\n",
       "        euclidean_distance_tf_idf_vecmap  euclidean_distance_tf_idf_proc_b_1k  \\\n",
       "0                               0.226334                             0.224596   \n",
       "1                               1.271983                             1.307549   \n",
       "2                               0.420348                             0.488642   \n",
       "3                               1.167412                             1.173976   \n",
       "4                               0.597295                             0.464334   \n",
       "...                                  ...                                  ...   \n",
       "499995                          0.058106                            -0.067736   \n",
       "499996                          0.064478                             0.055222   \n",
       "499997                          0.085979                            -0.093870   \n",
       "499998                          0.232667                             0.063907   \n",
       "499999                          0.056609                            -0.019650   \n",
       "\n",
       "        number_VERB_difference  number_ADJ_difference  \\\n",
       "0                    -0.592309              -0.513583   \n",
       "1                    -1.145620               0.046877   \n",
       "2                     1.067623               5.651484   \n",
       "3                    -1.145620              -0.513583   \n",
       "4                    -0.592309              -0.513583   \n",
       "...                        ...                    ...   \n",
       "499995               -1.145620              -0.513583   \n",
       "499996               -0.038998              -0.513583   \n",
       "499997                0.514313              -0.513583   \n",
       "499998               -0.038998              -0.513583   \n",
       "499999               -0.592309              -0.513583   \n",
       "\n",
       "        number_#_difference_normalized  number_ADJ_difference_relative  \n",
       "0                            -0.007071                       -0.345023  \n",
       "1                            -0.007071                        1.471587  \n",
       "2                            -0.007071                        0.790358  \n",
       "3                            -0.007071                       -0.345023  \n",
       "4                            -0.007071                       -0.708344  \n",
       "...                                ...                             ...  \n",
       "499995                       -0.007071                       -0.345023  \n",
       "499996                       -0.007071                       -0.708344  \n",
       "499997                       -0.007071                       -0.708344  \n",
       "499998                       -0.007071                       -0.708344  \n",
       "499999                       -0.007071                       -0.708344  \n",
       "\n",
       "[500000 rows x 8 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test[data_test.columns] = scaler.transform(data_test[data_test.columns])\n",
    "data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Polish MAP score on test set: 0.8081\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict_proba(data_test)\n",
    "MapScore = MAP_score(feature_retrieval_it['source_id'], target_test, prediction)\n",
    "print(\"The Polish MAP score on test set: {:.4f}\".format(MapScore))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IV. Document level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the model on German-English doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_id</th>\n",
       "      <th>target_id</th>\n",
       "      <th>Translation</th>\n",
       "      <th>number_punctuations_total_difference</th>\n",
       "      <th>number_punctuations_total_difference_relative</th>\n",
       "      <th>number_punctuations_total_difference_normalized</th>\n",
       "      <th>number_words_difference</th>\n",
       "      <th>number_words_difference_relative</th>\n",
       "      <th>number_words_difference_normalized</th>\n",
       "      <th>number_unique_words_difference</th>\n",
       "      <th>...</th>\n",
       "      <th>cosine_similarity_average_proc_b_1k</th>\n",
       "      <th>cosine_similarity_tf_idf_proc_b_1k</th>\n",
       "      <th>euclidean_distance_average_proc_b_1k</th>\n",
       "      <th>euclidean_distance_tf_idf_proc_b_1k</th>\n",
       "      <th>jaccard_translation_proc_b_1k</th>\n",
       "      <th>cosine_similarity_average_vecmap</th>\n",
       "      <th>cosine_similarity_tf_idf_vecmap</th>\n",
       "      <th>euclidean_distance_average_vecmap</th>\n",
       "      <th>euclidean_distance_tf_idf_vecmap</th>\n",
       "      <th>jaccard_translation_vecmap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.178571</td>\n",
       "      <td>290</td>\n",
       "      <td>0.863095</td>\n",
       "      <td>0.178571</td>\n",
       "      <td>144</td>\n",
       "      <td>...</td>\n",
       "      <td>0.580389</td>\n",
       "      <td>0.549913</td>\n",
       "      <td>0.531730</td>\n",
       "      <td>0.054664</td>\n",
       "      <td>0.007030</td>\n",
       "      <td>0.158882</td>\n",
       "      <td>0.125875</td>\n",
       "      <td>0.602464</td>\n",
       "      <td>0.057259</td>\n",
       "      <td>0.007866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.178571</td>\n",
       "      <td>335</td>\n",
       "      <td>0.879265</td>\n",
       "      <td>0.178571</td>\n",
       "      <td>185</td>\n",
       "      <td>...</td>\n",
       "      <td>0.543362</td>\n",
       "      <td>0.521699</td>\n",
       "      <td>0.567206</td>\n",
       "      <td>0.055330</td>\n",
       "      <td>0.005784</td>\n",
       "      <td>0.073765</td>\n",
       "      <td>0.043059</td>\n",
       "      <td>0.656281</td>\n",
       "      <td>0.059766</td>\n",
       "      <td>0.006825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.178571</td>\n",
       "      <td>329</td>\n",
       "      <td>0.877333</td>\n",
       "      <td>0.178571</td>\n",
       "      <td>172</td>\n",
       "      <td>...</td>\n",
       "      <td>0.512680</td>\n",
       "      <td>0.452094</td>\n",
       "      <td>0.609772</td>\n",
       "      <td>0.057912</td>\n",
       "      <td>0.006540</td>\n",
       "      <td>0.082798</td>\n",
       "      <td>0.011172</td>\n",
       "      <td>0.693836</td>\n",
       "      <td>0.061963</td>\n",
       "      <td>0.007726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.178571</td>\n",
       "      <td>368</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.178571</td>\n",
       "      <td>167</td>\n",
       "      <td>...</td>\n",
       "      <td>0.536417</td>\n",
       "      <td>0.502595</td>\n",
       "      <td>0.580073</td>\n",
       "      <td>0.056595</td>\n",
       "      <td>0.006444</td>\n",
       "      <td>0.101143</td>\n",
       "      <td>0.050886</td>\n",
       "      <td>0.671459</td>\n",
       "      <td>0.058318</td>\n",
       "      <td>0.008272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.178571</td>\n",
       "      <td>389</td>\n",
       "      <td>0.894253</td>\n",
       "      <td>0.178571</td>\n",
       "      <td>174</td>\n",
       "      <td>...</td>\n",
       "      <td>0.530223</td>\n",
       "      <td>0.491524</td>\n",
       "      <td>0.575751</td>\n",
       "      <td>0.056442</td>\n",
       "      <td>0.005852</td>\n",
       "      <td>0.056589</td>\n",
       "      <td>-0.003096</td>\n",
       "      <td>0.673305</td>\n",
       "      <td>0.061273</td>\n",
       "      <td>0.006961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499995</th>\n",
       "      <td>99</td>\n",
       "      <td>4995</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.114773</td>\n",
       "      <td>332</td>\n",
       "      <td>0.917127</td>\n",
       "      <td>0.114773</td>\n",
       "      <td>167</td>\n",
       "      <td>...</td>\n",
       "      <td>0.486395</td>\n",
       "      <td>0.418157</td>\n",
       "      <td>0.623162</td>\n",
       "      <td>0.129749</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.016775</td>\n",
       "      <td>-0.145692</td>\n",
       "      <td>0.752196</td>\n",
       "      <td>0.133761</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499996</th>\n",
       "      <td>99</td>\n",
       "      <td>4996</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>373</td>\n",
       "      <td>0.925558</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>155</td>\n",
       "      <td>...</td>\n",
       "      <td>0.474177</td>\n",
       "      <td>0.402875</td>\n",
       "      <td>0.631539</td>\n",
       "      <td>0.131067</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.030901</td>\n",
       "      <td>-0.146376</td>\n",
       "      <td>0.744337</td>\n",
       "      <td>0.132629</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499997</th>\n",
       "      <td>99</td>\n",
       "      <td>4997</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>140</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>89</td>\n",
       "      <td>...</td>\n",
       "      <td>0.559839</td>\n",
       "      <td>0.524665</td>\n",
       "      <td>0.551034</td>\n",
       "      <td>0.123131</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083889</td>\n",
       "      <td>0.026164</td>\n",
       "      <td>0.649910</td>\n",
       "      <td>0.130587</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499998</th>\n",
       "      <td>99</td>\n",
       "      <td>4998</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006536</td>\n",
       "      <td>1</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.006536</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.553223</td>\n",
       "      <td>0.475026</td>\n",
       "      <td>0.565722</td>\n",
       "      <td>0.140282</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.174603</td>\n",
       "      <td>0.126667</td>\n",
       "      <td>0.642268</td>\n",
       "      <td>0.157276</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499999</th>\n",
       "      <td>99</td>\n",
       "      <td>4999</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>13</td>\n",
       "      <td>0.302326</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.580545</td>\n",
       "      <td>0.518932</td>\n",
       "      <td>0.542310</td>\n",
       "      <td>0.120518</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.190219</td>\n",
       "      <td>0.205569</td>\n",
       "      <td>0.628223</td>\n",
       "      <td>0.136986</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500000 rows × 148 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        source_id  target_id  Translation  \\\n",
       "0               0          0            1   \n",
       "1               0          1            0   \n",
       "2               0          2            0   \n",
       "3               0          3            0   \n",
       "4               0          4            0   \n",
       "...           ...        ...          ...   \n",
       "499995         99       4995            0   \n",
       "499996         99       4996            0   \n",
       "499997         99       4997            0   \n",
       "499998         99       4998            0   \n",
       "499999         99       4999            0   \n",
       "\n",
       "        number_punctuations_total_difference  \\\n",
       "0                                          5   \n",
       "1                                          5   \n",
       "2                                          5   \n",
       "3                                          5   \n",
       "4                                          5   \n",
       "...                                      ...   \n",
       "499995                                     1   \n",
       "499996                                     2   \n",
       "499997                                     2   \n",
       "499998                                     0   \n",
       "499999                                     2   \n",
       "\n",
       "        number_punctuations_total_difference_relative  \\\n",
       "0                                            1.000000   \n",
       "1                                            1.000000   \n",
       "2                                            1.000000   \n",
       "3                                            1.000000   \n",
       "4                                            1.000000   \n",
       "...                                               ...   \n",
       "499995                                       0.333333   \n",
       "499996                                       1.000000   \n",
       "499997                                       1.000000   \n",
       "499998                                       0.000000   \n",
       "499999                                       1.000000   \n",
       "\n",
       "        number_punctuations_total_difference_normalized  \\\n",
       "0                                              0.178571   \n",
       "1                                              0.178571   \n",
       "2                                              0.178571   \n",
       "3                                              0.178571   \n",
       "4                                              0.178571   \n",
       "...                                                 ...   \n",
       "499995                                         0.114773   \n",
       "499996                                         0.117647   \n",
       "499997                                         0.117647   \n",
       "499998                                         0.006536   \n",
       "499999                                         0.117647   \n",
       "\n",
       "        number_words_difference  number_words_difference_relative  \\\n",
       "0                           290                          0.863095   \n",
       "1                           335                          0.879265   \n",
       "2                           329                          0.877333   \n",
       "3                           368                          0.888889   \n",
       "4                           389                          0.894253   \n",
       "...                         ...                               ...   \n",
       "499995                      332                          0.917127   \n",
       "499996                      373                          0.925558   \n",
       "499997                      140                          0.823529   \n",
       "499998                        1                          0.032258   \n",
       "499999                       13                          0.302326   \n",
       "\n",
       "        number_words_difference_normalized  number_unique_words_difference  \\\n",
       "0                                 0.178571                             144   \n",
       "1                                 0.178571                             185   \n",
       "2                                 0.178571                             172   \n",
       "3                                 0.178571                             167   \n",
       "4                                 0.178571                             174   \n",
       "...                                    ...                             ...   \n",
       "499995                            0.114773                             167   \n",
       "499996                            0.117647                             155   \n",
       "499997                            0.117647                              89   \n",
       "499998                            0.006536                               4   \n",
       "499999                            0.117647                               5   \n",
       "\n",
       "        ...  cosine_similarity_average_proc_b_1k  \\\n",
       "0       ...                             0.580389   \n",
       "1       ...                             0.543362   \n",
       "2       ...                             0.512680   \n",
       "3       ...                             0.536417   \n",
       "4       ...                             0.530223   \n",
       "...     ...                                  ...   \n",
       "499995  ...                             0.486395   \n",
       "499996  ...                             0.474177   \n",
       "499997  ...                             0.559839   \n",
       "499998  ...                             0.553223   \n",
       "499999  ...                             0.580545   \n",
       "\n",
       "        cosine_similarity_tf_idf_proc_b_1k  \\\n",
       "0                                 0.549913   \n",
       "1                                 0.521699   \n",
       "2                                 0.452094   \n",
       "3                                 0.502595   \n",
       "4                                 0.491524   \n",
       "...                                    ...   \n",
       "499995                            0.418157   \n",
       "499996                            0.402875   \n",
       "499997                            0.524665   \n",
       "499998                            0.475026   \n",
       "499999                            0.518932   \n",
       "\n",
       "        euclidean_distance_average_proc_b_1k  \\\n",
       "0                                   0.531730   \n",
       "1                                   0.567206   \n",
       "2                                   0.609772   \n",
       "3                                   0.580073   \n",
       "4                                   0.575751   \n",
       "...                                      ...   \n",
       "499995                              0.623162   \n",
       "499996                              0.631539   \n",
       "499997                              0.551034   \n",
       "499998                              0.565722   \n",
       "499999                              0.542310   \n",
       "\n",
       "        euclidean_distance_tf_idf_proc_b_1k  jaccard_translation_proc_b_1k  \\\n",
       "0                                  0.054664                       0.007030   \n",
       "1                                  0.055330                       0.005784   \n",
       "2                                  0.057912                       0.006540   \n",
       "3                                  0.056595                       0.006444   \n",
       "4                                  0.056442                       0.005852   \n",
       "...                                     ...                            ...   \n",
       "499995                             0.129749                       0.000000   \n",
       "499996                             0.131067                       0.000000   \n",
       "499997                             0.123131                       0.000000   \n",
       "499998                             0.140282                       0.000000   \n",
       "499999                             0.120518                       0.000000   \n",
       "\n",
       "        cosine_similarity_average_vecmap  cosine_similarity_tf_idf_vecmap  \\\n",
       "0                               0.158882                         0.125875   \n",
       "1                               0.073765                         0.043059   \n",
       "2                               0.082798                         0.011172   \n",
       "3                               0.101143                         0.050886   \n",
       "4                               0.056589                        -0.003096   \n",
       "...                                  ...                              ...   \n",
       "499995                         -0.016775                        -0.145692   \n",
       "499996                         -0.030901                        -0.146376   \n",
       "499997                          0.083889                         0.026164   \n",
       "499998                          0.174603                         0.126667   \n",
       "499999                          0.190219                         0.205569   \n",
       "\n",
       "        euclidean_distance_average_vecmap  euclidean_distance_tf_idf_vecmap  \\\n",
       "0                                0.602464                          0.057259   \n",
       "1                                0.656281                          0.059766   \n",
       "2                                0.693836                          0.061963   \n",
       "3                                0.671459                          0.058318   \n",
       "4                                0.673305                          0.061273   \n",
       "...                                   ...                               ...   \n",
       "499995                           0.752196                          0.133761   \n",
       "499996                           0.744337                          0.132629   \n",
       "499997                           0.649910                          0.130587   \n",
       "499998                           0.642268                          0.157276   \n",
       "499999                           0.628223                          0.136986   \n",
       "\n",
       "        jaccard_translation_vecmap  \n",
       "0                         0.007866  \n",
       "1                         0.006825  \n",
       "2                         0.007726  \n",
       "3                         0.008272  \n",
       "4                         0.006961  \n",
       "...                            ...  \n",
       "499995                    0.000000  \n",
       "499996                    0.000000  \n",
       "499997                    0.000000  \n",
       "499998                    0.000000  \n",
       "499999                    0.000000  \n",
       "\n",
       "[500000 rows x 148 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_retrieval_doc=pd.read_feather(\"../data/processed/feature_retrieval_doc.feather\")\n",
    "feature_retrieval_doc = feature_retrieval_doc.rename(columns={\"id_source\": \"source_id\", \"id_target\": \"target_id\"})\n",
    "feature_retrieval_doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>jaccard_translation_proc_5k</th>\n",
       "      <th>jaccard_translation_vecmap</th>\n",
       "      <th>euclidean_distance_tf_idf_vecmap</th>\n",
       "      <th>euclidean_distance_tf_idf_proc_b_1k</th>\n",
       "      <th>number_VERB_difference</th>\n",
       "      <th>number_ADJ_difference</th>\n",
       "      <th>number_#_difference_normalized</th>\n",
       "      <th>number_ADJ_difference_relative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.007874</td>\n",
       "      <td>0.007866</td>\n",
       "      <td>0.057259</td>\n",
       "      <td>0.054664</td>\n",
       "      <td>11</td>\n",
       "      <td>17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.680000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.006623</td>\n",
       "      <td>0.006825</td>\n",
       "      <td>0.059766</td>\n",
       "      <td>0.055330</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.007692</td>\n",
       "      <td>0.007726</td>\n",
       "      <td>0.061963</td>\n",
       "      <td>0.057912</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.004032</td>\n",
       "      <td>0.008272</td>\n",
       "      <td>0.058318</td>\n",
       "      <td>0.056595</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.692308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.006849</td>\n",
       "      <td>0.006961</td>\n",
       "      <td>0.061273</td>\n",
       "      <td>0.056442</td>\n",
       "      <td>9</td>\n",
       "      <td>24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499995</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.133761</td>\n",
       "      <td>0.129749</td>\n",
       "      <td>19</td>\n",
       "      <td>37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.948718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499996</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.132629</td>\n",
       "      <td>0.131067</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499997</th>\n",
       "      <td>0.004854</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.130587</td>\n",
       "      <td>0.123131</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499998</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.157276</td>\n",
       "      <td>0.140282</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499999</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.136986</td>\n",
       "      <td>0.120518</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        jaccard_translation_proc_5k  jaccard_translation_vecmap  \\\n",
       "0                          0.007874                    0.007866   \n",
       "1                          0.006623                    0.006825   \n",
       "2                          0.007692                    0.007726   \n",
       "3                          0.004032                    0.008272   \n",
       "4                          0.006849                    0.006961   \n",
       "...                             ...                         ...   \n",
       "499995                     0.000000                    0.000000   \n",
       "499996                     0.000000                    0.000000   \n",
       "499997                     0.004854                    0.000000   \n",
       "499998                     0.000000                    0.000000   \n",
       "499999                     0.000000                    0.000000   \n",
       "\n",
       "        euclidean_distance_tf_idf_vecmap  euclidean_distance_tf_idf_proc_b_1k  \\\n",
       "0                               0.057259                             0.054664   \n",
       "1                               0.059766                             0.055330   \n",
       "2                               0.061963                             0.057912   \n",
       "3                               0.058318                             0.056595   \n",
       "4                               0.061273                             0.056442   \n",
       "...                                  ...                                  ...   \n",
       "499995                          0.133761                             0.129749   \n",
       "499996                          0.132629                             0.131067   \n",
       "499997                          0.130587                             0.123131   \n",
       "499998                          0.157276                             0.140282   \n",
       "499999                          0.136986                             0.120518   \n",
       "\n",
       "        number_VERB_difference  number_ADJ_difference  \\\n",
       "0                           11                     17   \n",
       "1                            7                     10   \n",
       "2                            2                      6   \n",
       "3                            2                     18   \n",
       "4                            9                     24   \n",
       "...                        ...                    ...   \n",
       "499995                      19                     37   \n",
       "499996                       7                     10   \n",
       "499997                       4                      3   \n",
       "499998                       0                      2   \n",
       "499999                       2                      0   \n",
       "\n",
       "        number_#_difference_normalized  number_ADJ_difference_relative  \n",
       "0                                  0.0                        0.680000  \n",
       "1                                  0.0                        0.555556  \n",
       "2                                  0.0                        0.428571  \n",
       "3                                  0.0                        0.692308  \n",
       "4                                  0.0                        0.750000  \n",
       "...                                ...                             ...  \n",
       "499995                             0.0                        0.948718  \n",
       "499996                             0.0                        0.833333  \n",
       "499997                             0.0                        0.600000  \n",
       "499998                             0.0                        0.500000  \n",
       "499999                             0.0                        0.000000  \n",
       "\n",
       "[500000 rows x 8 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_test = feature_retrieval_doc['Translation']\n",
    "data_test = feature_retrieval_doc.filter(items=start_features)\n",
    "data_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>jaccard_translation_proc_5k</th>\n",
       "      <th>jaccard_translation_vecmap</th>\n",
       "      <th>euclidean_distance_tf_idf_vecmap</th>\n",
       "      <th>euclidean_distance_tf_idf_proc_b_1k</th>\n",
       "      <th>number_VERB_difference</th>\n",
       "      <th>number_ADJ_difference</th>\n",
       "      <th>number_#_difference_normalized</th>\n",
       "      <th>number_ADJ_difference_relative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.083643</td>\n",
       "      <td>-1.148194</td>\n",
       "      <td>-0.386573</td>\n",
       "      <td>-0.372711</td>\n",
       "      <td>4.940800</td>\n",
       "      <td>8.453787</td>\n",
       "      <td>-0.007071</td>\n",
       "      <td>0.599614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.105986</td>\n",
       "      <td>-1.166766</td>\n",
       "      <td>-0.350860</td>\n",
       "      <td>-0.363133</td>\n",
       "      <td>2.727556</td>\n",
       "      <td>4.530563</td>\n",
       "      <td>-0.007071</td>\n",
       "      <td>0.260514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.086887</td>\n",
       "      <td>-1.150694</td>\n",
       "      <td>-0.319545</td>\n",
       "      <td>-0.325956</td>\n",
       "      <td>-0.038998</td>\n",
       "      <td>2.288720</td>\n",
       "      <td>-0.007071</td>\n",
       "      <td>-0.085507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.152229</td>\n",
       "      <td>-1.140954</td>\n",
       "      <td>-0.371484</td>\n",
       "      <td>-0.344923</td>\n",
       "      <td>-0.038998</td>\n",
       "      <td>9.014248</td>\n",
       "      <td>-0.007071</td>\n",
       "      <td>0.633152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.101937</td>\n",
       "      <td>-1.164342</td>\n",
       "      <td>-0.329379</td>\n",
       "      <td>-0.347125</td>\n",
       "      <td>3.834178</td>\n",
       "      <td>12.377011</td>\n",
       "      <td>-0.007071</td>\n",
       "      <td>0.790358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499995</th>\n",
       "      <td>-1.224216</td>\n",
       "      <td>-1.288483</td>\n",
       "      <td>0.703466</td>\n",
       "      <td>0.708221</td>\n",
       "      <td>9.367287</td>\n",
       "      <td>19.663000</td>\n",
       "      <td>-0.007071</td>\n",
       "      <td>1.331847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499996</th>\n",
       "      <td>-1.224216</td>\n",
       "      <td>-1.288483</td>\n",
       "      <td>0.687331</td>\n",
       "      <td>0.727202</td>\n",
       "      <td>2.727556</td>\n",
       "      <td>4.530563</td>\n",
       "      <td>-0.007071</td>\n",
       "      <td>1.017434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499997</th>\n",
       "      <td>-1.137552</td>\n",
       "      <td>-1.288483</td>\n",
       "      <td>0.658232</td>\n",
       "      <td>0.612942</td>\n",
       "      <td>1.067623</td>\n",
       "      <td>0.607338</td>\n",
       "      <td>-0.007071</td>\n",
       "      <td>0.381621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499998</th>\n",
       "      <td>-1.224216</td>\n",
       "      <td>-1.288483</td>\n",
       "      <td>1.038513</td>\n",
       "      <td>0.859858</td>\n",
       "      <td>-1.145620</td>\n",
       "      <td>0.046877</td>\n",
       "      <td>-0.007071</td>\n",
       "      <td>0.109130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499999</th>\n",
       "      <td>-1.224216</td>\n",
       "      <td>-1.288483</td>\n",
       "      <td>0.749411</td>\n",
       "      <td>0.575328</td>\n",
       "      <td>-0.038998</td>\n",
       "      <td>-1.074044</td>\n",
       "      <td>-0.007071</td>\n",
       "      <td>-1.253327</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        jaccard_translation_proc_5k  jaccard_translation_vecmap  \\\n",
       "0                         -1.083643                   -1.148194   \n",
       "1                         -1.105986                   -1.166766   \n",
       "2                         -1.086887                   -1.150694   \n",
       "3                         -1.152229                   -1.140954   \n",
       "4                         -1.101937                   -1.164342   \n",
       "...                             ...                         ...   \n",
       "499995                    -1.224216                   -1.288483   \n",
       "499996                    -1.224216                   -1.288483   \n",
       "499997                    -1.137552                   -1.288483   \n",
       "499998                    -1.224216                   -1.288483   \n",
       "499999                    -1.224216                   -1.288483   \n",
       "\n",
       "        euclidean_distance_tf_idf_vecmap  euclidean_distance_tf_idf_proc_b_1k  \\\n",
       "0                              -0.386573                            -0.372711   \n",
       "1                              -0.350860                            -0.363133   \n",
       "2                              -0.319545                            -0.325956   \n",
       "3                              -0.371484                            -0.344923   \n",
       "4                              -0.329379                            -0.347125   \n",
       "...                                  ...                                  ...   \n",
       "499995                          0.703466                             0.708221   \n",
       "499996                          0.687331                             0.727202   \n",
       "499997                          0.658232                             0.612942   \n",
       "499998                          1.038513                             0.859858   \n",
       "499999                          0.749411                             0.575328   \n",
       "\n",
       "        number_VERB_difference  number_ADJ_difference  \\\n",
       "0                     4.940800               8.453787   \n",
       "1                     2.727556               4.530563   \n",
       "2                    -0.038998               2.288720   \n",
       "3                    -0.038998               9.014248   \n",
       "4                     3.834178              12.377011   \n",
       "...                        ...                    ...   \n",
       "499995                9.367287              19.663000   \n",
       "499996                2.727556               4.530563   \n",
       "499997                1.067623               0.607338   \n",
       "499998               -1.145620               0.046877   \n",
       "499999               -0.038998              -1.074044   \n",
       "\n",
       "        number_#_difference_normalized  number_ADJ_difference_relative  \n",
       "0                            -0.007071                        0.599614  \n",
       "1                            -0.007071                        0.260514  \n",
       "2                            -0.007071                       -0.085507  \n",
       "3                            -0.007071                        0.633152  \n",
       "4                            -0.007071                        0.790358  \n",
       "...                                ...                             ...  \n",
       "499995                       -0.007071                        1.331847  \n",
       "499996                       -0.007071                        1.017434  \n",
       "499997                       -0.007071                        0.381621  \n",
       "499998                       -0.007071                        0.109130  \n",
       "499999                       -0.007071                       -1.253327  \n",
       "\n",
       "[500000 rows x 8 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test[data_test.columns] = scaler.transform(data_test[data_test.columns])\n",
    "data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Doc MAP score on test set: 0.0005\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict_proba(data_test)\n",
    "MapScore = MAP_score(feature_retrieval_doc['source_id'], target_test, prediction)\n",
    "print(\"The Doc MAP score on test set: {:.4f}\".format(MapScore))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}