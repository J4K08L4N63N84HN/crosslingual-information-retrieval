{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Preprocessing and Feature Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In this notebook we import the data, preprocess the data and create features for supervised and unsupervised cross-lingual-information retrieval models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## I. Import Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we import the English and German europarl datasets and combine them into a parallel sentence translation dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.dirname((os.path.abspath(''))))\n",
    "\n",
    "from src.data import create_data_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'load_doc' in 1.56 seconds.\n",
      "Finished function: 'to_sentences' in 1.05 seconds.\n",
      "Finished function: 'load_doc' in 2.01 seconds.\n",
      "Finished function: 'to_sentences' in 1.24 seconds.\n",
      "Sampled dataframe saved in: ../data/interim/europarl_en_de_test.pkl\n",
      "Finished function: 'create_data_subset' in 7.85 seconds.\n"
     ]
    }
   ],
   "source": [
    "create_data_subset(sentence_data_source_path='../data/external/europarl-v7.de-en.en',\n",
    "                   sentence_data_target_path='../data/external/europarl-v7.de-en.de',\n",
    "                   sample_size=35000,\n",
    "                   sentence_data_sampled_path=\"../data/interim/europarl_en_de_test.pkl\",)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## II. Preprocess data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we preprocess the parallel sentence data for the feature generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from nltk.corpus import stopwords\n",
    "from textblob import TextBlob as textblob_source\n",
    "from textblob_de import TextBlobDE as textblob_target\n",
    "import en_core_web_sm\n",
    "import de_core_news_sm\n",
    "# import it_core_news_sm\n",
    "# import pl_core_news_sm\n",
    "import time\n",
    "from src.data import PreprocessingEuroParl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "stopwords_source = stopwords.words('english')\n",
    "stopwords_target = stopwords.words('german') # German stopwords\n",
    "# stopwords_target = stopwords.words('italian') # Italian stopwords\n",
    "# stopwords_target = stopwords.words('polish') # Polish stopwords\n",
    "nlp_source = en_core_web_sm.load()\n",
    "nlp_target = de_core_news_sm.load() # German pipeline\n",
    "# nlp_target = it_core_news_sm.load() # Italian pipeline\n",
    "# nlp_target = pl_core_news_sm.load() # Polish pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'import_data' in 0.04 seconds.\n"
     ]
    }
   ],
   "source": [
    "parallel_sentences = PreprocessingEuroParl(df_sampled_path=\"../data/interim/europarl_en_de_test.pkl\") # German\n",
    "# parallel_sentences = PreprocessingEuroParl(df_sampled_path=\"../data/interim/europarl_en_it.pkl\") # Italien\n",
    "# parallel_sentences = PreprocessingEuroParl(df_sampled_path=\"../data/interim/europarl_en_pol.pkl\") # Polnisch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "parallel_sentences.dataframe = parallel_sentences.dataframe.iloc[30000:, :]\n",
    "parallel_sentences.dataframe = parallel_sentences.dataframe.reset_index(drop=True)\n",
    "parallel_sentences.dataframe[\"id_source\"] = np.arange(len(parallel_sentences.dataframe))\n",
    "parallel_sentences.dataframe[\"id_target\"] = np.arange(len(parallel_sentences.dataframe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:39<00:00, 125.99it/s]\n",
      "100%|██████████| 5000/5000 [00:00<00:00, 192976.42it/s]\n",
      "100%|██████████| 5000/5000 [00:00<00:00, 124244.75it/s]\n",
      "100%|██████████| 5000/5000 [00:00<00:00, 63269.37it/s]\n",
      "100%|██████████| 5000/5000 [00:00<00:00, 154990.98it/s]\n",
      "  0%|          | 0/5000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'spacy' in 39.69 seconds.\n",
      "Finished function: 'remove_punctuation' in 0.03 seconds.\n",
      "Finished function: 'remove_numbers' in 0.04 seconds.\n",
      "Finished function: 'lemmatize' in 0.08 seconds.\n",
      "Finished function: 'lowercase_spacy' in 0.03 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:00<00:00, 17386.77it/s]\n",
      "  0%|          | 14/5000 [00:00<00:36, 135.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'remove_stopwords' in 0.29 seconds.\n",
      "Finished function: 'create_cleaned_token_embedding' in 40.22 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:36<00:00, 135.76it/s]\n",
      "100%|██████████| 5000/5000 [00:00<00:00, 191498.00it/s]\n",
      "100%|██████████| 5000/5000 [00:00<00:00, 195473.03it/s]\n",
      "100%|██████████| 5000/5000 [00:00<00:00, 73237.37it/s]\n",
      "100%|██████████| 5000/5000 [00:00<00:00, 152475.79it/s]\n",
      " 13%|█▎        | 667/5000 [00:00<00:01, 3664.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'spacy' in 36.83 seconds.\n",
      "Finished function: 'remove_punctuation' in 0.03 seconds.\n",
      "Finished function: 'remove_numbers' in 0.03 seconds.\n",
      "Finished function: 'lemmatize' in 0.07 seconds.\n",
      "Finished function: 'lowercase_spacy' in 0.03 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:00<00:00, 12765.04it/s]\n",
      " 15%|█▍        | 737/5000 [00:00<00:01, 3531.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'remove_stopwords' in 0.39 seconds.\n",
      "Finished function: 'create_cleaned_token_embedding' in 37.43 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:01<00:00, 4280.96it/s]\n",
      " 46%|████▌     | 2284/5000 [00:00<00:00, 22837.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'tokenize_sentence' in 1.17 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:00<00:00, 22901.20it/s]\n",
      "100%|██████████| 5000/5000 [00:00<00:00, 122677.77it/s]\n",
      "100%|██████████| 5000/5000 [00:00<00:00, 147986.90it/s]\n",
      " 41%|████      | 2060/5000 [00:00<00:00, 20596.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'remove_stopwords' in 0.22 seconds.\n",
      "Finished function: 'strip_whitespace' in 0.04 seconds.\n",
      "Finished function: 'lowercase' in 0.04 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:00<00:00, 22143.88it/s]\n",
      " 18%|█▊        | 892/5000 [00:00<00:00, 4351.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'remove_stopwords' in 0.23 seconds.\n",
      "Finished function: 'create_cleaned_text' in 1.71 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:01<00:00, 4527.10it/s]\n",
      " 37%|███▋      | 1869/5000 [00:00<00:00, 18689.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'tokenize_sentence' in 1.11 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:00<00:00, 18172.97it/s]\n",
      "100%|██████████| 5000/5000 [00:00<00:00, 163590.78it/s]\n",
      "100%|██████████| 5000/5000 [00:00<00:00, 103908.91it/s]\n",
      " 17%|█▋        | 847/5000 [00:00<00:00, 7463.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'remove_stopwords' in 0.28 seconds.\n",
      "Finished function: 'strip_whitespace' in 0.03 seconds.\n",
      "Finished function: 'lowercase' in 0.05 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:00<00:00, 10776.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'remove_stopwords' in 0.47 seconds.\n",
      "Finished function: 'create_cleaned_text' in 1.95 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "parallel_sentences.preprocess_sentences(nlp_source, nlp_target, stopwords_source, stopwords_target)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:00<00:00, 57565.20it/s]\n",
      "100%|██████████| 5000/5000 [00:00<00:00, 68232.46it/s]\n",
      "100%|██████████| 5000/5000 [00:00<00:00, 204968.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'number_punctuations_total' in 0.09 seconds.\n",
      "Finished function: 'number_punctuations_total' in 0.08 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 5000/5000 [00:00<00:00, 152439.21it/s]\n",
      "  0%|          | 0/5000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'number_words' in 0.03 seconds.\n",
      "Finished function: 'number_words' in 0.04 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:00<00:00, 38255.79it/s]\n",
      "  0%|          | 0/5000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'number_unique_words' in 0.13 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:00<00:00, 50974.99it/s]\n",
      "100%|██████████| 5000/5000 [00:00<00:00, 79739.62it/s]\n",
      "  0%|          | 0/5000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'number_unique_words' in 0.1 seconds.\n",
      "Finished function: 'number_characters' in 0.06 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:00<00:00, 82351.70it/s]\n",
      "/Users/I534344/Google Drive/crosslingual-information-retrieval/src/data/preprocess_data.py:262: RuntimeWarning: divide by zero encountered in log\n",
      "  return (character_vector / word_vector).replace(np.nan, 0).replace(np.inf, 0).replace(np.log(0), 0)\n",
      "100%|██████████| 5000/5000 [00:00<00:00, 402223.29it/s]\n",
      "100%|██████████| 5000/5000 [00:00<00:00, 261382.72it/s]\n",
      "  0%|          | 0/5000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'number_characters' in 0.06 seconds.\n",
      "Finished function: 'average_characters' in 0.03 seconds.\n",
      "Finished function: 'average_characters' in 0.0 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.01 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.02 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:00<00:00, 375490.50it/s]\n",
      "100%|██████████| 5000/5000 [00:00<00:00, 334607.42it/s]\n",
      "100%|██████████| 5000/5000 [00:00<00:00, 388627.76it/s]\n",
      "100%|██████████| 5000/5000 [00:00<00:00, 377953.75it/s]\n",
      "100%|██████████| 5000/5000 [00:00<00:00, 383440.66it/s]\n",
      "100%|██████████| 5000/5000 [00:00<00:00, 241933.48it/s]\n",
      "100%|██████████| 5000/5000 [00:00<00:00, 389284.23it/s]\n",
      "100%|██████████| 5000/5000 [00:00<00:00, 358732.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'number_punctuation_marks' in 0.02 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.02 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.01 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.01 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.01 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.02 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.01 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 5000/5000 [00:00<00:00, 348601.54it/s]\n",
      "100%|██████████| 5000/5000 [00:00<00:00, 366455.58it/s]\n",
      "100%|██████████| 5000/5000 [00:00<00:00, 396789.59it/s]\n",
      "100%|██████████| 5000/5000 [00:00<00:00, 369763.74it/s]\n",
      "100%|██████████| 5000/5000 [00:00<00:00, 303253.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'number_punctuation_marks' in 0.02 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.02 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.02 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.02 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.02 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 5000/5000 [00:00<00:00, 350805.77it/s]\n",
      "100%|██████████| 5000/5000 [00:00<00:00, 350091.31it/s]\n",
      "100%|██████████| 5000/5000 [00:00<00:00, 363287.89it/s]\n",
      "100%|██████████| 5000/5000 [00:00<00:00, 325968.66it/s]\n",
      "100%|██████████| 5000/5000 [00:00<00:00, 320063.49it/s]\n",
      "100%|██████████| 5000/5000 [00:00<00:00, 400387.95it/s]\n",
      "100%|██████████| 5000/5000 [00:00<00:00, 244224.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'number_punctuation_marks' in 0.02 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.02 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.02 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.02 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.02 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.02 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.01 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 5000/5000 [00:00<00:00, 217772.79it/s]\n",
      "100%|██████████| 5000/5000 [00:00<00:00, 263752.89it/s]\n",
      "100%|██████████| 5000/5000 [00:00<00:00, 308377.50it/s]\n",
      "  0%|          | 0/5000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'number_punctuation_marks' in 0.02 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.03 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.02 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.02 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:00<00:00, 251318.46it/s]\n",
      "100%|██████████| 5000/5000 [00:00<00:00, 323310.26it/s]\n",
      "100%|██████████| 5000/5000 [00:00<00:00, 360459.26it/s]\n",
      "100%|██████████| 5000/5000 [00:00<00:00, 361528.07it/s]\n",
      "100%|██████████| 5000/5000 [00:00<00:00, 345568.57it/s]\n",
      "100%|██████████| 5000/5000 [00:00<00:00, 406606.05it/s]\n",
      "100%|██████████| 5000/5000 [00:00<00:00, 229518.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'number_punctuation_marks' in 0.02 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.02 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.02 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.02 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.02 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.01 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 5000/5000 [00:00<00:00, 326750.80it/s]\n",
      "100%|██████████| 5000/5000 [00:00<00:00, 237575.70it/s]\n",
      "100%|██████████| 5000/5000 [00:00<00:00, 351593.88it/s]\n",
      "100%|██████████| 5000/5000 [00:00<00:00, 320655.64it/s]\n",
      "  0%|          | 0/5000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'number_punctuation_marks' in 0.02 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.02 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.02 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.02 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.02 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:00<00:00, 282676.95it/s]\n",
      "100%|██████████| 5000/5000 [00:00<00:00, 294933.20it/s]\n",
      "100%|██████████| 5000/5000 [00:00<00:00, 233564.47it/s]\n",
      "100%|██████████| 5000/5000 [00:00<00:00, 344846.91it/s]\n",
      "100%|██████████| 5000/5000 [00:00<00:00, 329057.93it/s]\n",
      "100%|██████████| 5000/5000 [00:00<00:00, 298952.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'number_punctuation_marks' in 0.02 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.02 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.02 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.02 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.02 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 5000/5000 [00:00<00:00, 328619.65it/s]\n",
      "100%|██████████| 5000/5000 [00:00<00:00, 344066.15it/s]\n",
      "100%|██████████| 5000/5000 [00:00<00:00, 467123.73it/s]\n",
      "100%|██████████| 5000/5000 [00:00<00:00, 431033.83it/s]\n",
      "100%|██████████| 5000/5000 [00:00<00:00, 459932.01it/s]\n",
      "100%|██████████| 5000/5000 [00:00<00:00, 384347.19it/s]\n",
      "  0%|          | 0/5000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'number_punctuation_marks' in 0.02 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.02 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.02 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.01 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.01 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.01 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.01 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:00<00:00, 465640.57it/s]\n",
      "100%|██████████| 5000/5000 [00:00<00:00, 422821.43it/s]\n",
      "100%|██████████| 5000/5000 [00:00<00:00, 455912.52it/s]\n",
      "100%|██████████| 5000/5000 [00:00<00:00, 458423.94it/s]\n",
      "100%|██████████| 5000/5000 [00:00<00:00, 493586.90it/s]\n",
      "100%|██████████| 5000/5000 [00:00<00:00, 432331.16it/s]\n",
      "100%|██████████| 5000/5000 [00:00<00:00, 481009.20it/s]\n",
      "100%|██████████| 5000/5000 [00:00<00:00, 423077.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'number_punctuation_marks' in 0.01 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.01 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.01 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.01 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.01 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.01 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.01 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:00<00:00, 429665.02it/s]\n",
      "100%|██████████| 5000/5000 [00:00<00:00, 409432.07it/s]\n",
      "100%|██████████| 5000/5000 [00:00<00:00, 496873.03it/s]\n",
      "100%|██████████| 5000/5000 [00:00<00:00, 439645.29it/s]\n",
      "100%|██████████| 5000/5000 [00:00<00:00, 438642.96it/s]\n",
      "100%|██████████| 5000/5000 [00:00<00:00, 454391.26it/s]\n",
      "100%|██████████| 5000/5000 [00:00<00:00, 486702.41it/s]\n",
      "100%|██████████| 5000/5000 [00:00<00:00, 431078.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'number_punctuation_marks' in 0.02 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.01 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.01 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.01 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.01 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.01 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.01 seconds.\n",
      "Finished function: 'number_punctuation_marks' in 0.01 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 10/5000 [00:00<00:52, 95.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'number_punctuation_marks' in 0.01 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:39<00:00, 125.99it/s]\n",
      "  0%|          | 12/5000 [00:00<00:45, 110.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'spacy' in 39.69 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:45<00:00, 110.76it/s]\n",
      "100%|██████████| 5000/5000 [00:00<00:00, 164196.61it/s]\n",
      "100%|██████████| 5000/5000 [00:00<00:00, 179006.62it/s]\n",
      "100%|██████████| 5000/5000 [00:00<00:00, 150570.94it/s]\n",
      "100%|██████████| 5000/5000 [00:00<00:00, 132594.35it/s]\n",
      "100%|██████████| 5000/5000 [00:00<00:00, 86968.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'spacy' in 45.14 seconds.\n",
      "Finished function: 'number_pos' in 0.03 seconds.\n",
      "Finished function: 'number_pos' in 0.03 seconds.\n",
      "Finished function: 'number_pos' in 0.04 seconds.\n",
      "Finished function: 'number_pos' in 0.04 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:00<00:00, 123808.32it/s]\n",
      " 43%|████▎     | 2127/5000 [00:00<00:00, 10533.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'number_pos' in 0.06 seconds.\n",
      "Finished function: 'number_pos' in 0.04 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:00<00:00, 10517.31it/s]\n",
      " 49%|████▉     | 2468/5000 [00:00<00:00, 12200.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'number_times' in 0.48 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:00<00:00, 10926.82it/s]\n",
      " 15%|█▍        | 733/5000 [00:00<00:00, 7323.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'number_times' in 0.46 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:00<00:00, 9791.54it/s]\n",
      " 48%|████▊     | 2421/5000 [00:00<00:00, 11806.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'number_times' in 0.51 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:00<00:00, 12550.30it/s]\n",
      " 47%|████▋     | 2338/5000 [00:00<00:00, 11716.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'number_times' in 0.4 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:00<00:00, 11752.29it/s]\n",
      " 24%|██▍       | 1201/5000 [00:00<00:00, 12001.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'number_times' in 0.43 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:00<00:00, 10862.22it/s]\n",
      "100%|██████████| 5000/5000 [00:00<00:00, 106057.64it/s]\n",
      "100%|██████████| 5000/5000 [00:00<00:00, 115370.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'number_times' in 0.46 seconds.\n",
      "Finished function: 'named_numbers' in 0.05 seconds.\n",
      "Finished function: 'named_numbers' in 0.05 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "parallel_sentences.extract_sentence_information(nlp_source, nlp_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'load_embeddings' in 1.29 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 77/5000 [00:00<00:06, 763.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'load_embeddings' in 0.64 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:07<00:00, 705.75it/s]\n",
      "  2%|▏         | 83/5000 [00:00<00:05, 828.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'word_embeddings' in 7.09 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:06<00:00, 771.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'word_embeddings' in 6.48 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:00<00:00, 259876.58it/s]\n",
      "100%|██████████| 5000/5000 [00:00<00:00, 221719.07it/s]\n",
      "  6%|▋         | 313/5000 [00:00<00:01, 3128.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'create_translation_dictionary' in 20.78 seconds.\n",
      "Finished function: 'translate_words' in 0.02 seconds.\n",
      "Finished function: 'translate_words' in 0.02 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:02<00:00, 2457.90it/s]\n",
      "  7%|▋         | 339/5000 [00:00<00:01, 3382.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'tf_idf_vector' in 2.1 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:01<00:00, 3027.60it/s]\n",
      " 12%|█▏        | 618/5000 [00:00<00:01, 3073.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'tf_idf_vector' in 1.74 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:02<00:00, 2431.44it/s]\n",
      "  6%|▌         | 305/5000 [00:00<00:01, 3042.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'sentence_embedding_average' in 2.06 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:01<00:00, 2521.64it/s]\n",
      "  1%|          | 32/5000 [00:00<00:16, 309.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'sentence_embedding_average' in 1.98 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 155/5000 [00:00<00:20, 238.00it/s]/Users/I534344/Google Drive/crosslingual-information-retrieval/src/data/preprocess_data.py:616: RuntimeWarning: Mean of empty slice.\n",
      "  return [pd.Series(embedding_dataframe.values.mean(axis=1))]\n",
      "100%|██████████| 5000/5000 [00:21<00:00, 231.86it/s]\n",
      "  1%|▏         | 65/5000 [00:00<00:15, 324.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'sentence_embedding_tf_idf' in 21.57 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:19<00:00, 262.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'sentence_embedding_tf_idf' in 19.07 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "parallel_sentences.create_embedding_information(\"proc_5k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'load_embeddings' in 0.83 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 129/5000 [00:00<00:07, 660.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'load_embeddings' in 0.61 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:07<00:00, 627.94it/s]\n",
      "  2%|▏         | 77/5000 [00:00<00:06, 766.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'word_embeddings' in 7.96 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:08<00:00, 579.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'word_embeddings' in 8.63 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:00<00:00, 230999.49it/s]\n",
      "100%|██████████| 5000/5000 [00:00<00:00, 194416.56it/s]\n",
      "  0%|          | 0/5000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'create_translation_dictionary' in 27.67 seconds.\n",
      "Finished function: 'translate_words' in 0.02 seconds.\n",
      "Finished function: 'translate_words' in 0.03 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:02<00:00, 2156.91it/s]\n",
      "  4%|▍         | 192/5000 [00:00<00:02, 1915.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'tf_idf_vector' in 2.38 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:02<00:00, 2235.64it/s]\n",
      "  4%|▍         | 205/5000 [00:00<00:02, 2049.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'tf_idf_vector' in 2.33 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:02<00:00, 1971.08it/s]\n",
      " 10%|▉         | 485/5000 [00:00<00:02, 2180.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'sentence_embedding_average' in 2.54 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:01<00:00, 2717.77it/s]\n",
      "  1%|▏         | 70/5000 [00:00<00:13, 359.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'sentence_embedding_average' in 1.84 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:16<00:00, 305.03it/s]\n",
      "  2%|▏         | 80/5000 [00:00<00:12, 397.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'sentence_embedding_tf_idf' in 16.4 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:14<00:00, 351.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'sentence_embedding_tf_idf' in 14.22 seconds.\n"
     ]
    }
   ],
   "source": [
    "parallel_sentences.create_embedding_information(\"proc_b_1k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'load_embeddings' in 0.67 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 62/5000 [00:00<00:08, 616.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'load_embeddings' in 0.59 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:07<00:00, 648.30it/s]\n",
      "  1%|▏         | 73/5000 [00:00<00:06, 719.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'word_embeddings' in 7.71 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:08<00:00, 609.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'word_embeddings' in 8.2 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:00<00:00, 275462.62it/s]\n",
      "100%|██████████| 5000/5000 [00:00<00:00, 211615.51it/s]\n",
      "  6%|▌         | 304/5000 [00:00<00:01, 3038.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'create_translation_dictionary' in 24.22 seconds.\n",
      "Finished function: 'translate_words' in 0.02 seconds.\n",
      "Finished function: 'translate_words' in 0.03 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:01<00:00, 2884.19it/s]\n",
      "  6%|▌         | 295/5000 [00:00<00:01, 2949.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'tf_idf_vector' in 1.82 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:01<00:00, 3064.38it/s]\n",
      "  6%|▌         | 311/5000 [00:00<00:01, 3103.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'tf_idf_vector' in 1.73 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:01<00:00, 3000.24it/s]\n",
      "  6%|▌         | 299/5000 [00:00<00:01, 2984.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'sentence_embedding_average' in 1.67 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:01<00:00, 3078.20it/s]\n",
      "  1%|          | 36/5000 [00:00<00:13, 356.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'sentence_embedding_average' in 1.63 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:15<00:00, 318.76it/s]\n",
      "  1%|          | 42/5000 [00:00<00:11, 414.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'sentence_embedding_tf_idf' in 15.69 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:14<00:00, 351.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'sentence_embedding_tf_idf' in 14.23 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "parallel_sentences.create_embedding_information(\"vecmap\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_sentences.preprocessed.to_json(\"../data/interim/preprocessed_data_en_de_testset.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_source</th>\n",
       "      <th>text_source</th>\n",
       "      <th>text_target</th>\n",
       "      <th>id_target</th>\n",
       "      <th>text_preprocessed_source</th>\n",
       "      <th>text_preprocessed_target</th>\n",
       "      <th>text_source_spacy</th>\n",
       "      <th>text_target_spacy</th>\n",
       "      <th>word_embedding_proc_5k_source</th>\n",
       "      <th>word_embedding_proc_5k_target</th>\n",
       "      <th>tf_idf_proc_5k_source</th>\n",
       "      <th>tf_idf_proc_5k_target</th>\n",
       "      <th>word_embedding_proc_b_1k_source</th>\n",
       "      <th>word_embedding_proc_b_1k_target</th>\n",
       "      <th>tf_idf_proc_b_1k_source</th>\n",
       "      <th>tf_idf_proc_b_1k_target</th>\n",
       "      <th>word_embedding_vecmap_source</th>\n",
       "      <th>word_embedding_vecmap_target</th>\n",
       "      <th>tf_idf_vecmap_source</th>\n",
       "      <th>tf_idf_vecmap_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>They must include press freedom, the rule of l...</td>\n",
       "      <td>Dazu gehört Pressefreiheit, dazu gehört Rechts...</td>\n",
       "      <td>0</td>\n",
       "      <td>[must, include, press, freedom, ,, rule, law, ...</td>\n",
       "      <td>[gehört, pressefreiheit, ,, gehört, rechtstaat...</td>\n",
       "      <td>[They, must, include, press, freedom, ,, the, ...</td>\n",
       "      <td>[Dazu, gehört, Pressefreiheit, ,, dazu, gehört...</td>\n",
       "      <td>must   include     press   freedom   ...</td>\n",
       "      <td>hören  pressefreiheit  toleranz  gegen...</td>\n",
       "      <td>{'must': 0.17626342263744035, 'include': 0.235...</td>\n",
       "      <td>{'hören': 0.6660395574174905, 'pressefreiheit'...</td>\n",
       "      <td>must   include     press   freedom   ...</td>\n",
       "      <td>hören  pressefreiheit  toleranz  gegen...</td>\n",
       "      <td>{'must': 0.17626342263744035, 'include': 0.235...</td>\n",
       "      <td>{'hören': 0.6660395574174905, 'pressefreiheit'...</td>\n",
       "      <td>must   include     press   freedom   ...</td>\n",
       "      <td>hören  pressefreiheit  toleranz  gegen...</td>\n",
       "      <td>{'must': 0.17626342263744035, 'include': 0.235...</td>\n",
       "      <td>{'hören': 0.6660395574174905, 'pressefreiheit'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Naturally, there are many other issues as well.</td>\n",
       "      <td>Aber natürlich auch alle weiteren Fragen.</td>\n",
       "      <td>1</td>\n",
       "      <td>[naturally, ,, many, issues, well, .]</td>\n",
       "      <td>[natürlich, weiteren, fragen, .]</td>\n",
       "      <td>[Naturally, ,, there, are, many, other, issues...</td>\n",
       "      <td>[Aber, natürlich, auch, alle, weiteren, Fragen...</td>\n",
       "      <td>naturally      many     issue      well\n",
       "0...</td>\n",
       "      <td>natürlich       all      weit     frage\n",
       "0...</td>\n",
       "      <td>{'naturally': 0.6306460930482953, 'many': 0.46...</td>\n",
       "      <td>{'natürlich': 0.563138440048413, 'all': 0.4521...</td>\n",
       "      <td>naturally      many     issue      well\n",
       "0...</td>\n",
       "      <td>natürlich       all      weit     frage\n",
       "0...</td>\n",
       "      <td>{'naturally': 0.6306460930482953, 'many': 0.46...</td>\n",
       "      <td>{'natürlich': 0.563138440048413, 'all': 0.4521...</td>\n",
       "      <td>naturally      many     issue      well\n",
       "0...</td>\n",
       "      <td>natürlich       all      weit     frage\n",
       "0...</td>\n",
       "      <td>{'naturally': 0.6306460930482953, 'many': 0.46...</td>\n",
       "      <td>{'natürlich': 0.563138440048413, 'all': 0.4521...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Mr President, ladies and gentlemen, Mrs Staune...</td>\n",
       "      <td>Herr Präsident, liebe Kolleginnen und Kollegen...</td>\n",
       "      <td>2</td>\n",
       "      <td>[mr, president, ,, ladies, gentlemen, ,, mrs, ...</td>\n",
       "      <td>[herr, präsident, ,, liebe, kolleginnen, kolle...</td>\n",
       "      <td>[Mr, President, ,, ladies, and, gentlemen, ,, ...</td>\n",
       "      <td>[Herr, Präsident, ,, liebe, Kolleginnen, und, ...</td>\n",
       "      <td>mr  president      lady  gentleman ...</td>\n",
       "      <td>herr  präsident      lieb  kollegin  ...</td>\n",
       "      <td>{'mr': 0.1990752902598333, 'president': 0.2026...</td>\n",
       "      <td>{'herr': 0.1667370642204634, 'präsident': 0.17...</td>\n",
       "      <td>mr  president      lady  gentleman ...</td>\n",
       "      <td>herr  präsident      lieb  kollegin  ...</td>\n",
       "      <td>{'mr': 0.1990752902598333, 'president': 0.2026...</td>\n",
       "      <td>{'herr': 0.1667370642204634, 'präsident': 0.17...</td>\n",
       "      <td>mr  president      lady  gentleman ...</td>\n",
       "      <td>herr  präsident      lieb  kollegin  ...</td>\n",
       "      <td>{'mr': 0.1990752902598333, 'president': 0.2026...</td>\n",
       "      <td>{'herr': 0.1667370642204634, 'präsident': 0.17...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>It is a basic policy that consumer protection ...</td>\n",
       "      <td>Es ist ein politisches Grundprinzip, dass Verb...</td>\n",
       "      <td>3</td>\n",
       "      <td>[basic, policy, consumer, protection, integral...</td>\n",
       "      <td>[politisches, grundprinzip, ,, verbraucherschu...</td>\n",
       "      <td>[It, is, a, basic, policy, that, consumer, pro...</td>\n",
       "      <td>[Es, ist, ein, politisches, Grundprinzip, ,, d...</td>\n",
       "      <td>basic    policy  consumer  protection ...</td>\n",
       "      <td>politisch  grundprinzip  verbraucherschut...</td>\n",
       "      <td>{'basic': 0.21810369565971274, 'policy': 0.142...</td>\n",
       "      <td>{'politisch': 0.2082602674266007, 'grundprinzi...</td>\n",
       "      <td>basic    policy  consumer  protection ...</td>\n",
       "      <td>politisch  grundprinzip  verbraucherschut...</td>\n",
       "      <td>{'basic': 0.21810369565971274, 'policy': 0.142...</td>\n",
       "      <td>{'politisch': 0.2082602674266007, 'grundprinzi...</td>\n",
       "      <td>basic    policy  consumer  protection ...</td>\n",
       "      <td>politisch  grundprinzip  verbraucherschut...</td>\n",
       "      <td>{'basic': 0.21810369565971274, 'policy': 0.142...</td>\n",
       "      <td>{'politisch': 0.2082602674266007, 'grundprinzi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Thank you Mrs Ţicău, we take due note of your ...</td>\n",
       "      <td>Vielen Dank Frau Ţicău, wir werden Ihre Beobac...</td>\n",
       "      <td>4</td>\n",
       "      <td>[thank, mrs, ţicău, ,, take, due, note, observ...</td>\n",
       "      <td>[vielen, dank, frau, ţicău, ,, beobachtung, ge...</td>\n",
       "      <td>[Thank, you, Mrs, Ţicău, ,, we, take, due, not...</td>\n",
       "      <td>[Vielen, Dank, Frau, Ţicău, ,, wir, werden, Ih...</td>\n",
       "      <td>thank       mrs      take       due   ...</td>\n",
       "      <td>dank      frau  beobachtung  gebühren...</td>\n",
       "      <td>{'thank': 0.2859167764901562, 'mrs': 0.3108525...</td>\n",
       "      <td>{'dank': 0.325110383877484, 'frau': 0.22630542...</td>\n",
       "      <td>thank       mrs      take       due   ...</td>\n",
       "      <td>dank      frau  beobachtung  gebühren...</td>\n",
       "      <td>{'thank': 0.2859167764901562, 'mrs': 0.3108525...</td>\n",
       "      <td>{'dank': 0.325110383877484, 'frau': 0.22630542...</td>\n",
       "      <td>thank       mrs      take       due   ...</td>\n",
       "      <td>dank      frau  beobachtung  gebühren...</td>\n",
       "      <td>{'thank': 0.2859167764901562, 'mrs': 0.3108525...</td>\n",
       "      <td>{'dank': 0.325110383877484, 'frau': 0.22630542...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>4995</td>\n",
       "      <td>I told them in one discussion that it looks as...</td>\n",
       "      <td>Ich habe ihnen in einem Gespräch gesagt, dass ...</td>\n",
       "      <td>4995</td>\n",
       "      <td>[told, one, discussion, looks, difficult, get,...</td>\n",
       "      <td>[gespräch, gesagt, ,, aussieht, ,, schwieriger...</td>\n",
       "      <td>[I, told, them, in, one, discussion, that, it,...</td>\n",
       "      <td>[Ich, habe, ihnen, in, einem, Gespräch, gesagt...</td>\n",
       "      <td>tell  discussion      look  difficult...</td>\n",
       "      <td>gespräch     sagen  aussehen  schwierig  ...</td>\n",
       "      <td>{'tell': 0.2336639862054862, 'discussion': 0.2...</td>\n",
       "      <td>{'gespräch': 0.2662775367692719, 'sagen': 0.16...</td>\n",
       "      <td>tell  discussion      look  difficult...</td>\n",
       "      <td>gespräch     sagen  aussehen  schwierig  ...</td>\n",
       "      <td>{'tell': 0.2336639862054862, 'discussion': 0.2...</td>\n",
       "      <td>{'gespräch': 0.2662775367692719, 'sagen': 0.16...</td>\n",
       "      <td>tell  discussion      look  difficult...</td>\n",
       "      <td>gespräch     sagen  aussehen  schwierig  ...</td>\n",
       "      <td>{'tell': 0.2336639862054862, 'discussion': 0.2...</td>\n",
       "      <td>{'gespräch': 0.2662775367692719, 'sagen': 0.16...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>4996</td>\n",
       "      <td>Is the European Union right to be proud of the...</td>\n",
       "      <td>Hat die Europäische Union Anlaß, auf humanitär...</td>\n",
       "      <td>4996</td>\n",
       "      <td>[european, union, right, proud, humanitarian, ...</td>\n",
       "      <td>[europäische, union, anlaß, ,, humanitäre, maß...</td>\n",
       "      <td>[Is, the, European, Union, right, to, be, prou...</td>\n",
       "      <td>[Hat, die, Europäische, Union, Anlaß, ,, auf, ...</td>\n",
       "      <td>european     union     right     proud  h...</td>\n",
       "      <td>europäisch     union     anlaß  maßnahme ...</td>\n",
       "      <td>{'european': 0.12302883215168699, 'union': 0.1...</td>\n",
       "      <td>{'europäisch': 0.1675379646449199, 'union': 0....</td>\n",
       "      <td>european     union     right     proud  h...</td>\n",
       "      <td>europäisch     union     anlaß  maßnahme ...</td>\n",
       "      <td>{'european': 0.12302883215168699, 'union': 0.1...</td>\n",
       "      <td>{'europäisch': 0.1675379646449199, 'union': 0....</td>\n",
       "      <td>european     union     right     proud  h...</td>\n",
       "      <td>europäisch     union     anlaß  maßnahme ...</td>\n",
       "      <td>{'european': 0.12302883215168699, 'union': 0.1...</td>\n",
       "      <td>{'europäisch': 0.1675379646449199, 'union': 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>4997</td>\n",
       "      <td>However, this information would concern only s...</td>\n",
       "      <td>Solche Hinweise hätten aber nur bei der Kennze...</td>\n",
       "      <td>4997</td>\n",
       "      <td>[however, ,, information, would, concern, subs...</td>\n",
       "      <td>[hinweise, hätten, kennzeichnung, gesundheitsg...</td>\n",
       "      <td>[However, ,, this, information, would, concern...</td>\n",
       "      <td>[Solche, Hinweise, hätten, aber, nur, bei, der...</td>\n",
       "      <td>however  information     would   concern...</td>\n",
       "      <td>solch   hinweis  kennzeichnung     sto...</td>\n",
       "      <td>{'however': 0.20587812620381066, 'information'...</td>\n",
       "      <td>{'solch': 0.24858968001616202, 'hinweis': 0.28...</td>\n",
       "      <td>however  information     would   concern...</td>\n",
       "      <td>solch   hinweis  kennzeichnung     sto...</td>\n",
       "      <td>{'however': 0.20587812620381066, 'information'...</td>\n",
       "      <td>{'solch': 0.24858968001616202, 'hinweis': 0.28...</td>\n",
       "      <td>however  information     would   concern...</td>\n",
       "      <td>solch   hinweis  kennzeichnung     sto...</td>\n",
       "      <td>{'however': 0.20587812620381066, 'information'...</td>\n",
       "      <td>{'solch': 0.24858968001616202, 'hinweis': 0.28...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>4998</td>\n",
       "      <td>Earlier this week, Jan Pronk, the former UN en...</td>\n",
       "      <td>Anfang dieser Woche gab Jan Pronk, der ehemali...</td>\n",
       "      <td>4998</td>\n",
       "      <td>[earlier, week, ,, jan, pronk, ,, former, un, ...</td>\n",
       "      <td>[anfang, woche, gab, jan, pronk, ,, ehemalige,...</td>\n",
       "      <td>[Earlier, this, week, ,, Jan, Pronk, ,, the, f...</td>\n",
       "      <td>[Anfang, dieser, Woche, gab, Jan, Pronk, ,, de...</td>\n",
       "      <td>early      week       jan    former   ...</td>\n",
       "      <td>anfang     woche     geben       jan  e...</td>\n",
       "      <td>{'early': 0.19923117371332466, 'week': 0.20036...</td>\n",
       "      <td>{'anfang': 0.21764427103233672, 'woche': 0.206...</td>\n",
       "      <td>early      week       jan    former   ...</td>\n",
       "      <td>anfang     woche     geben       jan  e...</td>\n",
       "      <td>{'early': 0.19923117371332466, 'week': 0.20036...</td>\n",
       "      <td>{'anfang': 0.21764427103233672, 'woche': 0.206...</td>\n",
       "      <td>early      week       jan    former   ...</td>\n",
       "      <td>anfang     woche     geben       jan  e...</td>\n",
       "      <td>{'early': 0.19923117371332466, 'week': 0.20036...</td>\n",
       "      <td>{'anfang': 0.21764427103233672, 'woche': 0.206...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>4999</td>\n",
       "      <td>The initial phase of a project is crucial from...</td>\n",
       "      <td>Die Anfangsphase eines Projekts ist aus qualit...</td>\n",
       "      <td>4999</td>\n",
       "      <td>[initial, phase, project, crucial, qualitative...</td>\n",
       "      <td>[anfangsphase, projekts, qualitativer, sicht, ...</td>\n",
       "      <td>[The, initial, phase, of, a, project, is, cruc...</td>\n",
       "      <td>[Die, Anfangsphase, eines, Projekts, ist, aus,...</td>\n",
       "      <td>initial     phase   project   crucial  q...</td>\n",
       "      <td>anfangsphase   projekt  qualitativ     si...</td>\n",
       "      <td>{'initial': 0.2585134481630949, 'phase': 0.251...</td>\n",
       "      <td>{'anfangsphase': 0.3156404203991046, 'projekt'...</td>\n",
       "      <td>initial     phase   project   crucial  q...</td>\n",
       "      <td>anfangsphase   projekt  qualitativ     si...</td>\n",
       "      <td>{'initial': 0.2585134481630949, 'phase': 0.251...</td>\n",
       "      <td>{'anfangsphase': 0.3156404203991046, 'projekt'...</td>\n",
       "      <td>initial     phase   project   crucial  q...</td>\n",
       "      <td>anfangsphase   projekt  qualitativ     si...</td>\n",
       "      <td>{'initial': 0.2585134481630949, 'phase': 0.251...</td>\n",
       "      <td>{'anfangsphase': 0.3156404203991046, 'projekt'...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id_source                                        text_source  \\\n",
       "0             0  They must include press freedom, the rule of l...   \n",
       "1             1    Naturally, there are many other issues as well.   \n",
       "2             2  Mr President, ladies and gentlemen, Mrs Staune...   \n",
       "3             3  It is a basic policy that consumer protection ...   \n",
       "4             4  Thank you Mrs Ţicău, we take due note of your ...   \n",
       "...         ...                                                ...   \n",
       "4995       4995  I told them in one discussion that it looks as...   \n",
       "4996       4996  Is the European Union right to be proud of the...   \n",
       "4997       4997  However, this information would concern only s...   \n",
       "4998       4998  Earlier this week, Jan Pronk, the former UN en...   \n",
       "4999       4999  The initial phase of a project is crucial from...   \n",
       "\n",
       "                                            text_target  id_target  \\\n",
       "0     Dazu gehört Pressefreiheit, dazu gehört Rechts...          0   \n",
       "1             Aber natürlich auch alle weiteren Fragen.          1   \n",
       "2     Herr Präsident, liebe Kolleginnen und Kollegen...          2   \n",
       "3     Es ist ein politisches Grundprinzip, dass Verb...          3   \n",
       "4     Vielen Dank Frau Ţicău, wir werden Ihre Beobac...          4   \n",
       "...                                                 ...        ...   \n",
       "4995  Ich habe ihnen in einem Gespräch gesagt, dass ...       4995   \n",
       "4996  Hat die Europäische Union Anlaß, auf humanitär...       4996   \n",
       "4997  Solche Hinweise hätten aber nur bei der Kennze...       4997   \n",
       "4998  Anfang dieser Woche gab Jan Pronk, der ehemali...       4998   \n",
       "4999  Die Anfangsphase eines Projekts ist aus qualit...       4999   \n",
       "\n",
       "                               text_preprocessed_source  \\\n",
       "0     [must, include, press, freedom, ,, rule, law, ...   \n",
       "1                 [naturally, ,, many, issues, well, .]   \n",
       "2     [mr, president, ,, ladies, gentlemen, ,, mrs, ...   \n",
       "3     [basic, policy, consumer, protection, integral...   \n",
       "4     [thank, mrs, ţicău, ,, take, due, note, observ...   \n",
       "...                                                 ...   \n",
       "4995  [told, one, discussion, looks, difficult, get,...   \n",
       "4996  [european, union, right, proud, humanitarian, ...   \n",
       "4997  [however, ,, information, would, concern, subs...   \n",
       "4998  [earlier, week, ,, jan, pronk, ,, former, un, ...   \n",
       "4999  [initial, phase, project, crucial, qualitative...   \n",
       "\n",
       "                               text_preprocessed_target  \\\n",
       "0     [gehört, pressefreiheit, ,, gehört, rechtstaat...   \n",
       "1                      [natürlich, weiteren, fragen, .]   \n",
       "2     [herr, präsident, ,, liebe, kolleginnen, kolle...   \n",
       "3     [politisches, grundprinzip, ,, verbraucherschu...   \n",
       "4     [vielen, dank, frau, ţicău, ,, beobachtung, ge...   \n",
       "...                                                 ...   \n",
       "4995  [gespräch, gesagt, ,, aussieht, ,, schwieriger...   \n",
       "4996  [europäische, union, anlaß, ,, humanitäre, maß...   \n",
       "4997  [hinweise, hätten, kennzeichnung, gesundheitsg...   \n",
       "4998  [anfang, woche, gab, jan, pronk, ,, ehemalige,...   \n",
       "4999  [anfangsphase, projekts, qualitativer, sicht, ...   \n",
       "\n",
       "                                      text_source_spacy  \\\n",
       "0     [They, must, include, press, freedom, ,, the, ...   \n",
       "1     [Naturally, ,, there, are, many, other, issues...   \n",
       "2     [Mr, President, ,, ladies, and, gentlemen, ,, ...   \n",
       "3     [It, is, a, basic, policy, that, consumer, pro...   \n",
       "4     [Thank, you, Mrs, Ţicău, ,, we, take, due, not...   \n",
       "...                                                 ...   \n",
       "4995  [I, told, them, in, one, discussion, that, it,...   \n",
       "4996  [Is, the, European, Union, right, to, be, prou...   \n",
       "4997  [However, ,, this, information, would, concern...   \n",
       "4998  [Earlier, this, week, ,, Jan, Pronk, ,, the, f...   \n",
       "4999  [The, initial, phase, of, a, project, is, cruc...   \n",
       "\n",
       "                                      text_target_spacy  \\\n",
       "0     [Dazu, gehört, Pressefreiheit, ,, dazu, gehört...   \n",
       "1     [Aber, natürlich, auch, alle, weiteren, Fragen...   \n",
       "2     [Herr, Präsident, ,, liebe, Kolleginnen, und, ...   \n",
       "3     [Es, ist, ein, politisches, Grundprinzip, ,, d...   \n",
       "4     [Vielen, Dank, Frau, Ţicău, ,, wir, werden, Ih...   \n",
       "...                                                 ...   \n",
       "4995  [Ich, habe, ihnen, in, einem, Gespräch, gesagt...   \n",
       "4996  [Hat, die, Europäische, Union, Anlaß, ,, auf, ...   \n",
       "4997  [Solche, Hinweise, hätten, aber, nur, bei, der...   \n",
       "4998  [Anfang, dieser, Woche, gab, Jan, Pronk, ,, de...   \n",
       "4999  [Die, Anfangsphase, eines, Projekts, ist, aus,...   \n",
       "\n",
       "                          word_embedding_proc_5k_source  \\\n",
       "0              must   include     press   freedom   ...   \n",
       "1          naturally      many     issue      well\n",
       "0...   \n",
       "2                mr  president      lady  gentleman ...   \n",
       "3             basic    policy  consumer  protection ...   \n",
       "4             thank       mrs      take       due   ...   \n",
       "...                                                 ...   \n",
       "4995           tell  discussion      look  difficult...   \n",
       "4996       european     union     right     proud  h...   \n",
       "4997        however  information     would   concern...   \n",
       "4998          early      week       jan    former   ...   \n",
       "4999        initial     phase   project   crucial  q...   \n",
       "\n",
       "                          word_embedding_proc_5k_target  \\\n",
       "0             hören  pressefreiheit  toleranz  gegen...   \n",
       "1          natürlich       all      weit     frage\n",
       "0...   \n",
       "2              herr  präsident      lieb  kollegin  ...   \n",
       "3          politisch  grundprinzip  verbraucherschut...   \n",
       "4              dank      frau  beobachtung  gebühren...   \n",
       "...                                                 ...   \n",
       "4995       gespräch     sagen  aussehen  schwierig  ...   \n",
       "4996       europäisch     union     anlaß  maßnahme ...   \n",
       "4997          solch   hinweis  kennzeichnung     sto...   \n",
       "4998         anfang     woche     geben       jan  e...   \n",
       "4999       anfangsphase   projekt  qualitativ     si...   \n",
       "\n",
       "                                  tf_idf_proc_5k_source  \\\n",
       "0     {'must': 0.17626342263744035, 'include': 0.235...   \n",
       "1     {'naturally': 0.6306460930482953, 'many': 0.46...   \n",
       "2     {'mr': 0.1990752902598333, 'president': 0.2026...   \n",
       "3     {'basic': 0.21810369565971274, 'policy': 0.142...   \n",
       "4     {'thank': 0.2859167764901562, 'mrs': 0.3108525...   \n",
       "...                                                 ...   \n",
       "4995  {'tell': 0.2336639862054862, 'discussion': 0.2...   \n",
       "4996  {'european': 0.12302883215168699, 'union': 0.1...   \n",
       "4997  {'however': 0.20587812620381066, 'information'...   \n",
       "4998  {'early': 0.19923117371332466, 'week': 0.20036...   \n",
       "4999  {'initial': 0.2585134481630949, 'phase': 0.251...   \n",
       "\n",
       "                                  tf_idf_proc_5k_target  \\\n",
       "0     {'hören': 0.6660395574174905, 'pressefreiheit'...   \n",
       "1     {'natürlich': 0.563138440048413, 'all': 0.4521...   \n",
       "2     {'herr': 0.1667370642204634, 'präsident': 0.17...   \n",
       "3     {'politisch': 0.2082602674266007, 'grundprinzi...   \n",
       "4     {'dank': 0.325110383877484, 'frau': 0.22630542...   \n",
       "...                                                 ...   \n",
       "4995  {'gespräch': 0.2662775367692719, 'sagen': 0.16...   \n",
       "4996  {'europäisch': 0.1675379646449199, 'union': 0....   \n",
       "4997  {'solch': 0.24858968001616202, 'hinweis': 0.28...   \n",
       "4998  {'anfang': 0.21764427103233672, 'woche': 0.206...   \n",
       "4999  {'anfangsphase': 0.3156404203991046, 'projekt'...   \n",
       "\n",
       "                        word_embedding_proc_b_1k_source  \\\n",
       "0              must   include     press   freedom   ...   \n",
       "1          naturally      many     issue      well\n",
       "0...   \n",
       "2                mr  president      lady  gentleman ...   \n",
       "3             basic    policy  consumer  protection ...   \n",
       "4             thank       mrs      take       due   ...   \n",
       "...                                                 ...   \n",
       "4995           tell  discussion      look  difficult...   \n",
       "4996       european     union     right     proud  h...   \n",
       "4997        however  information     would   concern...   \n",
       "4998          early      week       jan    former   ...   \n",
       "4999        initial     phase   project   crucial  q...   \n",
       "\n",
       "                        word_embedding_proc_b_1k_target  \\\n",
       "0             hören  pressefreiheit  toleranz  gegen...   \n",
       "1          natürlich       all      weit     frage\n",
       "0...   \n",
       "2              herr  präsident      lieb  kollegin  ...   \n",
       "3          politisch  grundprinzip  verbraucherschut...   \n",
       "4              dank      frau  beobachtung  gebühren...   \n",
       "...                                                 ...   \n",
       "4995       gespräch     sagen  aussehen  schwierig  ...   \n",
       "4996       europäisch     union     anlaß  maßnahme ...   \n",
       "4997          solch   hinweis  kennzeichnung     sto...   \n",
       "4998         anfang     woche     geben       jan  e...   \n",
       "4999       anfangsphase   projekt  qualitativ     si...   \n",
       "\n",
       "                                tf_idf_proc_b_1k_source  \\\n",
       "0     {'must': 0.17626342263744035, 'include': 0.235...   \n",
       "1     {'naturally': 0.6306460930482953, 'many': 0.46...   \n",
       "2     {'mr': 0.1990752902598333, 'president': 0.2026...   \n",
       "3     {'basic': 0.21810369565971274, 'policy': 0.142...   \n",
       "4     {'thank': 0.2859167764901562, 'mrs': 0.3108525...   \n",
       "...                                                 ...   \n",
       "4995  {'tell': 0.2336639862054862, 'discussion': 0.2...   \n",
       "4996  {'european': 0.12302883215168699, 'union': 0.1...   \n",
       "4997  {'however': 0.20587812620381066, 'information'...   \n",
       "4998  {'early': 0.19923117371332466, 'week': 0.20036...   \n",
       "4999  {'initial': 0.2585134481630949, 'phase': 0.251...   \n",
       "\n",
       "                                tf_idf_proc_b_1k_target  \\\n",
       "0     {'hören': 0.6660395574174905, 'pressefreiheit'...   \n",
       "1     {'natürlich': 0.563138440048413, 'all': 0.4521...   \n",
       "2     {'herr': 0.1667370642204634, 'präsident': 0.17...   \n",
       "3     {'politisch': 0.2082602674266007, 'grundprinzi...   \n",
       "4     {'dank': 0.325110383877484, 'frau': 0.22630542...   \n",
       "...                                                 ...   \n",
       "4995  {'gespräch': 0.2662775367692719, 'sagen': 0.16...   \n",
       "4996  {'europäisch': 0.1675379646449199, 'union': 0....   \n",
       "4997  {'solch': 0.24858968001616202, 'hinweis': 0.28...   \n",
       "4998  {'anfang': 0.21764427103233672, 'woche': 0.206...   \n",
       "4999  {'anfangsphase': 0.3156404203991046, 'projekt'...   \n",
       "\n",
       "                           word_embedding_vecmap_source  \\\n",
       "0              must   include     press   freedom   ...   \n",
       "1          naturally      many     issue      well\n",
       "0...   \n",
       "2                mr  president      lady  gentleman ...   \n",
       "3             basic    policy  consumer  protection ...   \n",
       "4             thank       mrs      take       due   ...   \n",
       "...                                                 ...   \n",
       "4995           tell  discussion      look  difficult...   \n",
       "4996       european     union     right     proud  h...   \n",
       "4997        however  information     would   concern...   \n",
       "4998          early      week       jan    former   ...   \n",
       "4999        initial     phase   project   crucial  q...   \n",
       "\n",
       "                           word_embedding_vecmap_target  \\\n",
       "0             hören  pressefreiheit  toleranz  gegen...   \n",
       "1          natürlich       all      weit     frage\n",
       "0...   \n",
       "2              herr  präsident      lieb  kollegin  ...   \n",
       "3          politisch  grundprinzip  verbraucherschut...   \n",
       "4              dank      frau  beobachtung  gebühren...   \n",
       "...                                                 ...   \n",
       "4995       gespräch     sagen  aussehen  schwierig  ...   \n",
       "4996       europäisch     union     anlaß  maßnahme ...   \n",
       "4997          solch   hinweis  kennzeichnung     sto...   \n",
       "4998         anfang     woche     geben       jan  e...   \n",
       "4999       anfangsphase   projekt  qualitativ     si...   \n",
       "\n",
       "                                   tf_idf_vecmap_source  \\\n",
       "0     {'must': 0.17626342263744035, 'include': 0.235...   \n",
       "1     {'naturally': 0.6306460930482953, 'many': 0.46...   \n",
       "2     {'mr': 0.1990752902598333, 'president': 0.2026...   \n",
       "3     {'basic': 0.21810369565971274, 'policy': 0.142...   \n",
       "4     {'thank': 0.2859167764901562, 'mrs': 0.3108525...   \n",
       "...                                                 ...   \n",
       "4995  {'tell': 0.2336639862054862, 'discussion': 0.2...   \n",
       "4996  {'european': 0.12302883215168699, 'union': 0.1...   \n",
       "4997  {'however': 0.20587812620381066, 'information'...   \n",
       "4998  {'early': 0.19923117371332466, 'week': 0.20036...   \n",
       "4999  {'initial': 0.2585134481630949, 'phase': 0.251...   \n",
       "\n",
       "                                   tf_idf_vecmap_target  \n",
       "0     {'hören': 0.6660395574174905, 'pressefreiheit'...  \n",
       "1     {'natürlich': 0.563138440048413, 'all': 0.4521...  \n",
       "2     {'herr': 0.1667370642204634, 'präsident': 0.17...  \n",
       "3     {'politisch': 0.2082602674266007, 'grundprinzi...  \n",
       "4     {'dank': 0.325110383877484, 'frau': 0.22630542...  \n",
       "...                                                 ...  \n",
       "4995  {'gespräch': 0.2662775367692719, 'sagen': 0.16...  \n",
       "4996  {'europäisch': 0.1675379646449199, 'union': 0....  \n",
       "4997  {'solch': 0.24858968001616202, 'hinweis': 0.28...  \n",
       "4998  {'anfang': 0.21764427103233672, 'woche': 0.206...  \n",
       "4999  {'anfangsphase': 0.3156404203991046, 'projekt'...  \n",
       "\n",
       "[5000 rows x 20 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parallel_sentences.dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_source</th>\n",
       "      <th>id_target</th>\n",
       "      <th>token_preprocessed_embedding_source</th>\n",
       "      <th>token_preprocessed_embedding_target</th>\n",
       "      <th>Translation</th>\n",
       "      <th>number_punctuations_total_source</th>\n",
       "      <th>number_punctuations_total_target</th>\n",
       "      <th>number_words_source</th>\n",
       "      <th>number_words_target</th>\n",
       "      <th>number_unique_words_source</th>\n",
       "      <th>...</th>\n",
       "      <th>sentence_embedding_average_proc_b_1k_source</th>\n",
       "      <th>sentence_embedding_average_proc_b_1k_target</th>\n",
       "      <th>sentence_embedding_tf_idf_proc_b_1k_source</th>\n",
       "      <th>sentence_embedding_tf_idf_proc_b_1k_target</th>\n",
       "      <th>translated_to_target_vecmap_source</th>\n",
       "      <th>translated_to_source_vecmap_target</th>\n",
       "      <th>sentence_embedding_average_vecmap_source</th>\n",
       "      <th>sentence_embedding_average_vecmap_target</th>\n",
       "      <th>sentence_embedding_tf_idf_vecmap_source</th>\n",
       "      <th>sentence_embedding_tf_idf_vecmap_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[must, include, press, freedom, rule, law, als...</td>\n",
       "      <td>[hören, pressefreiheit, hören, rechtstaatlichk...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>[[-0.021971818561164234, 0.011474978608580736,...</td>\n",
       "      <td>[[-0.04290382231452635, 0.046113511946584494, ...</td>\n",
       "      <td>[[-0.007066868075968942, 0.005607346065645118,...</td>\n",
       "      <td>[[-0.013969529264133333, 0.018536083310556985,...</td>\n",
       "      <td>[müssen, zählen, nachdruck, freiheit, facto, v...</td>\n",
       "      <td>[listen, censorship, listen, listen, tolerance...</td>\n",
       "      <td>[[0.20800741131489092, -0.03718488272548152, 0...</td>\n",
       "      <td>[[0.1708042360842228, -0.05323345214128494, 0....</td>\n",
       "      <td>[[0.05308659109689821, -0.012124574781091323, ...</td>\n",
       "      <td>[[0.053098278212977024, -0.004806572931137665,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[naturally, many, issue, well]</td>\n",
       "      <td>[natürlich, all, weit, frage]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>[[-0.07873985217884183, -0.00878874131012708, ...</td>\n",
       "      <td>[[-0.05510551622137427, 0.019210652448236942, ...</td>\n",
       "      <td>[[-0.039775796329763254, -0.004100882681543145...</td>\n",
       "      <td>[[-0.026569483773157737, 0.009380328691558417,...</td>\n",
       "      <td>[natürlicherweise, zahlreiche, problematik, eb...</td>\n",
       "      <td>[obviously, amazing, far, question]</td>\n",
       "      <td>[[0.33323322981595993, -0.013636057265102863, ...</td>\n",
       "      <td>[[0.31983064115047455, -0.012548421160317957, ...</td>\n",
       "      <td>[[0.16483797091322513, -0.009893845352128313, ...</td>\n",
       "      <td>[[0.1630749418803205, -0.007294520385128128, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>[mr, president, lady, gentleman, mrs, stauner,...</td>\n",
       "      <td>[herr, präsident, lieb, kollegin, kollege, ber...</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>[[-0.05349120330065489, 0.038198266993276775, ...</td>\n",
       "      <td>[[-0.07230656314641237, 0.04887153177211682, -...</td>\n",
       "      <td>[[-0.013956825976806853, 0.010524739055448654,...</td>\n",
       "      <td>[[-0.01840957375747747, 0.011432228637823928, ...</td>\n",
       "      <td>[herrn, präsident, mary, vornehm, mary, berich...</td>\n",
       "      <td>[lord, president, dear, mrs, colleague, report...</td>\n",
       "      <td>[[0.13944147573783994, 0.14624346122145654, 0....</td>\n",
       "      <td>[[0.13265844124058881, 0.13158888618151346, 0....</td>\n",
       "      <td>[[0.039298395795571026, 0.03915855198838343, 0...</td>\n",
       "      <td>[[0.03935996898779049, 0.029764392773049386, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>[basic, policy, consumer, protection, integral...</td>\n",
       "      <td>[politisch, grundprinzip, verbraucherschutz, i...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>[[-0.0196231756020676, -0.00987706098451533, -...</td>\n",
       "      <td>[[-0.05054771602153778, 0.00880683995783329, -...</td>\n",
       "      <td>[[-0.006306732065082907, -0.002367327419645338...</td>\n",
       "      <td>[[-0.014033250896603547, 0.0007865312866477389...</td>\n",
       "      <td>[grundlegende, wirtschaftspolitik, verbraucher...</td>\n",
       "      <td>[politically, principle, consumer, integral, p...</td>\n",
       "      <td>[[0.2640666257251393, -0.0853267332369631, 0.0...</td>\n",
       "      <td>[[0.18233205378055573, -0.06059268582612276, 0...</td>\n",
       "      <td>[[0.07169493797530326, -0.026357206451051805, ...</td>\n",
       "      <td>[[0.05362438231735067, -0.02147952806897634, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>[thank, mrs, ţicău, take, due, note, observation]</td>\n",
       "      <td>[dank, frau, ţicău, beobachtung, gebühren, bea...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>[[-0.016065427257368963, 0.06924035431196292, ...</td>\n",
       "      <td>[[-0.06597628220915794, 0.033844958432018755, ...</td>\n",
       "      <td>[[-0.004266745919428459, 0.020920746568999327,...</td>\n",
       "      <td>[[-0.02459387689770779, 0.009592057857595168, ...</td>\n",
       "      <td>[danke, mary, nehmen, aufgrund, anmerkung, beo...</td>\n",
       "      <td>[thank, daughter, observation, pay, apply]</td>\n",
       "      <td>[[0.2628776244819164, 0.07202177572374542, 0.1...</td>\n",
       "      <td>[[0.2281290665268898, 0.025979317165911196, 0....</td>\n",
       "      <td>[[0.08939328089640149, 0.01932059090826744, 0....</td>\n",
       "      <td>[[0.09774504782369009, -0.005629674603903475, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>4995</td>\n",
       "      <td>4995</td>\n",
       "      <td>[tell, discussion, look, difficult, get, good,...</td>\n",
       "      <td>[gespräch, sagen, aussehen, schwierig, peer, r...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>19</td>\n",
       "      <td>16</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>[[-0.03781758025029881, 0.04561582228375806, -...</td>\n",
       "      <td>[[-0.006831209890411368, 0.022711734254179255,...</td>\n",
       "      <td>[[-0.008710065448488858, 0.010466450631324158,...</td>\n",
       "      <td>[[5.6516836084291216e-05, 0.005375066987057035...</td>\n",
       "      <td>[sagen, konsens, schauen, schwierig, bekommen,...</td>\n",
       "      <td>[interview, say, shape, difficult, peer, good,...</td>\n",
       "      <td>[[0.24532438007493815, 0.004404090862307284, 0...</td>\n",
       "      <td>[[0.1969107918183519, 0.011512659090970243, 0....</td>\n",
       "      <td>[[0.05863010090177196, 0.004771032047790131, 0...</td>\n",
       "      <td>[[0.048826807176762056, 0.005519456655719748, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>4996</td>\n",
       "      <td>4996</td>\n",
       "      <td>[european, union, right, proud, humanitarian, ...</td>\n",
       "      <td>[europäisch, union, anlaß, humanitär, maßnahme...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>[[-0.03594180399721319, 0.015256671806458722, ...</td>\n",
       "      <td>[[-0.03823526995256543, 0.015385312959551811, ...</td>\n",
       "      <td>[[-0.011011873583563005, 0.0016257848030860106...</td>\n",
       "      <td>[[-0.009254192504192075, 0.007094162098472008,...</td>\n",
       "      <td>[europäische, union, linke, stolz, humanitäre,...</td>\n",
       "      <td>[european, union, acknowledgement, preventativ...</td>\n",
       "      <td>[[0.1838966760445725, -0.04385858147659085, 0....</td>\n",
       "      <td>[[0.1643218114040792, -0.023434823495335877, 0...</td>\n",
       "      <td>[[0.052804342223652274, -0.003989617522633716,...</td>\n",
       "      <td>[[0.04534390128151565, -0.001144711801600671, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>4997</td>\n",
       "      <td>4997</td>\n",
       "      <td>[however, information, would, concern, substan...</td>\n",
       "      <td>[solch, hinweis, kennzeichnung, gesundheitsgef...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>[[-0.06054617161862552, -0.032334873627405614,...</td>\n",
       "      <td>[[0.0004524181131273508, 0.0363775837700814, -...</td>\n",
       "      <td>[[-0.017964938149843405, -0.006479997166303774...</td>\n",
       "      <td>[[0.0009744391006637598, 0.013281651314851739,...</td>\n",
       "      <td>[jedoch, information, müssten, bedenken, subst...</td>\n",
       "      <td>[incredibly, explanation, labelling, substance...</td>\n",
       "      <td>[[0.33515107817947865, -0.048095799633301795, ...</td>\n",
       "      <td>[[0.29965757131576537, -0.055498963221907616, ...</td>\n",
       "      <td>[[0.09410211836024641, -0.024247944199762585, ...</td>\n",
       "      <td>[[0.093213372315576, -0.012954907841144938, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>4998</td>\n",
       "      <td>4998</td>\n",
       "      <td>[early, week, jan, pronk, former, un, envoy, s...</td>\n",
       "      <td>[anfang, woche, geben, jan, pronk, ehemalig, u...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>[[-0.0497313872911036, 0.03800346574280411, -0...</td>\n",
       "      <td>[[-0.03595951018441054, 0.04274792379389206, -...</td>\n",
       "      <td>[[-0.01482810741283633, 0.010372276755398773, ...</td>\n",
       "      <td>[[-0.011945683411114657, 0.01196331349841016, ...</td>\n",
       "      <td>[frühe, woche, that, ehemalig, uno, botschafte...</td>\n",
       "      <td>[beginning, week, give, anyway, former, sudan,...</td>\n",
       "      <td>[[0.06874247279483825, 0.09173224462817113, 0....</td>\n",
       "      <td>[[0.10321165372927983, 0.0371778037192093, 0.1...</td>\n",
       "      <td>[[0.008600220600305348, 0.01612903007741604, 0...</td>\n",
       "      <td>[[0.010701002245010907, 4.584188879966058e-05,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>4999</td>\n",
       "      <td>4999</td>\n",
       "      <td>[initial, phase, project, crucial, qualitative...</td>\n",
       "      <td>[anfangsphase, projekt, qualitativ, sicht, äuß...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>[[-0.023697290373092983, -0.003114733903203159...</td>\n",
       "      <td>[[-0.02371140491283898, 0.0018028813148183481,...</td>\n",
       "      <td>[[-0.004981590437542192, 1.7513979545761324e-0...</td>\n",
       "      <td>[[-0.00557969810802499, 0.0008041093101485405,...</td>\n",
       "      <td>[verzögerung, phase, projekt, entscheidende, q...</td>\n",
       "      <td>[beginning, project, quality, viewpoint, respo...</td>\n",
       "      <td>[[0.29209267161786556, -0.0680284810368903, 0....</td>\n",
       "      <td>[[0.3182435408234596, -0.06927407572844199, 0....</td>\n",
       "      <td>[[0.06854605026579885, -0.016785477247572626, ...</td>\n",
       "      <td>[[0.07786661168430384, -0.01763608023010569, 0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 111 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id_source  id_target                token_preprocessed_embedding_source  \\\n",
       "0             0          0  [must, include, press, freedom, rule, law, als...   \n",
       "1             1          1                     [naturally, many, issue, well]   \n",
       "2             2          2  [mr, president, lady, gentleman, mrs, stauner,...   \n",
       "3             3          3  [basic, policy, consumer, protection, integral...   \n",
       "4             4          4  [thank, mrs, ţicău, take, due, note, observation]   \n",
       "...         ...        ...                                                ...   \n",
       "4995       4995       4995  [tell, discussion, look, difficult, get, good,...   \n",
       "4996       4996       4996  [european, union, right, proud, humanitarian, ...   \n",
       "4997       4997       4997  [however, information, would, concern, substan...   \n",
       "4998       4998       4998  [early, week, jan, pronk, former, un, envoy, s...   \n",
       "4999       4999       4999  [initial, phase, project, crucial, qualitative...   \n",
       "\n",
       "                    token_preprocessed_embedding_target  Translation  \\\n",
       "0     [hören, pressefreiheit, hören, rechtstaatlichk...            1   \n",
       "1                         [natürlich, all, weit, frage]            1   \n",
       "2     [herr, präsident, lieb, kollegin, kollege, ber...            1   \n",
       "3     [politisch, grundprinzip, verbraucherschutz, i...            1   \n",
       "4     [dank, frau, ţicău, beobachtung, gebühren, bea...            1   \n",
       "...                                                 ...          ...   \n",
       "4995  [gespräch, sagen, aussehen, schwierig, peer, r...            1   \n",
       "4996  [europäisch, union, anlaß, humanitär, maßnahme...            1   \n",
       "4997  [solch, hinweis, kennzeichnung, gesundheitsgef...            1   \n",
       "4998  [anfang, woche, geben, jan, pronk, ehemalig, u...            1   \n",
       "4999  [anfangsphase, projekt, qualitativ, sicht, äuß...            1   \n",
       "\n",
       "      number_punctuations_total_source  number_punctuations_total_target  \\\n",
       "0                                    2                                 2   \n",
       "1                                    1                                 0   \n",
       "2                                    5                                 4   \n",
       "3                                    0                                 2   \n",
       "4                                    1                                 1   \n",
       "...                                ...                               ...   \n",
       "4995                                 0                                 5   \n",
       "4996                                 1                                 3   \n",
       "4997                                 2                                 0   \n",
       "4998                                 3                                 2   \n",
       "4999                                 0                                 2   \n",
       "\n",
       "      number_words_source  number_words_target  number_unique_words_source  \\\n",
       "0                      13                   10                          13   \n",
       "1                       4                    3                           4   \n",
       "2                      12                   13                          12   \n",
       "3                      16                   11                          11   \n",
       "4                       7                    7                           7   \n",
       "...                   ...                  ...                         ...   \n",
       "4995                   19                   16                          19   \n",
       "4996                   12                   12                          11   \n",
       "4997                    9                    8                           8   \n",
       "4998                   14                   13                          13   \n",
       "4999                   17                   15                          16   \n",
       "\n",
       "      ...        sentence_embedding_average_proc_b_1k_source  \\\n",
       "0     ...  [[-0.021971818561164234, 0.011474978608580736,...   \n",
       "1     ...  [[-0.07873985217884183, -0.00878874131012708, ...   \n",
       "2     ...  [[-0.05349120330065489, 0.038198266993276775, ...   \n",
       "3     ...  [[-0.0196231756020676, -0.00987706098451533, -...   \n",
       "4     ...  [[-0.016065427257368963, 0.06924035431196292, ...   \n",
       "...   ...                                                ...   \n",
       "4995  ...  [[-0.03781758025029881, 0.04561582228375806, -...   \n",
       "4996  ...  [[-0.03594180399721319, 0.015256671806458722, ...   \n",
       "4997  ...  [[-0.06054617161862552, -0.032334873627405614,...   \n",
       "4998  ...  [[-0.0497313872911036, 0.03800346574280411, -0...   \n",
       "4999  ...  [[-0.023697290373092983, -0.003114733903203159...   \n",
       "\n",
       "            sentence_embedding_average_proc_b_1k_target  \\\n",
       "0     [[-0.04290382231452635, 0.046113511946584494, ...   \n",
       "1     [[-0.05510551622137427, 0.019210652448236942, ...   \n",
       "2     [[-0.07230656314641237, 0.04887153177211682, -...   \n",
       "3     [[-0.05054771602153778, 0.00880683995783329, -...   \n",
       "4     [[-0.06597628220915794, 0.033844958432018755, ...   \n",
       "...                                                 ...   \n",
       "4995  [[-0.006831209890411368, 0.022711734254179255,...   \n",
       "4996  [[-0.03823526995256543, 0.015385312959551811, ...   \n",
       "4997  [[0.0004524181131273508, 0.0363775837700814, -...   \n",
       "4998  [[-0.03595951018441054, 0.04274792379389206, -...   \n",
       "4999  [[-0.02371140491283898, 0.0018028813148183481,...   \n",
       "\n",
       "             sentence_embedding_tf_idf_proc_b_1k_source  \\\n",
       "0     [[-0.007066868075968942, 0.005607346065645118,...   \n",
       "1     [[-0.039775796329763254, -0.004100882681543145...   \n",
       "2     [[-0.013956825976806853, 0.010524739055448654,...   \n",
       "3     [[-0.006306732065082907, -0.002367327419645338...   \n",
       "4     [[-0.004266745919428459, 0.020920746568999327,...   \n",
       "...                                                 ...   \n",
       "4995  [[-0.008710065448488858, 0.010466450631324158,...   \n",
       "4996  [[-0.011011873583563005, 0.0016257848030860106...   \n",
       "4997  [[-0.017964938149843405, -0.006479997166303774...   \n",
       "4998  [[-0.01482810741283633, 0.010372276755398773, ...   \n",
       "4999  [[-0.004981590437542192, 1.7513979545761324e-0...   \n",
       "\n",
       "             sentence_embedding_tf_idf_proc_b_1k_target  \\\n",
       "0     [[-0.013969529264133333, 0.018536083310556985,...   \n",
       "1     [[-0.026569483773157737, 0.009380328691558417,...   \n",
       "2     [[-0.01840957375747747, 0.011432228637823928, ...   \n",
       "3     [[-0.014033250896603547, 0.0007865312866477389...   \n",
       "4     [[-0.02459387689770779, 0.009592057857595168, ...   \n",
       "...                                                 ...   \n",
       "4995  [[5.6516836084291216e-05, 0.005375066987057035...   \n",
       "4996  [[-0.009254192504192075, 0.007094162098472008,...   \n",
       "4997  [[0.0009744391006637598, 0.013281651314851739,...   \n",
       "4998  [[-0.011945683411114657, 0.01196331349841016, ...   \n",
       "4999  [[-0.00557969810802499, 0.0008041093101485405,...   \n",
       "\n",
       "                     translated_to_target_vecmap_source  \\\n",
       "0     [müssen, zählen, nachdruck, freiheit, facto, v...   \n",
       "1     [natürlicherweise, zahlreiche, problematik, eb...   \n",
       "2     [herrn, präsident, mary, vornehm, mary, berich...   \n",
       "3     [grundlegende, wirtschaftspolitik, verbraucher...   \n",
       "4     [danke, mary, nehmen, aufgrund, anmerkung, beo...   \n",
       "...                                                 ...   \n",
       "4995  [sagen, konsens, schauen, schwierig, bekommen,...   \n",
       "4996  [europäische, union, linke, stolz, humanitäre,...   \n",
       "4997  [jedoch, information, müssten, bedenken, subst...   \n",
       "4998  [frühe, woche, that, ehemalig, uno, botschafte...   \n",
       "4999  [verzögerung, phase, projekt, entscheidende, q...   \n",
       "\n",
       "                     translated_to_source_vecmap_target  \\\n",
       "0     [listen, censorship, listen, listen, tolerance...   \n",
       "1                   [obviously, amazing, far, question]   \n",
       "2     [lord, president, dear, mrs, colleague, report...   \n",
       "3     [politically, principle, consumer, integral, p...   \n",
       "4            [thank, daughter, observation, pay, apply]   \n",
       "...                                                 ...   \n",
       "4995  [interview, say, shape, difficult, peer, good,...   \n",
       "4996  [european, union, acknowledgement, preventativ...   \n",
       "4997  [incredibly, explanation, labelling, substance...   \n",
       "4998  [beginning, week, give, anyway, former, sudan,...   \n",
       "4999  [beginning, project, quality, viewpoint, respo...   \n",
       "\n",
       "               sentence_embedding_average_vecmap_source  \\\n",
       "0     [[0.20800741131489092, -0.03718488272548152, 0...   \n",
       "1     [[0.33323322981595993, -0.013636057265102863, ...   \n",
       "2     [[0.13944147573783994, 0.14624346122145654, 0....   \n",
       "3     [[0.2640666257251393, -0.0853267332369631, 0.0...   \n",
       "4     [[0.2628776244819164, 0.07202177572374542, 0.1...   \n",
       "...                                                 ...   \n",
       "4995  [[0.24532438007493815, 0.004404090862307284, 0...   \n",
       "4996  [[0.1838966760445725, -0.04385858147659085, 0....   \n",
       "4997  [[0.33515107817947865, -0.048095799633301795, ...   \n",
       "4998  [[0.06874247279483825, 0.09173224462817113, 0....   \n",
       "4999  [[0.29209267161786556, -0.0680284810368903, 0....   \n",
       "\n",
       "               sentence_embedding_average_vecmap_target  \\\n",
       "0     [[0.1708042360842228, -0.05323345214128494, 0....   \n",
       "1     [[0.31983064115047455, -0.012548421160317957, ...   \n",
       "2     [[0.13265844124058881, 0.13158888618151346, 0....   \n",
       "3     [[0.18233205378055573, -0.06059268582612276, 0...   \n",
       "4     [[0.2281290665268898, 0.025979317165911196, 0....   \n",
       "...                                                 ...   \n",
       "4995  [[0.1969107918183519, 0.011512659090970243, 0....   \n",
       "4996  [[0.1643218114040792, -0.023434823495335877, 0...   \n",
       "4997  [[0.29965757131576537, -0.055498963221907616, ...   \n",
       "4998  [[0.10321165372927983, 0.0371778037192093, 0.1...   \n",
       "4999  [[0.3182435408234596, -0.06927407572844199, 0....   \n",
       "\n",
       "                sentence_embedding_tf_idf_vecmap_source  \\\n",
       "0     [[0.05308659109689821, -0.012124574781091323, ...   \n",
       "1     [[0.16483797091322513, -0.009893845352128313, ...   \n",
       "2     [[0.039298395795571026, 0.03915855198838343, 0...   \n",
       "3     [[0.07169493797530326, -0.026357206451051805, ...   \n",
       "4     [[0.08939328089640149, 0.01932059090826744, 0....   \n",
       "...                                                 ...   \n",
       "4995  [[0.05863010090177196, 0.004771032047790131, 0...   \n",
       "4996  [[0.052804342223652274, -0.003989617522633716,...   \n",
       "4997  [[0.09410211836024641, -0.024247944199762585, ...   \n",
       "4998  [[0.008600220600305348, 0.01612903007741604, 0...   \n",
       "4999  [[0.06854605026579885, -0.016785477247572626, ...   \n",
       "\n",
       "                sentence_embedding_tf_idf_vecmap_target  \n",
       "0     [[0.053098278212977024, -0.004806572931137665,...  \n",
       "1     [[0.1630749418803205, -0.007294520385128128, 0...  \n",
       "2     [[0.03935996898779049, 0.029764392773049386, 0...  \n",
       "3     [[0.05362438231735067, -0.02147952806897634, 0...  \n",
       "4     [[0.09774504782369009, -0.005629674603903475, ...  \n",
       "...                                                 ...  \n",
       "4995  [[0.048826807176762056, 0.005519456655719748, ...  \n",
       "4996  [[0.04534390128151565, -0.001144711801600671, ...  \n",
       "4997  [[0.093213372315576, -0.012954907841144938, 0....  \n",
       "4998  [[0.010701002245010907, 4.584188879966058e-05,...  \n",
       "4999  [[0.07786661168430384, -0.01763608023010569, 0...  \n",
       "\n",
       "[5000 rows x 111 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parallel_sentences.preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "preprocessed_data = pd.read_json(\"../data/interim/preprocessed_data_en_de_testset.json\")\n",
    "parallel_sentences = PreprocessingEuroParl(df_sampled_path=\"../data/interim/europarl_en_de_test.pkl\")\n",
    "parallel_sentences.preprocessed = preprocessed_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Create data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we create the datasets for the training of the supervised model and the data for the supervised and unsupervised retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from src.data import DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_model = 0\n",
    "n_queries = 100\n",
    "n_retrieval = 5000\n",
    "k = 10\n",
    "sample_size_k = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: '__init__' in 0.0 seconds.\n"
     ]
    }
   ],
   "source": [
    "dataset = DataSet(parallel_sentences.preprocessed)\n",
    "#dataset = DataSet(preprocessed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'split_model_retrieval' in 0.0 seconds.\n"
     ]
    }
   ],
   "source": [
    "dataset.split_model_retrieval(n_model, n_retrieval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#dataset.create_retrieval_index(n_queries)\n",
    "\n",
    "# If your pandas version is old, use this instead\n",
    "query = pd.DataFrame({\"id_source\": dataset.retrieval_subset.iloc[:n_queries][\"id_source\"]})\n",
    "documents = pd.DataFrame({\"id_target\": dataset.retrieval_subset[\"id_target\"]})\n",
    "index = pd.MultiIndex.from_product([dataset.retrieval_subset.iloc[:n_queries][\"id_source\"], dataset.retrieval_subset[\"id_target\"]], names = [\"id_source\", \"id_target\"])\n",
    "dataset.retrieval_dataset_index = pd.DataFrame(index = index).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.retrieval_dataset_index.reset_index(drop=True).to_feather(\"../data/processed/dataset_retrieval_index_en_de_testset.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# pd.read_feather(\"../data/processed/dataset_retrieval_index.feather\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%% md\n"
    }
   },
   "source": [
    "## IV. Create features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we create features for our model, that are sentence based and should be created before the text is preprocessed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#%autoreload 2\n",
    "from src.features import feature_generation_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generation of the data for the crosslingual information retrieval task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_retrieval = feature_generation_class.FeatureGeneration(dataset.retrieval_dataset_index, \n",
    "                                                            parallel_sentences.preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'create_feature_dataframe' in 0.01 seconds.\n"
     ]
    }
   ],
   "source": [
    "features_retrieval.create_feature_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'difference_numerical' in 0.02 seconds.\n",
      "Finished function: 'relative_difference_numerical' in 0.01 seconds.\n",
      "Finished function: 'normalized_difference_numerical' in 0.02 seconds.\n",
      "Finished function: 'difference_numerical' in 0.0 seconds.\n",
      "Finished function: 'relative_difference_numerical' in 0.02 seconds.\n",
      "Finished function: 'normalized_difference_numerical' in 0.02 seconds.\n",
      "Finished function: 'difference_numerical' in 0.0 seconds.\n",
      "Finished function: 'relative_difference_numerical' in 0.01 seconds.\n",
      "Finished function: 'normalized_difference_numerical' in 0.02 seconds.\n",
      "Finished function: 'difference_numerical' in 0.0 seconds.\n",
      "Finished function: 'relative_difference_numerical' in 0.01 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/I534344/Google Drive/crosslingual-information-retrieval/src/features/sentence_features.py:21: RuntimeWarning: divide by zero encountered in log\n",
      "  return abs(target_array - source_array).replace(np.nan, 0).replace(np.inf, 0).replace(np.log(0), 0)\n",
      "/Users/I534344/Google Drive/crosslingual-information-retrieval/src/features/sentence_features.py:38: RuntimeWarning: divide by zero encountered in log\n",
      "  0), 0)\n",
      "/Users/I534344/Google Drive/crosslingual-information-retrieval/src/features/sentence_features.py:58: RuntimeWarning: divide by zero encountered in log\n",
      "  np.log(0), 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'normalized_difference_numerical' in 0.02 seconds.\n",
      "Finished function: 'difference_numerical' in 0.0 seconds.\n",
      "Finished function: 'relative_difference_numerical' in 0.01 seconds.\n",
      "Finished function: 'normalized_difference_numerical' in 0.02 seconds.\n",
      "Finished function: 'difference_numerical' in 0.01 seconds.\n",
      "Finished function: 'relative_difference_numerical' in 0.01 seconds.\n",
      "Finished function: 'normalized_difference_numerical' in 0.02 seconds.\n",
      "Finished function: 'difference_numerical' in 0.0 seconds.\n",
      "Finished function: 'relative_difference_numerical' in 0.01 seconds.\n",
      "Finished function: 'normalized_difference_numerical' in 0.02 seconds.\n",
      "Finished function: 'difference_numerical' in 0.0 seconds.\n",
      "Finished function: 'relative_difference_numerical' in 0.01 seconds.\n",
      "Finished function: 'normalized_difference_numerical' in 0.02 seconds.\n",
      "Finished function: 'difference_numerical' in 0.0 seconds.\n",
      "Finished function: 'relative_difference_numerical' in 0.01 seconds.\n",
      "Finished function: 'normalized_difference_numerical' in 0.02 seconds.\n",
      "Finished function: 'difference_numerical' in 0.0 seconds.\n",
      "Finished function: 'relative_difference_numerical' in 0.01 seconds.\n",
      "Finished function: 'normalized_difference_numerical' in 0.02 seconds.\n",
      "Finished function: 'difference_numerical' in 0.0 seconds.\n",
      "Finished function: 'relative_difference_numerical' in 0.01 seconds.\n",
      "Finished function: 'normalized_difference_numerical' in 0.02 seconds.\n",
      "Finished function: 'difference_numerical' in 0.01 seconds.\n",
      "Finished function: 'relative_difference_numerical' in 0.02 seconds.\n",
      "Finished function: 'normalized_difference_numerical' in 0.02 seconds.\n",
      "Finished function: 'difference_numerical' in 0.01 seconds.\n",
      "Finished function: 'relative_difference_numerical' in 0.02 seconds.\n",
      "Finished function: 'normalized_difference_numerical' in 0.02 seconds.\n",
      "Finished function: 'difference_numerical' in 0.0 seconds.\n",
      "Finished function: 'relative_difference_numerical' in 0.01 seconds.\n",
      "Finished function: 'normalized_difference_numerical' in 0.02 seconds.\n",
      "Finished function: 'difference_numerical' in 0.0 seconds.\n",
      "Finished function: 'relative_difference_numerical' in 0.01 seconds.\n",
      "Finished function: 'normalized_difference_numerical' in 0.02 seconds.\n",
      "Finished function: 'difference_numerical' in 0.0 seconds.\n",
      "Finished function: 'relative_difference_numerical' in 0.01 seconds.\n",
      "Finished function: 'normalized_difference_numerical' in 0.02 seconds.\n",
      "Finished function: 'difference_numerical' in 0.0 seconds.\n",
      "Finished function: 'relative_difference_numerical' in 0.01 seconds.\n",
      "Finished function: 'normalized_difference_numerical' in 0.02 seconds.\n",
      "Finished function: 'difference_numerical' in 0.0 seconds.\n",
      "Finished function: 'relative_difference_numerical' in 0.01 seconds.\n",
      "Finished function: 'normalized_difference_numerical' in 0.02 seconds.\n",
      "Finished function: 'difference_numerical' in 0.0 seconds.\n",
      "Finished function: 'relative_difference_numerical' in 0.01 seconds.\n",
      "Finished function: 'normalized_difference_numerical' in 0.02 seconds.\n",
      "Finished function: 'difference_numerical' in 0.01 seconds.\n",
      "Finished function: 'relative_difference_numerical' in 0.02 seconds.\n",
      "Finished function: 'normalized_difference_numerical' in 0.02 seconds.\n",
      "Finished function: 'difference_numerical' in 0.0 seconds.\n",
      "Finished function: 'relative_difference_numerical' in 0.01 seconds.\n",
      "Finished function: 'normalized_difference_numerical' in 0.02 seconds.\n",
      "Finished function: 'difference_numerical' in 0.0 seconds.\n",
      "Finished function: 'relative_difference_numerical' in 0.01 seconds.\n",
      "Finished function: 'normalized_difference_numerical' in 0.02 seconds.\n",
      "Finished function: 'difference_numerical' in 0.0 seconds.\n",
      "Finished function: 'relative_difference_numerical' in 0.01 seconds.\n",
      "Finished function: 'normalized_difference_numerical' in 0.02 seconds.\n",
      "Finished function: 'difference_numerical' in 0.0 seconds.\n",
      "Finished function: 'relative_difference_numerical' in 0.01 seconds.\n",
      "Finished function: 'normalized_difference_numerical' in 0.02 seconds.\n",
      "Finished function: 'difference_numerical' in 0.0 seconds.\n",
      "Finished function: 'relative_difference_numerical' in 0.01 seconds.\n",
      "Finished function: 'normalized_difference_numerical' in 0.02 seconds.\n",
      "Finished function: 'difference_numerical' in 0.0 seconds.\n",
      "Finished function: 'relative_difference_numerical' in 0.01 seconds.\n",
      "Finished function: 'normalized_difference_numerical' in 0.03 seconds.\n",
      "Finished function: 'difference_numerical' in 0.0 seconds.\n",
      "Finished function: 'relative_difference_numerical' in 0.01 seconds.\n",
      "Finished function: 'normalized_difference_numerical' in 0.02 seconds.\n",
      "Finished function: 'difference_numerical' in 0.0 seconds.\n",
      "Finished function: 'relative_difference_numerical' in 0.01 seconds.\n",
      "Finished function: 'normalized_difference_numerical' in 0.02 seconds.\n",
      "Finished function: 'difference_numerical' in 0.0 seconds.\n",
      "Finished function: 'relative_difference_numerical' in 0.01 seconds.\n",
      "Finished function: 'normalized_difference_numerical' in 0.02 seconds.\n",
      "Finished function: 'difference_numerical' in 0.01 seconds.\n",
      "Finished function: 'relative_difference_numerical' in 0.02 seconds.\n",
      "Finished function: 'normalized_difference_numerical' in 0.02 seconds.\n",
      "Finished function: 'difference_numerical' in 0.01 seconds.\n",
      "Finished function: 'relative_difference_numerical' in 0.01 seconds.\n",
      "Finished function: 'normalized_difference_numerical' in 0.02 seconds.\n",
      "Finished function: 'difference_numerical' in 0.02 seconds.\n",
      "Finished function: 'relative_difference_numerical' in 0.03 seconds.\n",
      "Finished function: 'normalized_difference_numerical' in 0.03 seconds.\n",
      "Finished function: 'difference_numerical' in 0.01 seconds.\n",
      "Finished function: 'relative_difference_numerical' in 0.01 seconds.\n",
      "Finished function: 'normalized_difference_numerical' in 0.02 seconds.\n",
      "Finished function: 'difference_numerical' in 0.01 seconds.\n",
      "Finished function: 'relative_difference_numerical' in 0.02 seconds.\n",
      "Finished function: 'normalized_difference_numerical' in 0.02 seconds.\n",
      "Finished function: 'difference_numerical' in 0.01 seconds.\n",
      "Finished function: 'relative_difference_numerical' in 0.01 seconds.\n",
      "Finished function: 'normalized_difference_numerical' in 0.01 seconds.\n",
      "Finished function: 'difference_numerical' in 0.01 seconds.\n",
      "Finished function: 'relative_difference_numerical' in 0.01 seconds.\n",
      "Finished function: 'normalized_difference_numerical' in 0.01 seconds.\n",
      "Finished function: 'difference_numerical' in 0.01 seconds.\n",
      "Finished function: 'relative_difference_numerical' in 0.01 seconds.\n",
      "Finished function: 'normalized_difference_numerical' in 0.02 seconds.\n",
      "Finished function: 'difference_numerical' in 0.01 seconds.\n",
      "Finished function: 'relative_difference_numerical' in 0.01 seconds.\n",
      "Finished function: 'normalized_difference_numerical' in 0.02 seconds.\n",
      "Finished function: 'difference_numerical' in 0.0 seconds.\n",
      "Finished function: 'relative_difference_numerical' in 0.01 seconds.\n",
      "Finished function: 'normalized_difference_numerical' in 0.02 seconds.\n",
      "Finished function: 'difference_numerical' in 0.0 seconds.\n",
      "Finished function: 'relative_difference_numerical' in 0.01 seconds.\n",
      "Finished function: 'normalized_difference_numerical' in 0.02 seconds.\n",
      "Finished function: 'difference_numerical' in 0.0 seconds.\n",
      "Finished function: 'relative_difference_numerical' in 0.01 seconds.\n",
      "Finished function: 'normalized_difference_numerical' in 0.01 seconds.\n",
      "Finished function: 'difference_numerical' in 0.0 seconds.\n",
      "Finished function: 'relative_difference_numerical' in 0.01 seconds.\n",
      "Finished function: 'normalized_difference_numerical' in 0.02 seconds.\n",
      "Finished function: 'difference_numerical' in 0.0 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 3653/500000 [00:00<00:13, 36527.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'relative_difference_numerical' in 0.01 seconds.\n",
      "Finished function: 'normalized_difference_numerical' in 0.02 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500000/500000 [00:13<00:00, 36116.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'jaccard' in 13.9 seconds.\n",
      "Finished function: 'create_sentence_features' in 17.06 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "features_retrieval.create_sentence_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500000/500000 [03:44<00:00, 2230.90it/s]\n",
      "  0%|          | 154/500000 [00:00<05:24, 1539.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'cosine_similarity_vector' in 224.19 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500000/500000 [03:48<00:00, 2192.02it/s]\n",
      "  0%|          | 234/500000 [00:00<03:34, 2334.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'cosine_similarity_vector' in 228.18 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500000/500000 [02:54<00:00, 2861.78it/s]\n",
      "  0%|          | 421/500000 [00:00<04:21, 1906.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'euclidean_distance_vector' in 174.8 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500000/500000 [02:50<00:00, 2935.08it/s]\n",
      "  0%|          | 0/500000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'euclidean_distance_vector' in 170.46 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500000/500000 [00:13<00:00, 37392.74it/s]\n",
      "  1%|          | 3139/500000 [00:00<00:15, 31385.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'jaccard' in 13.5 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500000/500000 [00:13<00:00, 37078.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'jaccard' in 13.56 seconds.\n",
      "Finished function: 'create_embedding_features' in 824.75 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "features_retrieval.create_embedding_features(\"proc_5k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500000/500000 [03:45<00:00, 2221.47it/s]\n",
      "  0%|          | 0/500000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'cosine_similarity_vector' in 225.14 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500000/500000 [03:39<00:00, 2278.26it/s]\n",
      "  0%|          | 650/500000 [00:00<02:42, 3066.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'cosine_similarity_vector' in 219.57 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500000/500000 [02:18<00:00, 3614.72it/s]\n",
      "  0%|          | 316/500000 [00:00<02:38, 3154.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'euclidean_distance_vector' in 138.37 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500000/500000 [02:22<00:00, 3515.18it/s]\n",
      "  1%|          | 4066/500000 [00:00<00:12, 40658.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'euclidean_distance_vector' in 142.29 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500000/500000 [00:13<00:00, 37314.92it/s]\n",
      "  1%|          | 3382/500000 [00:00<00:14, 33818.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'jaccard' in 13.49 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500000/500000 [00:12<00:00, 40500.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'jaccard' in 12.43 seconds.\n",
      "Finished function: 'create_embedding_features' in 751.32 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "features_retrieval.create_embedding_features(\"proc_b_1k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500000/500000 [03:35<00:00, 2324.30it/s]\n",
      "  0%|          | 95/500000 [00:00<08:46, 948.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'cosine_similarity_vector' in 215.17 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500000/500000 [03:37<00:00, 2296.49it/s]\n",
      "  0%|          | 240/500000 [00:00<03:28, 2395.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'cosine_similarity_vector' in 217.8 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500000/500000 [02:33<00:00, 3264.70it/s]\n",
      "  0%|          | 611/500000 [00:00<03:06, 2674.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'euclidean_distance_vector' in 153.22 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500000/500000 [02:27<00:00, 3388.74it/s]\n",
      "  1%|          | 3294/500000 [00:00<00:15, 32937.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'euclidean_distance_vector' in 147.6 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500000/500000 [00:13<00:00, 37049.50it/s]\n",
      "  0%|          | 1457/500000 [00:00<00:34, 14566.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'jaccard' in 13.57 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500000/500000 [00:15<00:00, 32475.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished function: 'jaccard' in 15.47 seconds.\n",
      "Finished function: 'create_embedding_features' in 762.88 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "features_retrieval.create_embedding_features(\"vecmap\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_retrieval.feature_dataframe.reset_index(drop=True).to_feather(\"../data/processed/feature_retrieval_en_de_testset.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# pd.read_feather(\"../data/processed/feature_retrieval.feather\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
